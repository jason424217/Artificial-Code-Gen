{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! pip3 install --upgrade gensim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2219,
     "status": "ok",
     "timestamp": 1562072364186,
     "user": {
      "displayName": "Nathan Cooper",
      "photoUrl": "",
      "userId": "15284233239426922637"
     },
     "user_tz": 300
    },
    "id": "v-FFfIovWj1P",
    "outputId": "9e48829f-e15d-4adb-96d8-0d91a34c4fd6"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import pickle\n",
    "import gensim\n",
    "import tqdm\n",
    "import collections\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "def load_dataset(path):\n",
    "    paths = []\n",
    "    if os.path.isfile(path):\n",
    "        # Simple file\n",
    "        paths.append(path)\n",
    "    elif os.path.isdir(path):\n",
    "        # Directory\n",
    "        for i, (dirpath, _, fnames) in enumerate(os.walk(path)):\n",
    "            for fname in fnames:\n",
    "                paths.append(os.path.join(dirpath, fname))\n",
    "    else:\n",
    "        # Assume glob\n",
    "        paths = glob.glob(path)\n",
    "\n",
    "        \n",
    "    token_chunks = []\n",
    "    raw_text = ''\n",
    "    for i, path in enumerate(tqdm.tqdm(paths)):\n",
    "#         if i >= 100000: break\n",
    "        try:\n",
    "            with open(path, 'r', encoding=\"iso-8859-1\") as fp:\n",
    "                raw_text += fp.read()\n",
    "            tokens = raw_text\n",
    "            token_chunks.append(tokens)\n",
    "            raw_text = ''\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    return token_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 972771/972771 [00:50<00:00, 19147.61it/s]\n"
     ]
    }
   ],
   "source": [
    "hman_trn_dataset = load_dataset(\"/tf/src/data/methods/DATA00M_[god-r]/train\")\n",
    "# hman_tst_dataset = load_dataset(\"/tf/src/data/methods/DATA00M_[god-r]/test\")\n",
    "\n",
    "# # GPT2 Pretrained unconditional samples\n",
    "# m1_dataset = load_dataset(\"/tf/src/manifoldAnalysis/output_space/unconditional/samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_corpus(dataset, tokens_only=False):\n",
    "    for i, method in enumerate(dataset):\n",
    "        try:\n",
    "            if tokens_only:\n",
    "                yield gensim.utils.simple_preprocess(method)\n",
    "            else:\n",
    "                # For training data, add tags\n",
    "                yield gensim.models.doc2vec.TaggedDocument(gensim.utils.simple_preprocess(method), [i])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab training and testing data\n",
    "d2v_hman_trn_set = list(generate_corpus(hman_trn_dataset))\n",
    "# d2v_hman_tst_set = list(generate_corpus(hman_tst_dataset, tokens_only = True))\n",
    "\n",
    "# # Process GPT2 Pretrained unconditional samples for generating features\n",
    "# d2v_m1_set = list(generate_corpus(m1_dataset, tokens_only = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['java', 'lang', 'override', 'public', 'void', 'final', 'java', 'lang', 'object', 'value', 'throws', 'java', 'io', 'ioexception', 'final', 'org', 'opendaylight', 'yangtools', 'yang', 'model', 'api', 'schema', 'tracker', 'final', 'org', 'opendaylight', 'yangtools', 'yang', 'data', 'codec', 'gson', 'jsoncodec', 'java', 'lang', 'object', 'codec', 'codecs', 'codecfor', 'schema', 'context', 'emittingchild', 'codecs', 'writer', 'writevalue', 'value', 'codec'], tags=[0]),\n",
       " TaggedDocument(words=['private', 'void', 'releaseall', 'if', 'msensormanager', 'null', 'msensormanager', 'if', 'msensormanager', 'null', 'msensormanager', 'null', 'if', 'mcamera', 'null', 'mcamera', 'null', 'mcamera', 'release', 'mcamera', 'null'], tags=[1])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2v_hman_trn_set[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate model\n",
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=300, min_count=2, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(d2v_hman_trn_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time model.train(d2v_hman_trn_set, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.infer_vector(['only', 'you', 'can', 'prevent', 'forest', 'fires']).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import get_tmpfile\n",
    "\n",
    "fname = get_tmpfile(\"/tf/src/data/doc2vec/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(fname)\n",
    "model = gensim.models.doc2vec.Doc2Vec.load(fname)\n",
    "model.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok"
     ]
    }
   ],
   "source": [
    "!curl -X POST -H 'Content-type: application/json' --data '{\"text\":\"from: semeru tower 1\\nstatus: doc2vec model finished training\"}' https://hooks.slack.com/services/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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check model correctly loaded\n",
    "model.infer_vector([\"system\", \"response\"]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dict = {}\n",
    "for i in range(len(d2v_tst_set)):\n",
    "    features = model.infer_vector(d2v_tst_set[i])\n",
    "    feature_dict[tst_set[i]] = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/tf/src/manifoldAnalysis/output_space/human_features.pickle', 'wb') as f:\n",
    "    pickle.dump(feature_dict, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate feature vectors from methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class D2VEmbedder:\n",
    "    def __init__(self, model_path):\n",
    "        self.model = gensim.models.doc2vec.Doc2Vec.load(model_path)\n",
    "        \n",
    "    def __call__(self, ds_path):\n",
    "        methods = load_dataset(ds_path)\n",
    "        d2v_methods = list(tqdm.tqdm(generate_corpus(methods, tokens_only = True)))\n",
    "        \n",
    "        feature_dict = {}\n",
    "        for i in tqdm.tqdm(range(len(d2v_methods))):\n",
    "            features = self.model.infer_vector(d2v_methods[i])\n",
    "            feature_dict[methods[i]] = features\n",
    "            \n",
    "        return feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embdr = D2VEmbedder(\"/tf/src/data/doc2vec/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = embdr(\"/tf/src/data/methods/DATA00M_[god-r]/test\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "gpt2_tf2_new.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
