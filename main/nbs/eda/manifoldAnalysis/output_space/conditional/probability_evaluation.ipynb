{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Easily export jupyter cells to python module\n",
    "https://github.com/fastai/course-v3/blob/master/nbs/dl2/notebook2script.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! python /tf/src/scripts/notebook2script.py probability_evaluation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exp.nb_conditional import *\n",
    "from data_loader import *\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /tf/src/data/gpt-2/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "args = get_default_args()\n",
    "args.dataset = \"/tf/src/data/methods/DATA00M_[god-r]/test\"\n",
    "enc = get_encoder(args.model_name, \"models\")\n",
    "data_set = load_dataset(enc, args.dataset)\n",
    "len(data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_probs(ds, enc, chkpt_path, MAX_CHUNK = 1024, bs = 1, seed = None, temperature = 1, verbose = False):\n",
    "    with tf.compat.v1.Session(graph=tf.Graph()) as sess:\n",
    "        context = tf.compat.v1.placeholder(tf.int32, [bs, None])\n",
    "        np.random.seed(seed)\n",
    "        tf.compat.v1.set_random_seed(seed)\n",
    "        output, logits = sample_sequence(\n",
    "            hparams=default_hparams(),\n",
    "            context=context,\n",
    "            past=None,\n",
    "            batch_size=bs,\n",
    "            temperature=temperature\n",
    "        )\n",
    "        \n",
    "        saver = tf.compat.v1.train.Saver()\n",
    "        ckpt = tf.train.latest_checkpoint(chkpt_path)\n",
    "        saver.restore(sess, ckpt)\n",
    "        \n",
    "        mean_probs = {}\n",
    "        for method in tqdm.tqdm(ds):\n",
    "            enc_meth = enc.encode(method)\n",
    "            rshft = enc_meth[:-1]\n",
    "            lshft = enc_meth[1:]\n",
    "            context_tokens = []\n",
    "            for i, tok in enumerate(rshft):\n",
    "                context_tokens.append(tok)\n",
    "                if len(context_tokens) == MAX_CHUNK + 1:\n",
    "                    context_tokens.pop(0)\n",
    "               \n",
    "                out, probs = sess.run([output, logits], feed_dict={\n",
    "                    context: [context_tokens for _ in range(bs)]\n",
    "                }, options = tf.compat.v1.RunOptions(report_tensor_allocations_upon_oom = True))\n",
    "                out = out[:, -1]\n",
    "                \n",
    "                if verbose:\n",
    "                    print(repr(enc.decode([out[0]])), repr(enc.decode([lshft[i]])), probs[0][out[0]])\n",
    "                if out[0] == lshft[i]:\n",
    "                    if enc.decode([out[0]]) in mean_probs:\n",
    "                        prob, count = mean_probs[enc.decode([out[0]])]\n",
    "                        mean_probs[enc.decode([out[0]])] = (prob + probs[0][out[0]], count + 1)\n",
    "                    else:\n",
    "                        mean_probs[enc.decode([out[0]])] = (probs[0][out[0]], 1)\n",
    "        \n",
    "        return mean_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chkpt_path = os.path.join(\"checkpoint\", \"m1\")\n",
    "mean_probs = calc_probs(data_set, enc, chkpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Probabilities\n",
    "with open(os.path.join(\"/tf/src/data/misc\", 'mean_probs.pickle'), 'wb') as f:\n",
    "    pickle.dump(mean_probs, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! curl -X POST -H 'Content-type: application/json' --data '{\"text\":\"from: semeru tower 2\\nstatus: model 1 finished generating mean probabilities\"}' https://hooks.slack.com/services/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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"/tf/src/data/misc\", 'mean_probs.pickle'), 'rb') as f:\n",
    "    x = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summed, count = x[\"\\n\"]\n",
    "summed / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "MAX_CHUNK = 1024\n",
    "\n",
    "def interact_model(\n",
    "    model_name='117M',\n",
    "    seed=None,\n",
    "    nsamples=1,\n",
    "    batch_size=1,\n",
    "    length=None,\n",
    "    temperature=1,\n",
    "    top_k=0,\n",
    "    models_dir='models',\n",
    "    ds=[]\n",
    "):\n",
    "    models_dir = os.path.expanduser(os.path.expandvars(models_dir))\n",
    "    if batch_size is None:\n",
    "        batch_size = 1\n",
    "    assert nsamples % batch_size == 0\n",
    "\n",
    "    enc = get_encoder(\"117M\", \"models\")\n",
    "    hparams = default_hparams()\n",
    "\n",
    "    with tf.compat.v1.Session(graph=tf.Graph()) as sess:\n",
    "        context = tf.compat.v1.placeholder(tf.int32, [batch_size, None])\n",
    "        np.random.seed(seed)\n",
    "        tf.compat.v1.set_random_seed(seed)\n",
    "        output, logits = sample_sequence(\n",
    "            hparams=hparams,\n",
    "            context=context,\n",
    "            past=None,\n",
    "            batch_size=batch_size,\n",
    "            temperature=temperature\n",
    "        )\n",
    "        \n",
    "\n",
    "        saver = tf.compat.v1.train.Saver()\n",
    "        ckpt = tf.train.latest_checkpoint(os.path.join(models_dir, model_name))\n",
    "        saver.restore(sess, ckpt)\n",
    "        \n",
    "        mean_probs = {} \n",
    "        for method in tqdm.tqdm(ds[:2]):\n",
    "            enc_meth = enc.encode(method)\n",
    "            rshft = enc_meth[:-1]\n",
    "            lshft = enc_meth[1:]\n",
    "            context_tokens = []\n",
    "            for i, tok in enumerate(rshft):\n",
    "                context_tokens.append(tok)\n",
    "                if len(context_tokens) == MAX_CHUNK + 1:\n",
    "                    context_tokens.pop(0)\n",
    "               \n",
    "                out, probs = sess.run([output, logits], feed_dict={\n",
    "                    context: [context_tokens for _ in range(batch_size)]\n",
    "                }, options = tf.compat.v1.RunOptions(report_tensor_allocations_upon_oom = True))\n",
    "                out = out[:, -1]\n",
    "                \n",
    "                print(repr(enc.decode([out[0]])), repr(enc.decode([lshft[i]])), probs[0][out[0]])\n",
    "                if out[0] == lshft[i]:\n",
    "                    if enc.decode([out[0]]) in mean_probs:\n",
    "                        prob, count = mean_probs[enc.decode([out[0]])]\n",
    "                        mean_probs[enc.decode([out[0]])] = (prob + probs[0][out[0]], count + 1)\n",
    "                    else:\n",
    "                        mean_probs[enc.decode([out[0]])] = (probs[0][out[0]], 1)\n",
    "        print(mean_probs.keys())\n",
    "\n",
    "interact_model(model_name='run1',\n",
    "    seed=None,\n",
    "    nsamples=1,\n",
    "    batch_size=1,\n",
    "    length=None,\n",
    "    temperature=1,\n",
    "    top_k=40,\n",
    "    models_dir='checkpoint', ds=data_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
