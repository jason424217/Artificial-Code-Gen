{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Easily export jupyter cells to python module\n",
    "https://github.com/fastai/course-v3/blob/master/nbs/dl2/notebook2script.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! python /tf/src/scripts/notebook2script.py probability_evaluation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from encoder import *\n",
    "from data_loader import *\n",
    "from model import *\n",
    "from exp.nb_conditional import default_hparams\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/src/data/gpt-2\n"
     ]
    }
   ],
   "source": [
    "cd /tf/src/data/gpt-2/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/121596 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_path = \"/tf/src/data/methods/DATA00M_[god-r]/test\"\n",
    "enc = get_encoder(\"117M\", \"models\")\n",
    "data_set = load_dataset(enc, ds_path, sample = 1000)\n",
    "len(data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_context = tf.compat.v1.placeholder(tf.int32, [args.val_batch_size, None])\n",
    "val_output = model(hparams=hparams, X=val_context)\n",
    "val_loss        = tf.reduce_mean(\n",
    "                                    input_tensor=tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                                        labels=val_context[:, 1:], logits=val_output['logits'][:, :-1]))\n",
    "def validation():\n",
    "            print('Calculating validation loss...')\n",
    "            losses = []\n",
    "            for batch in tqdm.tqdm(val_batches):\n",
    "                losses.append(sess.run(val_loss, feed_dict={val_context: batch}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API look\n",
    "def cross_entropy(ds, chkpt_path, MAX_CHUNK = 1024, bs = 1):\n",
    "    # Generate permutations (TODO)\n",
    "    \n",
    "    \n",
    "    with tf.compat.v1.Session(graph=tf.Graph()) as sess:\n",
    "        context = tf.compat.v1.placeholder(tf.int32, [bs, None])\n",
    "        # Generate predictions of model\n",
    "        output  = model(hparams=default_hparams(), X=context)\n",
    "        # Calculate cross entropy using tf library\n",
    "        loss1    = tf.reduce_mean(\n",
    "            input_tensor = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                labels = context[:, 1:], logits = output['logits'][:, :-1]\n",
    "            )\n",
    "        )\n",
    "        loss2    = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            labels = context[:, 1:], logits = output['logits'][:, :-1]\n",
    "        )\n",
    "        \n",
    "        # Load model\n",
    "        saver = tf.compat.v1.train.Saver()\n",
    "        ckpt = tf.train.latest_checkpoint(chkpt_path)\n",
    "        saver.restore(sess, ckpt)\n",
    "    \n",
    "        # For each method:\n",
    "        entropy = []\n",
    "        for method in tqdm.tqdm(ds):\n",
    "            enc_meth    = enc.encode(method)\n",
    "            \n",
    "            context_tokens = enc_meth[:MAX_CHUNK]\n",
    "            val = sess.run(loss1, feed_dict={context: [context_tokens]})\n",
    "            if not math.isnan(val):\n",
    "                entropy.append(val)\n",
    "#             for i in range(len(enc_meth) % MAX_CHUNK):\n",
    "#                 context_tokens = enc_meth[MAX_CHUNK * i:MAX_CHUNK * (i + 1)]\n",
    "#                 print(len(tok))\n",
    "            for tok in enc_meth[MAX_CHUNK:]:\n",
    "                context_tokens.append(tok)\n",
    "                context_tokens.pop(0)\n",
    "    \n",
    "#                 # Need to recalculate this because this is not correct way (I think)\n",
    "                val = sess.run(loss2, feed_dict={context: [context_tokens]})\n",
    "                if not math.isnan(val[:, -1]):\n",
    "                    entropy.append(val[:, -1])\n",
    "        \n",
    "        return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  2.88it/s]\n"
     ]
    }
   ],
   "source": [
    "# API look\n",
    "chkpt_path = os.path.join(\"checkpoint\", \"m1\")\n",
    "entropy = cross_entropy(data_set[:2], chkpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.48468012], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy = np.array(entropy)\n",
    "entropy.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4819677"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy = np.array(entropy)\n",
    "entropy.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
