{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#danaderp May6'19\n",
    "#Prediction For Main Issues Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/danaderp/.conda/envs/drmccr_conda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Limited tf.compat.v2.summary API due to missing TensorBoard installation\n",
      "Limited tf.summary API due to missing TensorBoard installation\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from tensorflow.keras.preprocessing import text\n",
    "from nltk.corpus import gutenberg\n",
    "from string import punctuation\n",
    "from tensorflow.keras.preprocessing.sequence import skipgrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "pd.options.display.max_colwidth = 200\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "englishStemmer=SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dot, Input, Dense, Reshape, LSTM, Conv2D, Flatten, MaxPooling1D, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.layers import Embedding, Multiply, Subtract\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.python.keras.layers import Lambda\n",
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# visualize model structure\n",
    "#from IPython.display import SVG\n",
    "#from keras.utils.vis_utils import model_to_dot\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datasets.read_data import Dynamic_Dataset,Processing_Dataset\n",
    "from vectorize_sentence import Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"datasets/combined_dataset/\"\n",
    "process_unit = Processing_Dataset(path)\n",
    "ground_truth = process_unit.get_ground_truth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = Dynamic_Dataset(ground_truth, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test, train = process_unit.get_test_and_training(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1030\n",
      "9308\n",
      "('(1,0)', 'Moved SecurityUserValueResolver to security-http\\n\\n\\nThe SecurityUserValueResolver class is deprecated and will be removed in 5.0, use Symfony\\\\Component\\\\Security\\\\Http\\\\Controller\\\\UserValueResolver instead.\\nsymfony/symfony#25588')\n",
      "('(1,0)', \"'This is a useful security improvement, that I recommend gets integrated into gitlab. It protects users, in the event that their passwords get stolen from other sites, etc. I found a good gem for this: http://rubydoc.info/github/mdp/rotp/master/frames, however, given that it appears Gitlab uses Devise for auth, we should probably use this plugin: https://github.com/wmlele/devise-otp\\n\\nI intend to submit a Merge Request for this, so I'll outline my design for the system here (in case anyone has feedback/wants to help):\\n\\n### OTP Strategy\\nI'm going with time-based (TOTP). Its requires no storage implications, per-user (other than a 32bit secret key). Time-based keys are very common, Google uses this strategy to protect GMail/Apps customers.\\n\\n### Database Augmentation\\n**NOTE:** Given the existence of devise-otp, this may no longer be necessary.\\n\\nI will add new table, with a foreign key reference to a `user_id` column,  and `totp_secret` column. The existence of a row implies that this feature is enabled for a user. This table could be enhanced further down the road to support other types of otp strategies, if need be. This would also make future data migrations, in the event of further enhancement, easier to manage.\\n\\n### UI Augmentation\\n#### User Account Settings\\nWe'll add a simple checkbox that a user must toggle to enable this feature. Once the checkbox is toggled, a modal will appear, displaying a QR code that the user will then scan with their mobile device, to start generating OTP codes. There will also be a box for the user to provide a newly generated OTP code to verify the service is working properly, for their account. Users will also need the ability to also reset the secret, in case they lose their phone etc.\\n\\n#### Admin Settings\\nWe'll need to allow admins to toggle if this feature is enabled, for a given user account. Assumed use case would be to contact an admin to disable OTP codes so you can log back in, re-enable it, and setup a new secret for yourself.\\n\\n#### Sign In\\nOnce the user has provided a proper username/password pair, if the flag is enabled, they will be redirected to a page that asks them to enter an OTP code, before they can proceed into the protected areas of the site.\\n\\n------\\n\\n**QUESTION: What would be the best course of action to manage the scenario where a user has lost their phone, and can no longer regenerate OTP codes to access their account? How can we let them back in to reset their OTP secret?** So far, my assumption is that the user would contact their gitlab administrators and they would disable OTP for them. However, one potential issue with this is that the attacker, who may have the user's password, may also have access to their e-mail. This would allow them to ask the administrator to disable OTP, and gain access to their data. Likely the verification protocol for admins should be org-specific, and not in scope of this work. Unsure how gitlab cloud staff wants to manage this, for their users. \\n\\n**UPDATE:** Its worth noting that using devise-otp provides a list of emergency HTOP recovery tokens that can be used, if we expose that functionality.\")\n"
     ]
    }
   ],
   "source": [
    "print(len(test))\n",
    "print(len(train))\n",
    "print(test[0])\n",
    "print(train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train/Test split verification\n",
    "#for elem in test:\n",
    "#    print(elem[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Preprocesing Corpora\n",
    "embeddings = Embeddings()\n",
    "pre_corpora_train = [embeddings.preprocess(doc[1]) for doc in train]\n",
    "pre_corpora_test = [embeddings.preprocess(doc[1]) for doc in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['use',\n",
       " 'secur',\n",
       " 'improv',\n",
       " 'recommend',\n",
       " 'get',\n",
       " 'integr',\n",
       " 'gitlab',\n",
       " 'protect',\n",
       " 'user',\n",
       " 'event',\n",
       " 'password',\n",
       " 'get',\n",
       " 'stolen',\n",
       " 'site',\n",
       " 'etc',\n",
       " 'found',\n",
       " 'good',\n",
       " 'gem',\n",
       " 'http',\n",
       " 'rubydoc',\n",
       " 'info',\n",
       " 'github',\n",
       " 'mdp',\n",
       " 'rotp',\n",
       " 'master',\n",
       " 'frame',\n",
       " 'howev',\n",
       " 'given',\n",
       " 'appear',\n",
       " 'gitlab',\n",
       " 'use',\n",
       " 'devis',\n",
       " 'auth',\n",
       " 'probabl',\n",
       " 'use',\n",
       " 'plugin',\n",
       " 'https',\n",
       " 'github',\n",
       " 'com',\n",
       " 'wmlele',\n",
       " 'devis',\n",
       " 'otp',\n",
       " 'intend',\n",
       " 'submit',\n",
       " 'merg',\n",
       " 'request',\n",
       " 'outlin',\n",
       " 'design',\n",
       " 'system',\n",
       " 'case',\n",
       " 'anyon',\n",
       " 'feedback',\n",
       " 'want',\n",
       " 'help',\n",
       " 'otp',\n",
       " 'strategi',\n",
       " 'time',\n",
       " 'base',\n",
       " 'totp',\n",
       " 'requir',\n",
       " 'storag',\n",
       " 'implic',\n",
       " 'per',\n",
       " 'user',\n",
       " 'bit',\n",
       " 'secret',\n",
       " 'key',\n",
       " 'time',\n",
       " 'base',\n",
       " 'key',\n",
       " 'common',\n",
       " 'googl',\n",
       " 'use',\n",
       " 'strategi',\n",
       " 'protect',\n",
       " 'gmail',\n",
       " 'app',\n",
       " 'custom',\n",
       " 'databas',\n",
       " 'augment',\n",
       " 'note',\n",
       " 'given',\n",
       " 'exist',\n",
       " 'devis',\n",
       " 'otp',\n",
       " 'may',\n",
       " 'longer',\n",
       " 'necessari',\n",
       " 'add',\n",
       " 'new',\n",
       " 'tabl',\n",
       " 'foreign',\n",
       " 'key',\n",
       " 'refer',\n",
       " 'user',\n",
       " 'column',\n",
       " 'totp',\n",
       " 'secret',\n",
       " 'column',\n",
       " 'exist',\n",
       " 'row',\n",
       " 'impli',\n",
       " 'featur',\n",
       " 'enabl',\n",
       " 'user',\n",
       " 'tabl',\n",
       " 'could',\n",
       " 'enhanc',\n",
       " 'road',\n",
       " 'support',\n",
       " 'type',\n",
       " 'otp',\n",
       " 'strategi',\n",
       " 'need',\n",
       " 'would',\n",
       " 'also',\n",
       " 'make',\n",
       " 'futur',\n",
       " 'data',\n",
       " 'migrat',\n",
       " 'event',\n",
       " 'enhanc',\n",
       " 'easier',\n",
       " 'manag',\n",
       " 'augment',\n",
       " 'user',\n",
       " 'account',\n",
       " 'set',\n",
       " 'add',\n",
       " 'simpl',\n",
       " 'checkbox',\n",
       " 'user',\n",
       " 'must',\n",
       " 'toggl',\n",
       " 'enabl',\n",
       " 'featur',\n",
       " 'checkbox',\n",
       " 'toggl',\n",
       " 'modal',\n",
       " 'appear',\n",
       " 'display',\n",
       " 'code',\n",
       " 'user',\n",
       " 'scan',\n",
       " 'mobil',\n",
       " 'devic',\n",
       " 'start',\n",
       " 'generat',\n",
       " 'otp',\n",
       " 'code',\n",
       " 'also',\n",
       " 'box',\n",
       " 'user',\n",
       " 'provid',\n",
       " 'newli',\n",
       " 'generat',\n",
       " 'otp',\n",
       " 'code',\n",
       " 'verifi',\n",
       " 'servic',\n",
       " 'work',\n",
       " 'proper',\n",
       " 'account',\n",
       " 'user',\n",
       " 'also',\n",
       " 'need',\n",
       " 'abil',\n",
       " 'also',\n",
       " 'reset',\n",
       " 'secret',\n",
       " 'case',\n",
       " 'lose',\n",
       " 'phone',\n",
       " 'etc',\n",
       " 'admin',\n",
       " 'set',\n",
       " 'need',\n",
       " 'allow',\n",
       " 'admin',\n",
       " 'toggl',\n",
       " 'featur',\n",
       " 'enabl',\n",
       " 'given',\n",
       " 'user',\n",
       " 'account',\n",
       " 'assum',\n",
       " 'use',\n",
       " 'case',\n",
       " 'would',\n",
       " 'contact',\n",
       " 'admin',\n",
       " 'disabl',\n",
       " 'otp',\n",
       " 'code',\n",
       " 'log',\n",
       " 'back',\n",
       " 'enabl',\n",
       " 'setup',\n",
       " 'new',\n",
       " 'secret',\n",
       " 'sign',\n",
       " 'user',\n",
       " 'provid',\n",
       " 'proper',\n",
       " 'usernam',\n",
       " 'password',\n",
       " 'pair',\n",
       " 'flag',\n",
       " 'enabl',\n",
       " 'redirect',\n",
       " 'page',\n",
       " 'ask',\n",
       " 'enter',\n",
       " 'otp',\n",
       " 'code',\n",
       " 'proceed',\n",
       " 'protect',\n",
       " 'area',\n",
       " 'site',\n",
       " 'question',\n",
       " 'would',\n",
       " 'best',\n",
       " 'cours',\n",
       " 'action',\n",
       " 'manag',\n",
       " 'scenario',\n",
       " 'user',\n",
       " 'lost',\n",
       " 'phone',\n",
       " 'longer',\n",
       " 'regener',\n",
       " 'otp',\n",
       " 'code',\n",
       " 'access',\n",
       " 'account',\n",
       " 'let',\n",
       " 'back',\n",
       " 'reset',\n",
       " 'otp',\n",
       " 'secret',\n",
       " 'far',\n",
       " 'assumpt',\n",
       " 'user',\n",
       " 'would',\n",
       " 'contact',\n",
       " 'gitlab',\n",
       " 'administr',\n",
       " 'would',\n",
       " 'disabl',\n",
       " 'otp',\n",
       " 'howev',\n",
       " 'one',\n",
       " 'potenti',\n",
       " 'issu',\n",
       " 'attack',\n",
       " 'may',\n",
       " 'user',\n",
       " 'password',\n",
       " 'may',\n",
       " 'also',\n",
       " 'access',\n",
       " 'mail',\n",
       " 'would',\n",
       " 'allow',\n",
       " 'ask',\n",
       " 'administr',\n",
       " 'disabl',\n",
       " 'otp',\n",
       " 'gain',\n",
       " 'access',\n",
       " 'data',\n",
       " 'like',\n",
       " 'verif',\n",
       " 'protocol',\n",
       " 'admin',\n",
       " 'org',\n",
       " 'specif',\n",
       " 'scope',\n",
       " 'work',\n",
       " 'unsur',\n",
       " 'gitlab',\n",
       " 'cloud',\n",
       " 'staff',\n",
       " 'want',\n",
       " 'manag',\n",
       " 'user',\n",
       " 'updat',\n",
       " 'worth',\n",
       " 'note',\n",
       " 'use',\n",
       " 'devis',\n",
       " 'otp',\n",
       " 'provid',\n",
       " 'list',\n",
       " 'emerg',\n",
       " 'htop',\n",
       " 'recoveri',\n",
       " 'token',\n",
       " 'use',\n",
       " 'expos',\n",
       " 'function']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_corpora_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_len_sentences_train = max([len(doc) for doc in pre_corpora_train]) #<------- [Parameter]\n",
    "max_len_sentences_test = max([len(doc) for doc in pre_corpora_test]) #<------- [Parameter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max. Sentence # words: 13806\n"
     ]
    }
   ],
   "source": [
    "max_len_sentences = max(max_len_sentences_train,max_len_sentences_test)\n",
    "print(\"Max. Sentence # words:\",max_len_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embed_path = 'datasets/word_embeddings-embed_size_100-epochs_100.csv'\n",
    "embeddings_dict = embeddings.get_embeddings_dict(embed_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpora_train = [embeddings.vectorize(doc[1], embeddings_dict) for doc in train]#vectorization Inputs\n",
    "corpora_test = [embeddings.vectorize(doc[1], embeddings_dict) for doc in test]#vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_train = [[int(list(doc[0])[1]),int(list(doc[0])[3])] for doc in train]#vectorization Output\n",
    "target_test = [[int(list(doc[0])[1]),int(list(doc[0])[3])]for doc in test]#vectorization Output\n",
    "#target_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_len_sentences_train = max([len(doc) for doc in corpora_train]) #<------- [Parameter]\n",
    "max_len_sentences_test = max([len(doc) for doc in corpora_test]) #<------- [Parameter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max. Sentence # words: 13789\n"
     ]
    }
   ],
   "source": [
    "max_len_sentences = max(max_len_sentences_train,max_len_sentences_test)\n",
    "print(\"Max. Sentence # words:\",max_len_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_len_sentences_train = min([len(doc) for doc in corpora_train]) #<------- [Parameter]\n",
    "min_len_sentences_test = min([len(doc) for doc in corpora_test]) #<------- [Parameter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mix. Sentence # words: 1\n"
     ]
    }
   ],
   "source": [
    "min_len_sentences = max(min_len_sentences_train,min_len_sentences_test)\n",
    "print(\"Mix. Sentence # words:\",min_len_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embed_size = np.size(corpora_train[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#BaseLine Architecture <-------\n",
    "embeddigs_cols = embed_size\n",
    "input_sh = (max_len_sentences,embeddigs_cols,1)\n",
    "#Selecting filters? \n",
    "#https://stackoverflow.com/questions/48243360/how-to-determine-the-filter-parameter-in-the-keras-conv2d-function\n",
    "#https://stats.stackexchange.com/questions/196646/what-is-the-significance-of-the-number-of-convolution-filters-in-a-convolutional\n",
    "\n",
    "N_filters = 128 # <-------- [HyperParameter] Powers of 2 Numer of Features\n",
    "K = 2 # <-------- [HyperParameter] Number of Classess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13789, 100, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#baseline_model = Sequential()\n",
    "gram_input = Input(shape = input_sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1st Convolutional Layer\n",
    "conv_1_layer = Conv2D(filters=64, input_shape=input_sh, activation='relu', \n",
    "                      kernel_size=(7,7), strides=(2,2), padding='valid')(gram_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 6892, 47, 64])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_1_layer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Max Pooling\n",
    "max_1_pooling = MaxPooling2D(pool_size=(2,2), strides=None, padding='valid')(conv_1_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 3446, 23, 64])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_1_pooling.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2nd Convolutional Layer\n",
    "conv_2_layer = Conv2D(filters=256, kernel_size=(7,7), activation='relu', \n",
    "                      strides=(1,1), padding='valid')(max_1_pooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 3440, 17, 256])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_2_layer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max Pooling\n",
    "max_2_pooling = MaxPooling2D(pool_size=(2,2), strides=None, padding='valid')(conv_2_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 1720, 8, 256])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_2_pooling.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3rd Convolutional Layer\n",
    "conv_3_layer =  Conv2D(filters=512, kernel_size=(3,3), activation='relu', \n",
    "                      strides=(1,1), padding='valid')(max_2_pooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 1718, 6, 512])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_3_layer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4th Convolutional Layer\n",
    "conv_4_layer = Conv2D(filters=512, kernel_size=(3,3), activation='relu', \n",
    "                      strides=(1,1), padding='valid')(conv_3_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 1716, 4, 512])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_4_layer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5th Convolutional Layer\n",
    "conv_5_layer = Conv2D(filters=256, kernel_size=(3,3), activation='relu', \n",
    "                      strides=(1,1), padding='valid')(conv_4_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 1714, 2, 256])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_5_layer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Max Pooling\n",
    "max_5_pooling = MaxPooling2D(pool_size=(2,2), strides=None, padding='valid')(conv_5_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 857, 1, 256])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_5_pooling.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fully Connected layer\n",
    "fully_connected = Flatten()(max_5_pooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 219392])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fully_connected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1st Fully Connected Layer\n",
    "deep_dense_1_layer = Dense(1024, activation='relu')(fully_connected)\n",
    "deep_dense_1_layer = Dropout(0.4)(deep_dense_1_layer) # <-------- [HyperParameter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 1024])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_dense_1_layer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2nd Fully Connected Layer\n",
    "deep_dense_2_layer = Dense(1024, activation='relu')(deep_dense_1_layer)\n",
    "deep_dense_2_layer = Dropout(0.4)(deep_dense_2_layer) # <-------- [HyperParameter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 1024])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_dense_2_layer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3rd Fully Connected Layer\n",
    "deep_dense_3_layer = Dense(128, activation='relu')(deep_dense_2_layer)\n",
    "deep_dense_3_layer = Dropout(0.4)(deep_dense_3_layer) # <-------- [HyperParameter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 128])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_dense_3_layer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = Dense(K, activation='softmax')(deep_dense_3_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Criticality Model\n",
    "criticality_network = Model(inputs=[gram_input],outputs=[predictions]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 13789, 100, 1)]   0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 6892, 47, 64)      3200      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 3446, 23, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 3440, 17, 256)     803072    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 1720, 8, 256)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 1718, 6, 512)      1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 1716, 4, 512)      2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 1714, 2, 256)      1179904   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 857, 1, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 219392)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              224658432 \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 231,365,634\n",
      "Trainable params: 231,365,634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(criticality_network.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Seting up the Model\n",
    "criticality_network.compile(optimizer='adam',loss='binary_crossentropy',\n",
    "                                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Data set organization\n",
    "from tempfile import mkdtemp\n",
    "import os.path as path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Memoization \n",
    "file_corpora_train_x = path.join(mkdtemp(), 'alex-res_temp_corpora_train_x.dat') #Update per experiment\n",
    "file_corpora_test_x = path.join(mkdtemp(), 'alex-res_temp_corpora_test_x.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Shaping\n",
    "shape_train_x = (len(corpora_train),max_len_sentences,embeddigs_cols,1)\n",
    "shape_test_x = (len(corpora_test),max_len_sentences,embeddigs_cols,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Data sets\n",
    "corpora_train_x = np.memmap(\n",
    "        filename = file_corpora_train_x, \n",
    "        dtype='float32', \n",
    "        mode='w+', \n",
    "        shape = shape_train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpora_test_x = np.memmap( #Test Corpora (for future evaluation)\n",
    "        filename = file_corpora_test_x, \n",
    "        dtype='float32', \n",
    "        mode='w+', \n",
    "        shape = shape_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_train_y = np.array(target_train) #Train Target\n",
    "target_test_y = np.array(target_test) #Test Target (for future evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9308, 13789, 100, 1)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpora_train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9308, 2)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1030, 13789, 100, 1)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpora_test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1030, 2)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reshaping Train Inputs\n",
    "for doc in range(len(corpora_train)):\n",
    "    #print(corpora_train[doc].shape[1])\n",
    "    for words_rows in range(corpora_train[doc].shape[0]):\n",
    "        embed_flatten = np.array(corpora_train[doc][words_rows]).flatten() #<--- Capture doc and word\n",
    "        for embedding_cols in range(embed_flatten.shape[0]):\n",
    "            corpora_train_x[doc,words_rows,embedding_cols,0] = embed_flatten[embedding_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reshaping Test Inputs (for future evaluation)\n",
    "for doc in range(len(corpora_test)):\n",
    "    for words_rows in range(corpora_test[doc].shape[0]):\n",
    "        embed_flatten = np.array(corpora_test[doc][words_rows]).flatten() #<--- Capture doc and word\n",
    "        for embedding_cols in range(embed_flatten.shape[0]):\n",
    "            corpora_test_x[doc,words_rows,embedding_cols,0] = embed_flatten[embedding_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#CheckPoints\n",
    "#csv_logger = CSVLogger(system+'_training.log')\n",
    "filepath = \"alex-res/embeds100-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath)\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7446 samples, validate on 1862 samples\n",
      "Epoch 1/15\n",
      "3744/7446 [==============>...............] - ETA: 1:19:36 - loss: 0.7026 - accuracy: 0.5433"
     ]
    }
   ],
   "source": [
    "#Model Fitting\n",
    "history = criticality_network.fit(\n",
    "            x = corpora_train_x, \n",
    "            y = target_train_y,\n",
    "            #batch_size=64,\n",
    "            epochs=15, #5 <------ Hyperparameter\n",
    "            validation_split = 0.2,\n",
    "            callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Saving Training History\n",
    "df_history = pd.DataFrame.from_dict(history.history)\n",
    "df_history.to_csv('C-res/history_training.csv', encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_history.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Saving Test Data\n",
    "np.save('C-res/corpora_test_x.npy',corpora_test_x)\n",
    "np.save('C-res/target_test_y.npy',target_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Evaluation\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    " \n",
    "epochs2 = range(len(acc))\n",
    " \n",
    "plt.plot(epochs2, acc, 'b', label='Training')\n",
    "plt.plot(epochs2, val_acc, 'r', label='Validation')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    " \n",
    "plt.figure()\n",
    " \n",
    "plt.plot(epochs2, loss, 'b', label='Training')\n",
    "plt.plot(epochs2, val_loss, 'r', label='Validation')\n",
    "plt.title('Training and validation loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
