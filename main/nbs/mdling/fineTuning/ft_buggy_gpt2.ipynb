{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Easily export jupyter cells to python module\n",
    "https://github.com/fastai/course-v3/blob/master/nbs/dl2/notebook2script.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python /tf/src/scripts/notebook2script.py ft_buggy_gpt2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from exp.nb_embedding import generate_embeddings_from_files, generate_embeddings_from_list, generate_embeddings_from_text_files\n",
    "from exp.nb_finetuning import *\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /tf/src/data/gpt-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run once (should be saving features to pickle for later use)\n",
    "x_trn = generate_embeddings_from_text_files(\n",
    "    \"/tf/src/data/gpt-2/checkpoint/m1\",\n",
    "    [\"/tf/src/data/datasets/train/fixed.txt\", \"/tf/src/data/datasets/train/buggy.txt\"],\n",
    "    \"/tf/src/data/embeddings/trn_buggy_m1.dat\",\n",
    "#     samples = 93360,\n",
    "    MAX_CHUNK = 256 \n",
    ")\n",
    "\n",
    "len(x_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run once (should be saving features to pickle for later use)\n",
    "x_val = generate_embeddings_from_text_files(\n",
    "    \"/tf/src/data/gpt-2/checkpoint/m1\",\n",
    "    [\"/tf/src/data/datasets/eval/fixed.txt\", \"/tf/src/data/datasets/eval/buggy.txt\"],\n",
    "    \"/tf/src/data/embeddings/val_buggy_m1.dat\",\n",
    "#     samples = 11670,\n",
    "    MAX_CHUNK = 256\n",
    ")\n",
    "\n",
    "len(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run once (should be saving features to pickle for later use)\n",
    "x_tst = generate_embeddings_from_text_files(\n",
    "    \"/tf/src/data/gpt-2/checkpoint/m1\",\n",
    "    [\"/tf/src/data/datasets/test/fixed.txt\", \"/tf/src/data/datasets/test/buggy.txt\"],\n",
    "    \"/tf/src/data/embeddings/tst_buggy_m1.dat\",\n",
    "#     samples = 11670,\n",
    "    MAX_CHUNK = 256\n",
    ")\n",
    "\n",
    "len(x_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trn = np.asarray(x_trn)[None, :, :]\n",
    "x_val = np.asarray(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trn.shape, x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_path = \"/tf/src/data/embeddings/trn_buggy_gpt-2.pickle\"\n",
    "with open(pickle_path, 'wb') as f:\n",
    "    pickle.dump(x_trn, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_path = \"/tf/src/data/embeddings/trn_buggy_gpt-2.pickle\"\n",
    "with open(pickle_path, 'rb') as f:\n",
    "    x_trn = pickle.load(f)\n",
    "    \n",
    "x_trn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_path = \"/tf/src/data/embeddings/val_buggy_gpt-2.pickle\"\n",
    "with open(pickle_path, 'wb') as f:\n",
    "    pickle.dump(x_val, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_path = \"/tf/src/data/embeddings/val_buggy_gpt-2.pickle\"\n",
    "with open(pickle_path, 'rb') as f:\n",
    "    x_val = pickle.load(f)\n",
    "    \n",
    "x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_path = \"/tf/src/data/embeddings/tst_buggy_gpt-2.pickle\"\n",
    "with open(pickle_path, 'wb') as f:\n",
    "    pickle.dump(x_tst, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load back in data\n",
    "shape = (93360, 256, 768)\n",
    "x_trn = np.memmap(\"/tf/src/data/embeddings/trn_buggy_m4.dat\", dtype='float32', mode='r', shape = shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "shape = (101947, 256, 768)\n",
    "x_trn = np.memmap(\"/tf/src/data/embeddings/trn_vulnerability_m4.dat\", dtype='float32', mode='r', shape = shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_trn.shape, x_trn[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load back in data\n",
    "shape = (11670, 256, 768)\n",
    "x_val = np.memmap(\"/tf/src/data/embeddings/val_buggy_m4.dat\", dtype='float32', mode='r', shape = shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load back in data\n",
    "shape = (11670, 256, 768)\n",
    "x_tst = np.memmap(\"/tf/src/data/embeddings/tst_buggy_m4.dat\", dtype='float32', mode='r', shape = shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_trn = prepare_dataset(pickle_path)\n",
    "a = np.zeros((46680,), dtype=int, order='C') # fixed\n",
    "b = np.ones((46680,), dtype=int, order='C')  # buggy\n",
    "y_trn = to_categorical(np.append(a, b))\n",
    "x_trn.shape, y_trn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros((5835,), dtype=int, order='C') # fixed\n",
    "b = np.ones((5835,), dtype=int, order='C')  # buggy\n",
    "y_val = to_categorical(np.append(a, b))\n",
    "x_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros((5835,), dtype=int, order='C') # fixed\n",
    "b = np.ones((5835,), dtype=int, order='C')  # buggy\n",
    "y_tst = to_categorical(np.append(a, b))\n",
    "x_tst.shape, y_tst.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! curl -X POST -H 'Content-type: application/json' --data '{\"text\":\"from: semeru tower 2\\nstatus: embeddings finished\"}' https://hooks.slack.com/services/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"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "#     tf.keras.callbacks.EarlyStopping(\n",
    "#         # Stop training when `val_loss` is no longer improving\n",
    "#         monitor='val_loss',\n",
    "#         # \"no longer improving\" being defined as \"no better than 1e-2 less\"\n",
    "#         min_delta=1e-2,\n",
    "#         # \"no longer improving\" being further defined as \"for at least 2 epochs\"\n",
    "#         patience=2,\n",
    "#         verbose=1\n",
    "#     ),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath='/tf/src/data/checkpoints/ft_buggy_m1_{epoch}.h5',\n",
    "        # Path where to save the model\n",
    "        # The two parameters below mean that we will overwrite\n",
    "        # the current checkpoint if and only if\n",
    "        # the `val_loss` score has improved.\n",
    "        save_best_only=True,\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        verbose=1\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def get_class_weights(y):\n",
    "    counter = Counter(y)\n",
    "    majority = max(counter.values())\n",
    "    return  {cls: round(float(majority)/float(count), 2) for cls, count in counter.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = get_class_weights(np.argmax(y_trn, axis=1))\n",
    "class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = get_model(x_trn[0].shape)\n",
    "history = finetune_model(x_trn, y_trn, x_val, y_val, model, callbacks = callbacks, class_weight = class_weight, epochs = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! curl -X POST -H 'Content-type: application/json' --data '{\"text\":\"from: semeru tower 2\\nstatus: m1 finetuning finished\"}' https://hooks.slack.com/services/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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_history = pd.DataFrame.from_dict(history.history)\n",
    "df_history.to_csv('/tf/src/data/checkpoints/history_training_m1_security.csv', encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_path = \"/tf/src/data/checkpoints/history_buggy_m1.pickle\"\n",
    "with open(pickle_path, 'wb') as f:\n",
    "    pickle.dump(history.history, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_path = \"/tf/src/data/checkpoints/history_buggy_m1.pickle\"\n",
    "with open(pickle_path, 'rb') as f:\n",
    "    history = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
