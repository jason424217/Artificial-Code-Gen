{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Easily export jupyter cells to python module\n",
    "https://github.com/fastai/course-v3/blob/master/nbs/dl2/notebook2script.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python /tf/src/scripts/notebook2script.py embedding.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0-beta1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#export\n",
    "from new_model import *\n",
    "from encoder import get_encoder\n",
    "import math\n",
    "import tqdm\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/src/data/gpt-2\n"
     ]
    }
   ],
   "source": [
    "cd /tf/src/data/gpt-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python3 download_model.py 117M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def top_k_logits(logits, k):\n",
    "    if k == 0:\n",
    "        # no truncation\n",
    "        return logits\n",
    "\n",
    "    def _top_k():\n",
    "        values, _ = tf.nn.top_k(logits, k=k)\n",
    "        min_values = values[:, -1, tf.newaxis]\n",
    "        return tf.compat.v1.where(\n",
    "            logits < min_values,\n",
    "            tf.ones_like(logits, dtype=logits.dtype) * -1e10,\n",
    "            logits,\n",
    "        )\n",
    "    return tf.cond(\n",
    "       pred=tf.equal(k, 0),\n",
    "       true_fn=lambda: logits,\n",
    "       false_fn=lambda: _top_k(),\n",
    "    )\n",
    "\n",
    "\n",
    "def sample_sequence(*, hparams, length, start_token=None, batch_size=None, context=None, past=None, temperature=1, top_k=0):\n",
    "    if start_token is None:\n",
    "        assert context is not None, 'Specify exactly one of start_token and context!'\n",
    "    else:\n",
    "        assert context is None, 'Specify exactly one of start_token and context!'\n",
    "        context = tf.fill([batch_size, 1], start_token)\n",
    "\n",
    "    def step(hparams, tokens, past=None):\n",
    "        lm_output = model(hparams=hparams, X=tokens, past=past, reuse=tf.compat.v1.AUTO_REUSE)\n",
    "\n",
    "        logits = lm_output['logits'][:, :, :hparams.n_vocab]\n",
    "        presents = lm_output['present']\n",
    "        presents.set_shape(past_shape(hparams=hparams, batch_size=batch_size))\n",
    "        return {\n",
    "            'logits': logits,\n",
    "            'presents': presents,\n",
    "            'hidden_state': lm_output['hidden_state'],\n",
    "            'clf_h': lm_output['clf_h'],\n",
    "            'clf_logits': lm_output['clf_logits']\n",
    "        }\n",
    "\n",
    "    def body(past, prev, output, embedding):\n",
    "        next_outputs = step(hparams, prev, past=past)\n",
    "        logits = next_outputs['logits'][:, -1, :]  / tf.cast(temperature, dtype=tf.float32)\n",
    "        logits = top_k_logits(logits, k=top_k)\n",
    "        samples = tf.random.categorical(logits=logits, num_samples=1, dtype=tf.int32)\n",
    "        return [\n",
    "            next_outputs['presents'] if past is None else tf.concat([past, next_outputs['presents']], axis=-2),\n",
    "            samples,\n",
    "            tf.concat([output, samples], axis=1),\n",
    "            next_outputs['hidden_state'],\n",
    "            next_outputs['clf_h'],\n",
    "            next_outputs['clf_logits']\n",
    "        ]\n",
    "\n",
    "    past, prev, output, h, clf_h, clf_logits = body(past, context, context, context)\n",
    "\n",
    "    def cond(*args):\n",
    "        return True\n",
    "\n",
    "    return output, h, clf_h, clf_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Embedder:\n",
    "    def __init__(self, chkpt_path, chunk_size):\n",
    "        tf.compat.v1.disable_eager_execution()\n",
    "        self.g = tf.Graph()\n",
    "        with self.g.as_default():\n",
    "            self.context = tf.compat.v1.placeholder(tf.int32, [1, None])\n",
    "\n",
    "        self.sess = tf.compat.v1.Session(graph=self.g)\n",
    "    \n",
    "        self.MAX_CHUNK = chunk_size\n",
    "        self.enc = get_encoder(\"117M\", \"models\")\n",
    "        hparams = default_hparams()\n",
    "        with self.g.as_default():\n",
    "            self.output, self.hidden_state, self.clf_h, self.clf_logits = sample_sequence(\n",
    "                hparams=hparams, length=None,\n",
    "                context=self.context,\n",
    "                past=None,\n",
    "                batch_size=1,\n",
    "                temperature=1, top_k=1\n",
    "            )\n",
    "        \n",
    "        if chkpt_path is not None:\n",
    "            self.restore(chkpt_path)\n",
    "            \n",
    "    def restore(self, chkpt_path):\n",
    "        with self.g.as_default():\n",
    "            saver = tf.compat.v1.train.Saver()\n",
    "            chkpt = tf.train.latest_checkpoint(chkpt_path)\n",
    "            saver.restore(self.sess, chkpt)\n",
    "        \n",
    "    def __call__(self, method):\n",
    "        with self.g.as_default():\n",
    "            enc_meth = self.enc.encode(method)\n",
    "            context_tokens = enc_meth[:self.MAX_CHUNK]\n",
    "\n",
    "            _, h, clf_h, clf_logits = self.sess.run([self.output, self.hidden_state, self.clf_h, self.clf_logits], feed_dict={\n",
    "                self.context: [context_tokens]\n",
    "            }, options = tf.compat.v1.RunOptions(report_tensor_allocations_upon_oom = True))\n",
    "                        \n",
    "#             for tok in enc_meth[self.MAX_CHUNK:]:\n",
    "#                 context_tokens.append(tok)\n",
    "#                 context_tokens.pop(0)\n",
    "                \n",
    "#                 _, h_ = self.sess.run([self.output, self.hidden_state], feed_dict={\n",
    "#                     self.context: [context_tokens]\n",
    "#                 }, options = tf.compat.v1.RunOptions(report_tensor_allocations_upon_oom = True))\n",
    "#                 h = np.append(h, h_[None, :, -1], axis = 1)\n",
    "\n",
    "            print(clf_h.shape, clf_logits.shape)\n",
    "\n",
    "            return h #np.squeeze(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[[1, 2, 3], [1, 2, 3]]])\n",
    "b = np.array([[[1, 2, 4], [4, 5, 6]]])\n",
    "# b = b[None, :, -1]\n",
    "# b[None, :, -1].shape\n",
    "# b.shape\n",
    "a = np.append(a, b[None, :, -1], axis = 1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def generate_embeddings_from_files(chkpt_path, ds_path, samples = None, MAX_CHUNK = 1024):\n",
    "    embd = Embedder(chkpt_path, MAX_CHUNK)\n",
    "    features = []\n",
    "    for i, fname in enumerate(tqdm.tqdm(os.listdir(ds_path))):\n",
    "        if samples is not None:\n",
    "            if i >= samples: break\n",
    "        \n",
    "        with open(os.path.join(ds_path, fname)) as f:\n",
    "            method = f.read()\n",
    "            features.append(embd(method)) #np.sum(embd(method), axis = 0)\n",
    "            \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def generate_embeddings_from_list(chkpt_path, methods, out_path, samples = None, MAX_CHUNK = 1024):\n",
    "    embd = Embedder(chkpt_path, MAX_CHUNK)\n",
    "    shape = (len(methods), MAX_CHUNK, 768)\n",
    "    if samples is not None:\n",
    "        shape = (samples, MAX_CHUNK, 768)\n",
    "    \n",
    "    features = np.memmap(out_path, dtype='float32', mode='w+', shape = shape)\n",
    "    for i, method in enumerate(tqdm.tqdm(methods)):\n",
    "        if samples is not None:\n",
    "            if i >= samples: break\n",
    "                \n",
    "        features[i] = np.squeeze(\n",
    "            tf.keras.preprocessing.sequence.pad_sequences(embd(method), MAX_CHUNK, dtype='float32', padding='post')\n",
    "        )\n",
    "            #np.sum(embd(method), axis = 0)\n",
    "            \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# Generates embeddings from multiple text files where each method\n",
    "# is on a different line in each file\n",
    "def generate_embeddings_from_text_files(chkpt_path, files, out_path, samples = None, MAX_CHUNK = 1024):\n",
    "    embd = Embedder(chkpt_path, MAX_CHUNK)\n",
    "#     shape = (len(methods), MAX_CHUNK, 768)\n",
    "    if samples is not None:\n",
    "        shape = (samples, MAX_CHUNK, 768)\n",
    "    \n",
    "    features = np.memmap(out_path, dtype='float32', mode='w+', shape = shape)\n",
    "    for _, file in enumerate(files):\n",
    "        with open(file) as f:\n",
    "            for i, method in enumerate(tqdm.tqdm(f.readlines())):\n",
    "                if samples is not None:\n",
    "                    if i >= samples: break\n",
    "                        \n",
    "                features[i] = np.squeeze(\n",
    "                    tf.keras.preprocessing.sequence.pad_sequences(embd(method), MAX_CHUNK, dtype='float32', padding='post')\n",
    "                ) #np.sum(embd(method), axis = 0)\n",
    "            \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = generate_embeddings(\"/tf/src/data/gpt-2/checkpoint/run1\",\n",
    "                               \"/tf/src/data/methods/DATA00M_[god-r]/test\",\n",
    "                               samples = 10\n",
    "                              )\n",
    "\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0814 21:41:50.652522 139688576931648 nn_ops.py:4220] Large dropout rate: 0.9 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "  0%|          | 0/121596 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "2 root error(s) found.\n  (0) Invalid argument: Input to reshape is a tensor with 137 values, but the requested shape requires a multiple of 2048\n\t [[node model/Reshape (defined at /tf/src/fineTuning/new_model.py:184) ]]\n\t [[model/Reshape_4/_45]]\n  (1) Invalid argument: Input to reshape is a tensor with 137 values, but the requested shape requires a multiple of 2048\n\t [[node model/Reshape (defined at /tf/src/fineTuning/new_model.py:184) ]]\n0 successful operations.\n0 derived errors ignored.\n\nErrors may have originated from an input operation.\nInput Source operations connected to node model/Reshape:\n Placeholder (defined at <ipython-input-7-a4cf76f8252f>:7)\n\nInput Source operations connected to node model/Reshape:\n Placeholder (defined at <ipython-input-7-a4cf76f8252f>:7)\n\nOriginal stack trace for 'model/Reshape':\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 781, in inner\n    self.run()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-10-d1e91cd04ef5>\", line 1, in <module>\n    embd = Embedder(None, 1024)\n  File \"<ipython-input-7-a4cf76f8252f>\", line 20, in __init__\n    temperature=1, top_k=1\n  File \"<ipython-input-6-fb43dc412a3f>\", line 57, in sample_sequence\n    past, prev, output, h, clf_h, clf_logits = body(past, context, context, context)\n  File \"<ipython-input-6-fb43dc412a3f>\", line 44, in body\n    next_outputs = step(hparams, prev, past=past)\n  File \"<ipython-input-6-fb43dc412a3f>\", line 30, in step\n    lm_output = model(hparams=hparams, X=tokens, past=past, reuse=tf.compat.v1.AUTO_REUSE)\n  File \"/tf/src/fineTuning/new_model.py\", line 184, in model\n    X = tf.reshape(X, [-1, hparams.n_ctx, 2])\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 7715, in reshape\n    \"Reshape\", tensor=tensor, shape=shape, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3296, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1692, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) Invalid argument: Input to reshape is a tensor with 137 values, but the requested shape requires a multiple of 2048\n\t [[{{node model/Reshape}}]]\n\t [[model/Reshape_4/_45]]\n  (1) Invalid argument: Input to reshape is a tensor with 137 values, but the requested shape requires a multiple of 2048\n\t [[{{node model/Reshape}}]]\n0 successful operations.\n0 derived errors ignored.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-d1e91cd04ef5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Feature {i} dims:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-a4cf76f8252f>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, method)\u001b[0m\n\u001b[1;32m     37\u001b[0m             _, h, clf_h, clf_logits = self.sess.run([self.output, self.hidden_state, self.clf_h, self.clf_logits], feed_dict={\n\u001b[1;32m     38\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcontext_tokens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             }, options = tf.compat.v1.RunOptions(report_tensor_allocations_upon_oom = True))\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m#             for tok in enc_meth[self.MAX_CHUNK:]:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1368\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) Invalid argument: Input to reshape is a tensor with 137 values, but the requested shape requires a multiple of 2048\n\t [[node model/Reshape (defined at /tf/src/fineTuning/new_model.py:184) ]]\n\t [[model/Reshape_4/_45]]\n  (1) Invalid argument: Input to reshape is a tensor with 137 values, but the requested shape requires a multiple of 2048\n\t [[node model/Reshape (defined at /tf/src/fineTuning/new_model.py:184) ]]\n0 successful operations.\n0 derived errors ignored.\n\nErrors may have originated from an input operation.\nInput Source operations connected to node model/Reshape:\n Placeholder (defined at <ipython-input-7-a4cf76f8252f>:7)\n\nInput Source operations connected to node model/Reshape:\n Placeholder (defined at <ipython-input-7-a4cf76f8252f>:7)\n\nOriginal stack trace for 'model/Reshape':\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 781, in inner\n    self.run()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-10-d1e91cd04ef5>\", line 1, in <module>\n    embd = Embedder(None, 1024)\n  File \"<ipython-input-7-a4cf76f8252f>\", line 20, in __init__\n    temperature=1, top_k=1\n  File \"<ipython-input-6-fb43dc412a3f>\", line 57, in sample_sequence\n    past, prev, output, h, clf_h, clf_logits = body(past, context, context, context)\n  File \"<ipython-input-6-fb43dc412a3f>\", line 44, in body\n    next_outputs = step(hparams, prev, past=past)\n  File \"<ipython-input-6-fb43dc412a3f>\", line 30, in step\n    lm_output = model(hparams=hparams, X=tokens, past=past, reuse=tf.compat.v1.AUTO_REUSE)\n  File \"/tf/src/fineTuning/new_model.py\", line 184, in model\n    X = tf.reshape(X, [-1, hparams.n_ctx, 2])\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 7715, in reshape\n    \"Reshape\", tensor=tensor, shape=shape, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3296, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1692, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "embd = Embedder(None, 1024)\n",
    "path = \"/tf/src/data/methods/DATA00M_[god-r]/test\"\n",
    "\n",
    "features = {}\n",
    "for i, fname in enumerate(tqdm.tqdm(os.listdir(path))):\n",
    "#     if i => 10000: break\n",
    "    with open(os.path.join(path, fname)) as f:\n",
    "        method = f.read()\n",
    "        features[method] = embd(method)\n",
    "        print(f\"Feature {i} dims:\", features[method].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API look\n",
    "def cross_entropy(ds, chkpt_path, MAX_CHUNK = 1024, bs = 1):\n",
    "    # Generate permutations (TODO)\n",
    "    \n",
    "    \n",
    "    with tf.compat.v1.Session(graph=tf.Graph()) as sess:\n",
    "        context = tf.compat.v1.placeholder(tf.int32, [bs, None])\n",
    "        # Generate predictions of model\n",
    "        output  = model(hparams=default_hparams(), X=context)\n",
    "        # Calculate cross entropy using tf library\n",
    "        loss1    = tf.reduce_mean(\n",
    "            input_tensor = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                labels = context[:, 1:], logits = output['logits'][:, :-1]\n",
    "            )\n",
    "        )\n",
    "        loss2    = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            labels = context[:, 1:], logits = output['logits'][:, :-1]\n",
    "        )\n",
    "        \n",
    "        # Load model\n",
    "        saver = tf.compat.v1.train.Saver()\n",
    "        ckpt = tf.train.latest_checkpoint(chkpt_path)\n",
    "        saver.restore(sess, ckpt)\n",
    "    \n",
    "        # For each method:\n",
    "        entropy = []\n",
    "        for method in tqdm.tqdm(ds):\n",
    "            enc_meth    = enc.encode(method)\n",
    "            \n",
    "            context_tokens = enc_meth[:MAX_CHUNK]\n",
    "            val = sess.run(loss1, feed_dict={context: [context_tokens]})\n",
    "            if not math.isnan(val):\n",
    "                entropy.append(val)\n",
    "#             for i in range(len(enc_meth) % MAX_CHUNK):\n",
    "#                 context_tokens = enc_meth[MAX_CHUNK * i:MAX_CHUNK * (i + 1)]\n",
    "#                 print(len(tok))\n",
    "            for tok in enc_meth[MAX_CHUNK:]:\n",
    "                context_tokens.append(tok)\n",
    "                context_tokens.pop(0)\n",
    "    \n",
    "#                 # Need to recalculate this because this is not correct way (I think)\n",
    "                val = sess.run(loss2, feed_dict={context: [context_tokens]})\n",
    "                if not math.isnan(val[:, -1]):\n",
    "                    entropy.append(val[:, -1])\n",
    "        \n",
    "        return entropy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
