{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 49608,
     "status": "ok",
     "timestamp": 1562072209393,
     "user": {
      "displayName": "Nathan Cooper",
      "photoUrl": "",
      "userId": "15284233239426922637"
     },
     "user_tz": 300
    },
    "id": "NMSgqfI2O6qD",
    "outputId": "61ecf8c3-1a92-4bfc-cbc1-d8a9a740db98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-gpu==2.0.0beta1 in /usr/local/lib/python3.6/dist-packages (2.0.0b1)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorflow-gpu==2.0.0beta1) (0.30.0)\n",
      "Requirement already satisfied: tb-nightly<1.14.0a20190604,>=1.14.0a20190603 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0beta1) (1.14.0a20190603)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0beta1) (1.0.8)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0beta1) (1.21.1)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0beta1) (3.8.0)\n",
      "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0beta1) (1.14.0.dev2019060501)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0beta1) (1.11.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0beta1) (0.1.7)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0beta1) (1.1.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0beta1) (0.8.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0beta1) (0.7.1)\n",
      "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0beta1) (0.2.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0beta1) (1.16.4)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/lib/python3/dist-packages (from tensorflow-gpu==2.0.0beta1) (1.11.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0beta1) (1.1.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu==2.0.0beta1) (0.15.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu==2.0.0beta1) (3.1.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu==2.0.0beta1) (41.0.1)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0beta1) (2.9.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-gpu==2.0.0beta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 48047,
     "status": "ok",
     "timestamp": 1562072214526,
     "user": {
      "displayName": "Nathan Cooper",
      "photoUrl": "",
      "userId": "15284233239426922637"
     },
     "user_tz": 300
    },
    "id": "2hVxx2VqR5oU",
    "outputId": "07f964f1-ac44-4d2c-a3d4-9bdf96c9c646"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'data/gpt-2'...\n",
      "remote: Enumerating objects: 319, done.\u001b[K\n",
      "remote: Total 319 (delta 0), reused 0 (delta 0), pack-reused 319\u001b[K\n",
      "Receiving objects: 100% (319/319), 4.40 MiB | 10.60 MiB/s, done.\n",
      "Resolving deltas: 100% (177/177), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ncoop57/gpt-2.git data/gpt-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 840,
     "status": "ok",
     "timestamp": 1562072276551,
     "user": {
      "displayName": "Nathan Cooper",
      "photoUrl": "",
      "userId": "15284233239426922637"
     },
     "user_tz": 300
    },
    "id": "NqSTZm5UR9NS",
    "outputId": "5afa5e70-35ca-48cf-b255-fa6d12694551"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/src/data/gpt-2\n"
     ]
    }
   ],
   "source": [
    "cd /tf/src/data/gpt-2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 19101,
     "status": "ok",
     "timestamp": 1562072297626,
     "user": {
      "displayName": "Nathan Cooper",
      "photoUrl": "",
      "userId": "15284233239426922637"
     },
     "user_tz": 300
    },
    "id": "_wONoY04SGgL",
    "outputId": "eccda4fe-0849-4d91-879f-edc5ceac48a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fire>=0.1.3 (from -r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/5a/b7/205702f348aab198baecd1d8344a90748cb68f53bdcd1cc30cbc08e47d3e/fire-0.1.3.tar.gz\n",
      "Collecting regex==2017.4.5 (from -r requirements.txt (line 2))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/62/c0c0d762ffd4ffaf39f372eb8561b8d491a11ace5a7884610424a8b40f95/regex-2017.04.05.tar.gz (601kB)\n",
      "\u001b[K     |████████████████████████████████| 604kB 7.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting requests==2.21.0 (from -r requirements.txt (line 3))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/e3/20f3d364d6c8e5d2353c72a67778eb189176f08e873c9900e10c0287b84b/requests-2.21.0-py2.py3-none-any.whl (57kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 10.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tqdm==4.31.1 (from -r requirements.txt (line 4))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/4b/c38b5144cf167c4f52288517436ccafefe9dc01b8d1c190e18a6b154cd4a/tqdm-4.31.1-py2.py3-none-any.whl (48kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 15.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting toposort==1.5 (from -r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/e9/8a/321cd8ea5f4a22a06e3ba30ef31ec33bea11a3443eeb1d89807640ee6ed4/toposort-1.5-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.11.0)\n",
      "Collecting certifi>=2017.4.17 (from requests==2.21.0->-r requirements.txt (line 3))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/1b/b853c7a9d4f6a6d00749e94eb6f3a041e342a885b87340b79c1ef73e3a78/certifi-2019.6.16-py2.py3-none-any.whl (157kB)\n",
      "\u001b[K     |████████████████████████████████| 163kB 11.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting chardet<3.1.0,>=3.0.2 (from requests==2.21.0->-r requirements.txt (line 3))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl (133kB)\n",
      "\u001b[K     |████████████████████████████████| 143kB 11.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: idna<2.9,>=2.5 in /usr/lib/python3/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (2.6)\n",
      "Collecting urllib3<1.25,>=1.21.1 (from requests==2.21.0->-r requirements.txt (line 3))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/01/11/525b02e4acc0c747de8b6ccdab376331597c569c42ea66ab0a1dbd36eca2/urllib3-1.24.3-py2.py3-none-any.whl (118kB)\n",
      "\u001b[K     |████████████████████████████████| 122kB 10.5MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: fire, regex\n",
      "  Building wheel for fire (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/2a/1a/4d/6b30377c3051e76559d1185c1dbbfff15aed31f87acdd14c22\n",
      "  Building wheel for regex (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/75/07/38/3c16b529d50cb4e0cd3dbc7b75cece8a09c132692c74450b01\n",
      "Successfully built fire regex\n",
      "Installing collected packages: fire, regex, certifi, chardet, urllib3, requests, tqdm, toposort\n",
      "Successfully installed certifi-2019.6.16 chardet-3.0.4 fire-0.1.3 regex-2017.4.5 requests-2.21.0 toposort-1.5 tqdm-4.31.1 urllib3-1.24.3\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 20276,
     "status": "ok",
     "timestamp": 1562072326898,
     "user": {
      "displayName": "Nathan Cooper",
      "photoUrl": "",
      "userId": "15284233239426922637"
     },
     "user_tz": 300
    },
    "id": "cUb_A5XDSSMo",
    "outputId": "bcaf3ce0-e0e8-4fa3-e2c4-0b076363acc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching checkpoint: 1.00kit [00:00, 985kit/s]                                                      \n",
      "Fetching encoder.json: 1.04Mit [00:00, 9.56Mit/s]                                                   \n",
      "Fetching hparams.json: 1.00kit [00:00, 714kit/s]                                                    \n",
      "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:43, 11.3Mit/s]                                  \n",
      "Fetching model.ckpt.index: 6.00kit [00:00, 2.83Mit/s]                                               \n",
      "Fetching model.ckpt.meta: 472kit [00:00, 7.97Mit/s]                                                 \n",
      "Fetching vocab.bpe: 457kit [00:00, 7.79Mit/s]                                                       \n"
     ]
    }
   ],
   "source": [
    "!python3 download_model.py 117M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2956,
     "status": "ok",
     "timestamp": 1561477302856,
     "user": {
      "displayName": "Nathan Cooper",
      "photoUrl": "",
      "userId": "15284233239426922637"
     },
     "user_tz": 300
    },
    "id": "BcedMCyqEuEi",
    "outputId": "ff2fdefd-c55f-4266-c9dc-46c36efa34c5"
   },
   "outputs": [],
   "source": [
    "!mkdir data\n",
    "!wget -O data/training.txt https://raw.githubusercontent.com/micheletufano/NeuralCodeTranslator/master/dataset/bug-fixes/medium/train/fixed.txt # http://groups.inf.ed.ac.uk/cup/javaGithub/java_projects.tar.gz\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uw2-89BESWJf"
   },
   "outputs": [],
   "source": [
    "# cd src/\n",
    "!ls src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nlNlHpbaSoZE"
   },
   "outputs": [],
   "source": [
    "!tf_upgrade_v2 --infile src/encoder.py --outfile src/encoder-upgraded.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RJcMVMykTKG-"
   },
   "outputs": [],
   "source": [
    "!cat src/encoder-upgraded.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WgX_5X_eSyqs"
   },
   "outputs": [],
   "source": [
    "!tf_upgrade_v2 --infile src/sample.py --outfile src/sample-upgraded.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qsarJnTCTkK4"
   },
   "outputs": [],
   "source": [
    "!cat src/sample-upgraded.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kGP25lSdSYym"
   },
   "outputs": [],
   "source": [
    "!tf_upgrade_v2 --infile src/interactive_conditional_samples.py --outfile src/interactive_conditional_samples-upgraded.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "erJLtcmxT_JG"
   },
   "outputs": [],
   "source": [
    "!cat src/interactive_conditional_samples-upgraded.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QGAxkZc7PHXm"
   },
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/openai/gpt-2/master/src/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mECUPMcaPMT0"
   },
   "outputs": [],
   "source": [
    "!tf_upgrade_v2 --infile model.py --outfile model-upgraded.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "85v_NYB7PdD5"
   },
   "outputs": [],
   "source": [
    "!cat model-upgraded.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OpMlEBBopVo6"
   },
   "outputs": [],
   "source": [
    "!tf_upgrade_v2 --infile src/load_dataset.py --outfile src/load_dataset-upgraded.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U97oeafJpgt_"
   },
   "outputs": [],
   "source": [
    "!cat src/load_dataset-upgraded.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kIYLKMMgrlmM"
   },
   "outputs": [],
   "source": [
    "!tf_upgrade_v2 --infile src/memory_saving_gradients.py --outfile src/memory_saving_gradients-upgraded.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wTAe3JvFrxO1"
   },
   "outputs": [],
   "source": [
    "!cat src/memory_saving_gradients-upgraded.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fu6Ati-RqJve"
   },
   "outputs": [],
   "source": [
    "!tf_upgrade_v2 --infile train.py --outfile train-upgraded.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vbh_LpHcqSdo"
   },
   "outputs": [],
   "source": [
    "!cat train-upgraded.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 48335,
     "status": "ok",
     "timestamp": 1562072360913,
     "user": {
      "displayName": "Nathan Cooper",
      "photoUrl": "",
      "userId": "15284233239426922637"
     },
     "user_tz": 300
    },
    "id": "eOL0HxJeVZfJ",
    "outputId": "4f814ef4-8315-4e60-b06a-694ea7287337"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 39060,
     "status": "ok",
     "timestamp": 1562037012301,
     "user": {
      "displayName": "Nathan Cooper",
      "photoUrl": "",
      "userId": "15284233239426922637"
     },
     "user_tz": 300
    },
    "id": "3cXwFF3AVaR9",
    "outputId": "fa40ceb9-837e-4c76-be61-2a111625d0b4"
   },
   "outputs": [],
   "source": [
    "! mkdir data\n",
    "! cp -r /content/drive/My\\ Drive/data/ /content/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pDEu7UP4Vcje"
   },
   "outputs": [],
   "source": [
    "! unzip -qq /content/data//bug-fixes-methods.zip &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12749482,
     "status": "ok",
     "timestamp": 1562017852274,
     "user": {
      "displayName": "Nathan Cooper",
      "photoUrl": "",
      "userId": "15284233239426922637"
     },
     "user_tz": 300
    },
    "id": "BZV54GVfbG9c",
    "outputId": "d3bfb963-e260-40c2-bb45-ab9eaeb97d09"
   },
   "outputs": [],
   "source": [
    "! cp -r sciclone /content/drive/My\\ Drive/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2219,
     "status": "ok",
     "timestamp": 1562072364186,
     "user": {
      "displayName": "Nathan Cooper",
      "photoUrl": "",
      "userId": "15284233239426922637"
     },
     "user_tz": 300
    },
    "id": "v-FFfIovWj1P",
    "outputId": "9e48829f-e15d-4adb-96d8-0d91a34c4fd6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0-beta1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fire\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import regex as re\n",
    "from functools import lru_cache\n",
    "import argparse\n",
    "import time\n",
    "import tqdm\n",
    "from tensorflow.core.protobuf import rewriter_config_pb2\n",
    "import glob\n",
    "\n",
    "# from accumulate import AccumulatingOptimizer\n",
    "# import memory_saving_gradients\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZxEBhbrwUnzY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fire>=0.1.3 (from -r /tf/src/data/gpt-2/requirements.txt (line 1))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/69/faeaae8687f4de0f5973694d02e9d6c3eb827636a009157352d98de1129e/fire-0.2.1.tar.gz (76kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 3.6MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting regex==2017.4.5 (from -r /tf/src/data/gpt-2/requirements.txt (line 2))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/62/c0c0d762ffd4ffaf39f372eb8561b8d491a11ace5a7884610424a8b40f95/regex-2017.04.05.tar.gz (601kB)\n",
      "\u001b[K     |████████████████████████████████| 604kB 10.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting requests==2.21.0 (from -r /tf/src/data/gpt-2/requirements.txt (line 3))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/e3/20f3d364d6c8e5d2353c72a67778eb189176f08e873c9900e10c0287b84b/requests-2.21.0-py2.py3-none-any.whl (57kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 14.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tqdm==4.31.1 (from -r /tf/src/data/gpt-2/requirements.txt (line 4))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/4b/c38b5144cf167c4f52288517436ccafefe9dc01b8d1c190e18a6b154cd4a/tqdm-4.31.1-py2.py3-none-any.whl (48kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 15.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting toposort==1.5 (from -r /tf/src/data/gpt-2/requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/e9/8a/321cd8ea5f4a22a06e3ba30ef31ec33bea11a3443eeb1d89807640ee6ed4/toposort-1.5-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from fire>=0.1.3->-r /tf/src/data/gpt-2/requirements.txt (line 1)) (1.11.0)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from fire>=0.1.3->-r /tf/src/data/gpt-2/requirements.txt (line 1)) (1.1.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/lib/python3/dist-packages (from requests==2.21.0->-r /tf/src/data/gpt-2/requirements.txt (line 3)) (2.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r /tf/src/data/gpt-2/requirements.txt (line 3)) (2019.6.16)\n",
      "Collecting urllib3<1.25,>=1.21.1 (from requests==2.21.0->-r /tf/src/data/gpt-2/requirements.txt (line 3))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/01/11/525b02e4acc0c747de8b6ccdab376331597c569c42ea66ab0a1dbd36eca2/urllib3-1.24.3-py2.py3-none-any.whl (118kB)\n",
      "\u001b[K     |████████████████████████████████| 122kB 13.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r /tf/src/data/gpt-2/requirements.txt (line 3)) (3.0.4)\n",
      "Building wheels for collected packages: fire, regex\n",
      "  Building wheel for fire (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/31/9c/c0/07b6dc7faf1844bb4688f46b569efe6cafaa2179c95db821da\n",
      "  Building wheel for regex (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/75/07/38/3c16b529d50cb4e0cd3dbc7b75cece8a09c132692c74450b01\n",
      "Successfully built fire regex\n",
      "Installing collected packages: fire, regex, urllib3, requests, tqdm, toposort\n",
      "  Found existing installation: urllib3 1.25.3\n",
      "    Uninstalling urllib3-1.25.3:\n",
      "      Successfully uninstalled urllib3-1.25.3\n",
      "  Found existing installation: requests 2.22.0\n",
      "    Uninstalling requests-2.22.0:\n",
      "      Successfully uninstalled requests-2.22.0\n",
      "  Found existing installation: tqdm 4.34.0\n",
      "    Uninstalling tqdm-4.34.0:\n",
      "      Successfully uninstalled tqdm-4.34.0\n",
      "Successfully installed fire-0.2.1 regex-2017.4.5 requests-2.21.0 toposort-1.5 tqdm-4.31.1 urllib3-1.24.3\n",
      "\u001b[33mWARNING: You are using pip version 19.1.1, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install -r /tf/src/data/gpt-2/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eib-CYeS36mL"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 470,
     "status": "ok",
     "timestamp": 1561755454833,
     "user": {
      "displayName": "Nathan Cooper",
      "photoUrl": "",
      "userId": "15284233239426922637"
     },
     "user_tz": 300
    },
    "id": "VJoGi-y139H4",
    "outputId": "5777b32c-8310-47ea-9e8f-f24f82131d28"
   },
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "  return mask  # (seq_len, seq_len)\n",
    "# def create_look_ahead_mask(size):\n",
    "#   mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "#   return mask\n",
    "\n",
    "x = tf.random.uniform((1, 3))\n",
    "temp = create_look_ahead_mask(x.shape[1])\n",
    "temp * -1e9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bQ3d7jgiXVFR"
   },
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aO819gXNXG9-"
   },
   "outputs": [],
   "source": [
    "\"\"\"Byte pair encoding utilities\"\"\"\n",
    "\n",
    "\n",
    "@lru_cache()\n",
    "def bytes_to_unicode():\n",
    "    \"\"\"\n",
    "    Returns list of utf-8 byte and a corresponding list of unicode strings.\n",
    "    The reversible bpe codes work on unicode strings.\n",
    "    This means you need a large # of unicode characters in your vocab if you want to avoid UNKs.\n",
    "    When you're at something like a 10B token dataset you end up needing around 5K for decent coverage.\n",
    "    This is a signficant percentage of your normal, say, 32K bpe vocab.\n",
    "    To avoid that, we want lookup tables between utf-8 bytes and unicode strings.\n",
    "    And avoids mapping to whitespace/control characters the bpe code barfs on.\n",
    "    \"\"\"\n",
    "    bs = list(range(ord(\"!\"), ord(\"~\")+1))+list(range(ord(\"¡\"), ord(\"¬\")+1))+list(range(ord(\"®\"), ord(\"ÿ\")+1))\n",
    "    cs = bs[:]\n",
    "    n = 0\n",
    "    for b in range(2**8):\n",
    "        if b not in bs:\n",
    "            bs.append(b)\n",
    "            cs.append(2**8+n)\n",
    "            n += 1\n",
    "    cs = [chr(n) for n in cs]\n",
    "    return dict(zip(bs, cs))\n",
    "\n",
    "def get_pairs(word):\n",
    "    \"\"\"Return set of symbol pairs in a word.\n",
    "\n",
    "    Word is represented as tuple of symbols (symbols being variable-length strings).\n",
    "    \"\"\"\n",
    "    pairs = set()\n",
    "    prev_char = word[0]\n",
    "    for char in word[1:]:\n",
    "        pairs.add((prev_char, char))\n",
    "        prev_char = char\n",
    "    return pairs\n",
    "\n",
    "class Encoder:\n",
    "    def __init__(self, encoder, bpe_merges, errors='replace'):\n",
    "        self.encoder = encoder\n",
    "        self.decoder = {v:k for k,v in self.encoder.items()}\n",
    "        self.errors = errors # how to handle errors in decoding\n",
    "        self.byte_encoder = bytes_to_unicode()\n",
    "        self.byte_decoder = {v:k for k, v in self.byte_encoder.items()}\n",
    "        self.bpe_ranks = dict(zip(bpe_merges, range(len(bpe_merges))))\n",
    "        self.cache = {}\n",
    "\n",
    "        # Should haved added re.IGNORECASE so BPE merges can happen for capitalized versions of contractions\n",
    "        self.pat = re.compile(r\"\"\"'s|'t|'re|'ve|'m|'ll|'d| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\")\n",
    "\n",
    "    def bpe(self, token):\n",
    "        if token in self.cache:\n",
    "            return self.cache[token]\n",
    "        word = tuple(token)\n",
    "        pairs = get_pairs(word)\n",
    "\n",
    "        if not pairs:\n",
    "            return token\n",
    "\n",
    "        while True:\n",
    "            bigram = min(pairs, key = lambda pair: self.bpe_ranks.get(pair, float('inf')))\n",
    "            if bigram not in self.bpe_ranks:\n",
    "                break\n",
    "            first, second = bigram\n",
    "            new_word = []\n",
    "            i = 0\n",
    "            while i < len(word):\n",
    "                try:\n",
    "                    j = word.index(first, i)\n",
    "                    new_word.extend(word[i:j])\n",
    "                    i = j\n",
    "                except:\n",
    "                    new_word.extend(word[i:])\n",
    "                    break\n",
    "\n",
    "                if word[i] == first and i < len(word)-1 and word[i+1] == second:\n",
    "                    new_word.append(first+second)\n",
    "                    i += 2\n",
    "                else:\n",
    "                    new_word.append(word[i])\n",
    "                    i += 1\n",
    "            new_word = tuple(new_word)\n",
    "            word = new_word\n",
    "            if len(word) == 1:\n",
    "                break\n",
    "            else:\n",
    "                pairs = get_pairs(word)\n",
    "        word = ' '.join(word)\n",
    "        self.cache[token] = word\n",
    "        return word\n",
    "\n",
    "    def encode(self, text):\n",
    "        bpe_tokens = []\n",
    "        for token in re.findall(self.pat, text):\n",
    "            token = ''.join(self.byte_encoder[b] for b in token.encode('utf-8'))\n",
    "            bpe_tokens.extend(self.encoder[bpe_token] for bpe_token in self.bpe(token).split(' '))\n",
    "        return bpe_tokens\n",
    "\n",
    "    def decode(self, tokens):\n",
    "        text = ''.join([self.decoder[token] for token in tokens])\n",
    "        text = bytearray([self.byte_decoder[c] for c in text]).decode('utf-8', errors=self.errors)\n",
    "        return text\n",
    "\n",
    "def get_encoder(model_name, models_dir):\n",
    "    with open(os.path.join(models_dir, model_name, 'encoder.json'), 'r') as f:\n",
    "        encoder = json.load(f)\n",
    "    with open(os.path.join(models_dir, model_name, 'vocab.bpe'), 'r', encoding=\"utf-8\") as f:\n",
    "        bpe_data = f.read()\n",
    "    bpe_merges = [tuple(merge_str.split()) for merge_str in bpe_data.split('\\n')[1:-1]]\n",
    "    return Encoder(\n",
    "        encoder=encoder,\n",
    "        bpe_merges=bpe_merges,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y_aIf7Q7XHTy"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "61cFgIMfamTx"
   },
   "outputs": [],
   "source": [
    "class HParams():\n",
    "  n_vocab=50257\n",
    "  n_ctx=1024\n",
    "  n_embd=768\n",
    "  n_head=12\n",
    "  n_layer=12\n",
    "  \n",
    "  def __init__(self, n_vocab, n_ctx, n_embd, n_head, n_layer):\n",
    "    self.n_vocab = n_vocab\n",
    "    self.n_ctx = n_ctx\n",
    "    self.n_embd = n_embd\n",
    "    self.n_head = n_head\n",
    "    self.n_layer = n_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jpBqRQiuQRd4"
   },
   "outputs": [],
   "source": [
    "def default_hparams():\n",
    "    return HParams(\n",
    "        n_vocab=50257,\n",
    "        n_ctx=1024,\n",
    "        n_embd=768,\n",
    "        n_head=12,\n",
    "        n_layer=12,\n",
    "    )\n",
    "\n",
    "def shape_list(x):\n",
    "    \"\"\"Deal with dynamic shape in tensorflow cleanly.\"\"\"\n",
    "    static = x.shape.as_list()\n",
    "    dynamic = tf.shape(input=x)\n",
    "    return [dynamic[i] if s is None else s for i, s in enumerate(static)]\n",
    "\n",
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + tf.tanh(np.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
    "\n",
    "def norm(x, scope, *, axis=-1, epsilon=1e-5):\n",
    "    \"\"\"Normalize to mean = 0, std = 1, then do a diagonal affine transform.\"\"\"\n",
    "    with tf.compat.v1.variable_scope(scope):\n",
    "        n_state = x.shape[-1]\n",
    "        g = tf.compat.v1.get_variable('g', [n_state], initializer=tf.compat.v1.constant_initializer(1), use_resource=False)\n",
    "        b = tf.compat.v1.get_variable('b', [n_state], initializer=tf.compat.v1.constant_initializer(0), use_resource=False)\n",
    "        u = tf.reduce_mean(input_tensor=x, axis=axis, keepdims=True)\n",
    "        s = tf.reduce_mean(input_tensor=tf.square(x-u), axis=axis, keepdims=True)\n",
    "        x = (x - u) * tf.math.rsqrt(s + epsilon)\n",
    "        x = x*g + b\n",
    "        return x\n",
    "\n",
    "def split_states(x, n):\n",
    "    \"\"\"Reshape the last dimension of x into [n, x.shape[-1]/n].\"\"\"\n",
    "    *start, m = shape_list(x)\n",
    "    return tf.reshape(x, start + [n, m//n])\n",
    "\n",
    "def merge_states(x):\n",
    "    \"\"\"Smash the last two dimensions of x into a single dimension.\"\"\"\n",
    "    *start, a, b = shape_list(x)\n",
    "    return tf.reshape(x, start + [a*b])\n",
    "\n",
    "def conv1d(x, scope, nf, *, w_init_stdev=0.02):\n",
    "    with tf.compat.v1.variable_scope(scope):\n",
    "        *start, nx = shape_list(x)\n",
    "        w = tf.compat.v1.get_variable('w', [1, nx, nf], initializer=tf.compat.v1.random_normal_initializer(stddev=w_init_stdev), use_resource=False)\n",
    "        b = tf.compat.v1.get_variable('b', [nf], initializer=tf.compat.v1.constant_initializer(0), use_resource=False)\n",
    "        c = tf.reshape(tf.matmul(tf.reshape(x, [-1, nx]), tf.reshape(w, [-1, nf]))+b, start+[nf])\n",
    "        return c\n",
    "\n",
    "def attention_mask(nd, ns, *, dtype):\n",
    "    \"\"\"1's in the lower triangle, counting from the lower right corner.\n",
    "\n",
    "    Same as tf.matrix_band_part(tf.ones([nd, ns]), -1, ns-nd), but doesn't produce garbage on TPUs.\n",
    "    \"\"\"\n",
    "    i = tf.range(nd)[:,None]\n",
    "    j = tf.range(ns)\n",
    "    m = i >= j - ns + nd\n",
    "    return tf.cast(m, dtype)\n",
    "\n",
    "\n",
    "def attn(x, scope, n_state, *, past, hparams):\n",
    "    assert x.shape.ndims == 3  # Should be [batch, sequence, features]\n",
    "    assert n_state % hparams.n_head == 0\n",
    "    if past is not None:\n",
    "        assert past.shape.ndims == 5  # Should be [batch, 2, heads, sequence, features], where 2 is [k, v]\n",
    "\n",
    "    def split_heads(x):\n",
    "        # From [batch, sequence, features] to [batch, heads, sequence, features]\n",
    "        return tf.transpose(a=split_states(x, hparams.n_head), perm=[0, 2, 1, 3])\n",
    "\n",
    "    def merge_heads(x):\n",
    "        # Reverse of split_heads\n",
    "        return merge_states(tf.transpose(a=x, perm=[0, 2, 1, 3]))\n",
    "\n",
    "    def mask_attn_weights(w):\n",
    "        # w has shape [batch, heads, dst_sequence, src_sequence], where information flows from src to dst.\n",
    "        _, _, nd, ns = shape_list(w)\n",
    "        b = attention_mask(nd, ns, dtype=w.dtype)\n",
    "        b = tf.reshape(b, [1, 1, nd, ns])\n",
    "        w = w*b - tf.cast(1e10, w.dtype)*(1-b)\n",
    "        return w\n",
    "\n",
    "    def multihead_attn(q, k, v):\n",
    "        # q, k, v have shape [batch, heads, sequence, features]\n",
    "        w = tf.matmul(q, k, transpose_b=True)\n",
    "        w = w * tf.math.rsqrt(tf.cast(v.shape[-1], w.dtype))\n",
    "\n",
    "        w = mask_attn_weights(w)\n",
    "        w = tf.nn.softmax(w, axis=-1)\n",
    "#         w = softmax(w)\n",
    "        a = tf.matmul(w, v)\n",
    "        return a\n",
    "\n",
    "    with tf.compat.v1.variable_scope(scope):\n",
    "        c = conv1d(x, 'c_attn', n_state*3)\n",
    "        q, k, v = map(split_heads, tf.split(c, 3, axis=2))\n",
    "        present = tf.stack([k, v], axis=1)\n",
    "        if past is not None:\n",
    "            pk, pv = tf.unstack(past, axis=1)\n",
    "            k = tf.concat([pk, k], axis=-2)\n",
    "            v = tf.concat([pv, v], axis=-2)\n",
    "        a = multihead_attn(q, k, v)\n",
    "        a = merge_heads(a)\n",
    "        a = conv1d(a, 'c_proj', n_state)\n",
    "        return a, present\n",
    "\n",
    "\n",
    "def mlp(x, scope, n_state, *, hparams):\n",
    "    with tf.compat.v1.variable_scope(scope):\n",
    "        nx = x.shape[-1]\n",
    "        h = gelu(conv1d(x, 'c_fc', n_state))\n",
    "        h2 = conv1d(h, 'c_proj', nx)\n",
    "        return h2\n",
    "\n",
    "def block(x, scope, *, past, hparams):\n",
    "    with tf.compat.v1.variable_scope(scope):\n",
    "        nx = x.shape[-1]\n",
    "#         layer_norm1 = tf.keras.layers.LayerNormalization(epsilon=1e-5, name='ln_1')\n",
    "#         a, present = attn(layer_norm1(x), 'attn', nx, past=past, hparams=hparams)\n",
    "        a, present = attn(norm(x, 'ln_1'), 'attn', nx, past=past, hparams=hparams)\n",
    "        x = x + a\n",
    "        m = mlp(norm(x, 'ln_2'), 'mlp', nx*4, hparams=hparams)\n",
    "        x = x + m\n",
    "        return x, present\n",
    "\n",
    "def past_shape(*, hparams, batch_size=None, sequence=None):\n",
    "    return [batch_size, hparams.n_layer, 2, hparams.n_head, sequence, hparams.n_embd // hparams.n_head]\n",
    "\n",
    "def expand_tile(value, size):\n",
    "    \"\"\"Add a new axis of given size.\"\"\"\n",
    "    value = tf.convert_to_tensor(value=value, name='value')\n",
    "    ndims = value.shape.ndims\n",
    "    return tf.tile(tf.expand_dims(value, axis=0), [size] + [1]*ndims)\n",
    "\n",
    "def positions_for(tokens, past_length):\n",
    "    batch_size = tf.shape(input=tokens)[0]\n",
    "    nsteps = tf.shape(input=tokens)[1]\n",
    "    return expand_tile(past_length + tf.range(nsteps), batch_size)\n",
    "\n",
    "\n",
    "def model(hparams, X, past=None, scope='model', reuse=tf.compat.v1.AUTO_REUSE):\n",
    "    with tf.compat.v1.variable_scope(scope, reuse=reuse):\n",
    "        results = {}\n",
    "        batch, sequence = shape_list(X)\n",
    "\n",
    "        wpe = tf.compat.v1.get_variable('wpe', [hparams.n_ctx, hparams.n_embd],\n",
    "                             initializer=tf.compat.v1.random_normal_initializer(stddev=0.01), use_resource=False)\n",
    "        wte = tf.compat.v1.get_variable('wte', [hparams.n_vocab, hparams.n_embd],\n",
    "                             initializer=tf.compat.v1.random_normal_initializer(stddev=0.02), use_resource=False)\n",
    "        past_length = 0 if past is None else tf.shape(input=past)[-2]\n",
    "        h = tf.gather(wte, X) + tf.gather(wpe, positions_for(X, past_length))\n",
    "\n",
    "        # Transformer\n",
    "        presents = []\n",
    "        pasts = tf.unstack(past, axis=1) if past is not None else [None] * hparams.n_layer\n",
    "        assert len(pasts) == hparams.n_layer\n",
    "        for layer, past in enumerate(pasts):\n",
    "            h, present = block(h, 'h%d' % layer, past=past, hparams=hparams)\n",
    "            presents.append(present)\n",
    "        results['present'] = tf.stack(presents, axis=1)\n",
    "        h = norm(h, 'ln_f')\n",
    "\n",
    "        # Language model loss.  Do tokens <n predict token n?\n",
    "        h_flat = tf.reshape(h, [batch*sequence, hparams.n_embd])\n",
    "        logits = tf.matmul(h_flat, wte, transpose_b=True)\n",
    "        logits = tf.reshape(logits, [batch, sequence, hparams.n_vocab])\n",
    "        results['logits'] = logits\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A_rmLotVXbbw"
   },
   "source": [
    "# Sample from Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "45t7syAbXaPb"
   },
   "outputs": [],
   "source": [
    "def top_k_logits(logits, k):\n",
    "    if k == 0:\n",
    "        # no truncation\n",
    "        return logits\n",
    "\n",
    "    def _top_k():\n",
    "        values, _ = tf.nn.top_k(logits, k=k)\n",
    "        min_values = values[:, -1, tf.newaxis]\n",
    "        return tf.compat.v1.where(\n",
    "            logits < min_values,\n",
    "            tf.ones_like(logits, dtype=logits.dtype) * -1e10,\n",
    "            logits,\n",
    "        )\n",
    "    return tf.cond(\n",
    "       pred=tf.equal(k, 0),\n",
    "       true_fn=lambda: logits,\n",
    "       false_fn=lambda: _top_k(),\n",
    "    )\n",
    "\n",
    "\n",
    "def sample_sequence(*, hparams, length, start_token=None, batch_size=None, context=None, temperature=1, top_k=0):\n",
    "    if start_token is None:\n",
    "        assert context is not None, 'Specify exactly one of start_token and context!'\n",
    "    else:\n",
    "        assert context is None, 'Specify exactly one of start_token and context!'\n",
    "        context = tf.fill([batch_size, 1], start_token)\n",
    "\n",
    "    def step(hparams, tokens, past=None):\n",
    "        lm_output = model(hparams=hparams, X=tokens, past=past, reuse=tf.compat.v1.AUTO_REUSE)\n",
    "\n",
    "        logits = lm_output['logits'][:, :, :hparams.n_vocab]\n",
    "        presents = lm_output['present']\n",
    "        presents.set_shape(past_shape(hparams=hparams, batch_size=batch_size))\n",
    "        return {\n",
    "            'logits': logits,\n",
    "            'presents': presents,\n",
    "        }\n",
    "\n",
    "#     with tf.compat.v1.name_scope('sample_sequence'):\n",
    "    def body(past, prev, output):\n",
    "        next_outputs = step(hparams, prev, past=past)\n",
    "        logits = next_outputs['logits'][:, -1, :]  / tf.cast(temperature, dtype=tf.float32)\n",
    "        logits = top_k_logits(logits, k=top_k)\n",
    "        samples = tf.random.categorical(logits=logits, num_samples=1, dtype=tf.int32)\n",
    "        return [\n",
    "            next_outputs['presents'] if past is None else tf.concat([past, next_outputs['presents']], axis=-2),\n",
    "            samples,\n",
    "            tf.concat([output, samples], axis=1)\n",
    "        ]\n",
    "\n",
    "    past, prev, output = body(None, context, context)\n",
    "\n",
    "    def cond(*args):\n",
    "        return True\n",
    "#     print(length)\n",
    "#         for _ in range(20):\n",
    "#             past, prev, output = body(past, prev, output)\n",
    "\n",
    "    _, _, tokens = tf.while_loop(\n",
    "        cond=cond, body=body,\n",
    "        maximum_iterations=length - 1,\n",
    "        loop_vars=[\n",
    "            past,\n",
    "            prev,\n",
    "            output\n",
    "        ],\n",
    "        shape_invariants=[\n",
    "            tf.TensorShape(past_shape(hparams=hparams, batch_size=batch_size)),\n",
    "            tf.TensorShape([batch_size, None]),\n",
    "            tf.TensorShape([batch_size, None]),\n",
    "        ],\n",
    "        back_prop=False,\n",
    "    )\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1820,
     "status": "ok",
     "timestamp": 1560964120243,
     "user": {
      "displayName": "Nathan Cooper",
      "photoUrl": "",
      "userId": "15284233239426922637"
     },
     "user_tz": 300
    },
    "id": "NPL1U5vccFIA",
    "outputId": "e1cf597f-6e6f-4c95-b1e8-5cfb5583431c"
   },
   "outputs": [],
   "source": [
    "!ls models/345M\n",
    "!cat models/117M/hparams.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LsGA_Ye1XKCW"
   },
   "source": [
    "# Interactive Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 78171,
     "status": "error",
     "timestamp": 1562037139530,
     "user": {
      "displayName": "Nathan Cooper",
      "photoUrl": "",
      "userId": "15284233239426922637"
     },
     "user_tz": 300
    },
    "id": "mDXo9GTgR3v_",
    "outputId": "64cb84a9-4c8d-41e5-af59-f1eceb2b9f68"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0904 20:19:02.771937 140475408045888 deprecation.py:323] From <ipython-input-7-ef3b52cbd52e>:12: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0904 20:19:05.333244 140475408045888 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model prompt >>> Hi, my name is\n",
      "Output Obj:  Tensor(\"while/Exit_3:0\", shape=(1, None), dtype=int32)\n",
      "Context:  [[17250, 11, 616, 1438, 318]]\n",
      "======================================== SAMPLE 1 ========================================\n",
      " Ryan Kostka. I've gone to Harvard, the most prestigious university in America; you can't get there in a black shirt. If you do find something of value at all, make us a call. Call me. Please.\n",
      "\n",
      "That's it. I'll be here. Good to see you, there. Thank you for leaving.<|endoftext|>WASHINGTON, July 5 (UPI) -- President Obama gave a televised address on Friday thanking Russia for helping him win a military victory in Ukraine, but also acknowledging that more than 600 troops still have not returned to the country, and that many in the U.S. believe the United States can't afford a second war, in which U.S.-backed rebels have killed thousands.\n",
      "\n",
      "The President addressed the United States' military personnel at the National Defense Reserves Training Center, located at the base's base site in Bethesda, Md., where three American troops were killed during fighting with the self-proclaimed \"Shattered Banner.\" The group's leader was killed at the base that night, two days after the Democratic Party claimed the white separatist group had been responsible for its deaths, according to sources.\n",
      "\n",
      "The White House said that the President thanked those who are able to return to the American side. \"We cannot afford two wars if we do not begin rebuilding our armed forces,\" Obama said. Obama called on the Russian Federation to provide assistance in recovering the soldiers. The President also acknowledged that the United States does not have 100 percent troops there for the next six months. The United States is \"ready and willing\" to step-up military support in the face of the current conflict in Ukraine.\n",
      "\n",
      "An earlier report from NBC News cited sources in the White House, which said that the President's invitation for the General Assembly to discuss US military options was approved just one day after the Russian President said the United States will get some troops home by the end of September. Obama also promised to provide $25 million each month in assistance for the Kiev government after it won the Ukrainian parliamentary elections in February.\n",
      "\n",
      "Obama said he has not decided, because he and his national security team are busy negotiating a new deal with the International Criminal Court.\n",
      "\n",
      "Russian Foreign Minister Sergey Lavrov told the European Parliament to take action to bring the sanctions into force and that Putin would have no choice but to provide $25 million in additional military aid to the Ukrainian government.\n",
      "\n",
      "Follow Chuck on Twitter<|endoftext|>For one man -- and one woman, for that matter -- this year's Republican National Convention was a political\n",
      "================================================================================\n",
      "Model prompt >>> Is Nathan a virgin?\n",
      "Output Obj:  Tensor(\"while/Exit_3:0\", shape=(1, None), dtype=int32)\n",
      "Context:  [[3792, 18106, 257, 21772, 30]]\n",
      "======================================== SAMPLE 1 ========================================\n",
      " Or an ex-con that has been a virgin for six months and will return as an ex-con?!\n",
      "\n",
      "Or the real Nathan:\n",
      "\n",
      "\"Oh, I suppose Nathan is pretty virile, in all my flesh.\" --John 17:10-15,\n",
      "\n",
      "and it seems Nathan could be the best-kept secret of those who will follow.<|endoftext|>For the first time in its history, the Supreme Court has ruled that the right to contraceptives is still a fundamental right of American citizens, despite the growing pressure to allow those with mental illness or some other mental impairment to participate.\n",
      "\n",
      "The landmark decision, on behalf of nine states, was cheered on by some members of Congress, as well as some supporters of reproductive rights.\n",
      "\n",
      "But the fact that President Donald Trump has said repeatedly in his campaign for the presidency that we must defund the National Institutes of Health shows that the decision to deny access to contraceptive coverage to millions of people isn't limited to the president's supporters; some of these groups are also trying to undermine the court's decision to grant them all the benefits that would be given to them under the law.\n",
      "\n",
      "A recent study from the National Center for Health Statistics estimated that as a result of the court's decision that it must be repealed, nearly 7 million people could be denied contraceptive coverage from the end of this year. More than half of these would be disabled, and many would not have access to contraceptives. The study found that at least 3 million people had unintended pregnancies; a number that could be reduced by cutting funding to abortion centers and other facilities providing care for women who want an abortion.\n",
      "\n",
      "The National Conference of State Legislatures and many of its members are advocating similar measures to defund the National Institutes of Health (NIH), which has been a key pillar of President Trump's campaign. The group's executive director, Bill Huiter, argued that the court's decision to end funding for the NIH \"disrupts their ability to provide services and services that have important medical and financial consequences.\" To that end, the NCSL has released a proposal the group has proposed requiring all federal funding for the NIH, and an additional 12 years of funding that should be given to states, not to states.\n",
      "\n",
      "\"To protect health and public health in this country at great cost, we are urging the Justice Department to halt funding for the NCIS until the NICS report is complete, but until this funding is restored to states, no state would be required to comply with Section 1 of the Hyde Amendment,\n",
      "================================================================================\n",
      "Model prompt >>> What is the capital of Bangladesh?\n",
      "Output Obj:  Tensor(\"while/Exit_3:0\", shape=(1, None), dtype=int32)\n",
      "Context:  [[2061, 318, 262, 3139, 286, 19483, 30]]\n",
      "======================================== SAMPLE 1 ========================================\n",
      " (And is it all the money?)\n",
      "\n",
      "No, it's the capital of Bangladesh. Our entire economy is based on investment by everyone and nobody.\n",
      "\n",
      "The capital of Bangladesh is worth around $2 billion and that's right there in the middle of the country. And then, you know - (inaudible) the bank account of Bangladesh has changed - now because the government says it's going to charge interest, the government says it will charge interest - or they charge interest so it's going to pay interest, and the banks don't let it.\n",
      "\n",
      "So the banks, it's not a problem for the banks. In Bangladesh in the old era, banks made payments on the backs of citizens, who could easily pay them with cash.\n",
      "\n",
      "So I would say that what we're here to look at now is very much the same as the old days - but this time it's different.\n",
      "\n",
      "So, for those of you who understand what we are looking at here, you're looking at a very different system than what we're looking at.\n",
      "\n",
      "And there are two very important things. One, there's this whole idea of \"good money, bad money.\" So, what about the other way: \"good money, bad money\"?\n",
      "\n",
      "That is, what are the differences between the two?\n",
      "\n",
      "One is good money in this case - the money that's been received is only money you receive from the people who have invested in you, because there is nothing that could be wrong with that.\n",
      "\n",
      "But the other way, is to try to get the money to you through banks, which is to just do everything at home. You might make a purchase for cash, but when you go to bank, you don't even know where the money is. So the only thing that you can do is to ask the bank to give you cash and check it, right?\n",
      "\n",
      "So when you don't have cash, even in Bangladesh, banks can charge interest on it. Because if the bank is doing that, you're not paying the interest on the investment. So the only kind of system to deal with the problem of bad money is to use banks because the one place where banks are in this system would be to try to make their business look cheap.\n",
      "\n",
      "In fact, it's this kind of system that is the most basic of the reforms that have emerged.\n",
      "\n",
      "But what it's really about is that the only system in the world that has not been reformulated - that\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def interact_model(\n",
    "    model_name='117M',\n",
    "    seed=None,\n",
    "    nsamples=1,\n",
    "    batch_size=1,\n",
    "    length=None,\n",
    "    temperature=1,\n",
    "    top_k=0,\n",
    "    models_dir='models',    \n",
    "):\n",
    "    \"\"\"\n",
    "    Interactively run the model\n",
    "    :model_name=117M : String, which model to use\n",
    "    :seed=None : Integer seed for random number generators, fix seed to reproduce\n",
    "     results\n",
    "    :nsamples=1 : Number of samples to return total\n",
    "    :batch_size=1 : Number of batches (only affects speed/memory).  Must divide nsamples.\n",
    "    :length=None : Number of tokens in generated text, if None (default), is\n",
    "     determined by model hyperparameters\n",
    "    :temperature=1 : Float value controlling randomness in boltzmann\n",
    "     distribution. Lower temperature results in less random completions. As the\n",
    "     temperature approaches zero, the model will become deterministic and\n",
    "     repetitive. Higher temperature results in more random completions.\n",
    "    :top_k=0 : Integer value controlling diversity. 1 means only 1 word is\n",
    "     considered for each step (token), resulting in deterministic completions,\n",
    "     while 40 means 40 words are considered at each step. 0 (default) is a\n",
    "     special setting meaning no restrictions. 40 generally is a good value.\n",
    "     :models_dir : path to parent folder containing model subfolders\n",
    "     (i.e. contains the <model_name> folder)     \n",
    "    \"\"\"\n",
    "    models_dir = os.path.expanduser(os.path.expandvars(models_dir))\n",
    "    if batch_size is None:\n",
    "        batch_size = 1\n",
    "    assert nsamples % batch_size == 0\n",
    "\n",
    "    enc = get_encoder(model_name, models_dir)\n",
    "    hparams = default_hparams()\n",
    "#     with open(os.path.join(models_dir, model_name, 'hparams.json')) as f:\n",
    "#         hparams.override_from_dict(json.load(f))\n",
    "\n",
    "    if length is None:\n",
    "        length = hparams.n_ctx // 2\n",
    "    elif length > hparams.n_ctx:\n",
    "        raise ValueError(\"Can't get samples longer than window size: %s\" % hparams.n_ctx)\n",
    "\n",
    "    with tf.compat.v1.Session(graph=tf.Graph()) as sess:\n",
    "        context = tf.compat.v1.placeholder(tf.int32, [batch_size, None])\n",
    "        np.random.seed(seed)\n",
    "        tf.compat.v1.set_random_seed(seed)\n",
    "        output = sample_sequence(\n",
    "            hparams=hparams, length=length,\n",
    "            context=context,\n",
    "            batch_size=batch_size,\n",
    "            temperature=temperature, top_k=top_k\n",
    "        )\n",
    "        \n",
    "\n",
    "        saver = tf.compat.v1.train.Saver()\n",
    "        ckpt = tf.train.latest_checkpoint(os.path.join(models_dir, model_name))\n",
    "        saver.restore(sess, ckpt)\n",
    "        tf.compat.v1.global_variables_initializer()\n",
    "#         init = tf.compat.v1.global_variables_initializer()\n",
    "#         sess.run(init)\n",
    "        \n",
    "\n",
    "        while True:\n",
    "            raw_text = input(\"Model prompt >>> \")\n",
    "            while not raw_text:\n",
    "                print('Prompt should not be empty!')\n",
    "                raw_text = input(\"Model prompt >>> \")\n",
    "            context_tokens = enc.encode(raw_text)\n",
    "            generated = 0\n",
    "            for _ in range(nsamples // batch_size):\n",
    "                print(\"Output Obj: \", output)\n",
    "                print(\"Context: \", [context_tokens for _ in range(batch_size)])\n",
    "#                 out = output #predict(output, length, [context_tokens for _ in range(batch_size)])\n",
    "                out = sess.run(output, feed_dict={\n",
    "                    context: [context_tokens for _ in range(batch_size)]\n",
    "                })[:, len(context_tokens):]\n",
    "                for i in range(batch_size):\n",
    "                    generated += 1\n",
    "                    text = enc.decode(out[i])\n",
    "                    print(\"=\" * 40 + \" SAMPLE \" + str(generated) + \" \" + \"=\" * 40)\n",
    "                    print(text)\n",
    "            print(\"=\" * 80)\n",
    "\n",
    "interact_model(model_name='117M',\n",
    "    seed=None,\n",
    "    nsamples=1,\n",
    "    batch_size=1,\n",
    "    length=None,\n",
    "    temperature=1,\n",
    "    top_k=40,\n",
    "    models_dir='models')\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     fire.Fire(interact_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jTcrUHeJr_iL"
   },
   "outputs": [],
   "source": [
    "ates(x):\n",
    "    \"\"\"Smash the last twfrom toposort import toposort\n",
    "import contextlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.graph_editor as ge\n",
    "import time\n",
    "import sys\n",
    "sys.setrecursionlimit(10000)\n",
    "# refers back to current module if we decide to split helpers out\n",
    "util = sys.modules[__name__]\n",
    "\n",
    "# getting rid of \"WARNING:tensorflow:VARIABLES collection name is deprecated\"\n",
    "setattr(tf.compat.v1.GraphKeys, \"VARIABLES\", \"variables\")\n",
    "\n",
    "# save original gradients since tf.gradient could be monkey-patched to point\n",
    "# to our version\n",
    "from tensorflow.python.ops import gradients as tf_gradients_lib\n",
    "tf_gradients = tf_gradients_lib.gradients\n",
    "\n",
    "MIN_CHECKPOINT_NODE_SIZE=1024    # use lower value during testing\n",
    "\n",
    "# specific versions we can use to do process-wide replacement of tf.gradients\n",
    "def gradients_speed(ys, xs, grad_ys=None, **kwargs):\n",
    "    return gradients(ys, xs, grad_ys, checkpoints='speed', **kwargs)\n",
    "\n",
    "def gradients_memory(ys, xs, grad_ys=None, **kwargs):\n",
    "    return gradients(ys, xs, grad_ys, checkpoints='memory', **kwargs)\n",
    "\n",
    "def gradients_collection(ys, xs, grad_ys=None, **kwargs):\n",
    "    return gradients(ys, xs, grad_ys, checkpoints='collection', **kwargs)\n",
    "\n",
    "def gradients(ys, xs, grad_ys=None, checkpoints='collection', **kwargs):\n",
    "    '''\n",
    "    Authors: Tim Salimans & Yaroslav Bulatov\n",
    "\n",
    "    memory efficient gradient implementation inspired by \"Training Deep Nets with Sublinear Memory Cost\"\n",
    "    by Chen et al. 2016 (https://arxiv.org/abs/1604.06174)\n",
    "\n",
    "    ys,xs,grad_ys,kwargs are the arguments to standard tensorflow tf.gradients\n",
    "    (https://www.tensorflow.org/versions/r0.12/api_docs/python/train.html#gradients)\n",
    "\n",
    "    'checkpoints' can either be\n",
    "        - a list consisting of tensors from the forward pass of the neural net\n",
    "          that we should re-use when calculating the gradients in the backward pass\n",
    "          all other tensors that do not appear in this list will be re-computed\n",
    "        - a string specifying how this list should be determined. currently we support\n",
    "            - 'speed':  checkpoint all outputs of convolutions and matmuls. these ops are usually the most expensive,\n",
    "                        so checkpointing them maximizes the running speed\n",
    "                        (this is a good option if nonlinearities, concats, batchnorms, etc are taking up a lot of memory)\n",
    "            - 'memory': try to minimize the memory usage\n",
    "                        (currently using a very simple strategy that identifies a number of bottleneck tensors in the graph to checkpoint)\n",
    "            - 'collection': look for a tensorflow collection named 'checkpoints', which holds the tensors to checkpoint\n",
    "    '''\n",
    "\n",
    "    #    print(\"Calling memsaving gradients with\", checkpoints)\n",
    "    if not isinstance(ys,list):\n",
    "        ys = [ys]\n",
    "    if not isinstance(xs,list):\n",
    "        xs = [xs]\n",
    "\n",
    "    bwd_ops = ge.get_backward_walk_ops([y.op for y in ys],\n",
    "                                       inclusive=True)\n",
    "\n",
    "    debug_print(\"bwd_ops: %s\", bwd_ops)\n",
    "\n",
    "    # forward ops are all ops that are candidates for recomputation\n",
    "    fwd_ops = ge.get_forward_walk_ops([x.op for x in xs],\n",
    "                                      inclusive=True,\n",
    "                                      within_ops=bwd_ops)\n",
    "    debug_print(\"fwd_ops: %s\", fwd_ops)\n",
    "\n",
    "    # exclude ops with no inputs\n",
    "    fwd_ops = [op for op in fwd_ops if op.inputs]\n",
    "\n",
    "    # don't recompute xs, remove variables\n",
    "    xs_ops = _to_ops(xs)\n",
    "    fwd_ops = [op for op in fwd_ops if not op in xs_ops]\n",
    "    fwd_ops = [op for op in fwd_ops if not '/assign' in op.name]\n",
    "    fwd_ops = [op for op in fwd_ops if not '/Assign' in op.name]\n",
    "    fwd_ops = [op for op in fwd_ops if not '/read' in op.name]\n",
    "    ts_all = ge.filter_ts(fwd_ops, True) # get the tensors\n",
    "    ts_all = [t for t in ts_all if '/read' not in t.name]\n",
    "    ts_all = set(ts_all) - set(xs) - set(ys)\n",
    "\n",
    "    # construct list of tensors to checkpoint during forward pass, if not\n",
    "    # given as input\n",
    "    if type(checkpoints) is not list:\n",
    "        if checkpoints == 'collection':\n",
    "            checkpoints = tf.compat.v1.get_collection('checkpoints')\n",
    "\n",
    "        elif checkpoints == 'speed':\n",
    "            # checkpoint all expensive ops to maximize running speed\n",
    "            checkpoints = ge.filter_ts_from_regex(fwd_ops, 'conv2d|Conv|MatMul')\n",
    "\n",
    "        elif checkpoints == 'memory':\n",
    "\n",
    "            # remove very small tensors and some weird ops\n",
    "            def fixdims(t): # tf.Dimension values are not compatible with int, convert manually\n",
    "                try:\n",
    "                    return [int(e if e.value is not None else 64) for e in t]\n",
    "                except:\n",
    "                    return [0]  # unknown shape\n",
    "            ts_all = [t for t in ts_all if np.prod(fixdims(t.shape)) > MIN_CHECKPOINT_NODE_SIZE]\n",
    "            ts_all = [t for t in ts_all if 'L2Loss' not in t.name]\n",
    "            ts_all = [t for t in ts_all if 'entropy' not in t.name]\n",
    "            ts_all = [t for t in ts_all if 'FusedBatchNorm' not in t.name]\n",
    "            ts_all = [t for t in ts_all if 'Switch' not in t.name]\n",
    "            ts_all = [t for t in ts_all if 'dropout' not in t.name]\n",
    "            # DV: FP16_FIX - need to add 'Cast' layer here to make it work for FP16\n",
    "            ts_all = [t for t in ts_all if 'Cast' not in t.name]\n",
    "\n",
    "            # filter out all tensors that are inputs of the backward graph\n",
    "            with util.capture_ops() as bwd_ops:\n",
    "                tf_gradients(ys, xs, grad_ys, **kwargs)\n",
    "\n",
    "            bwd_inputs = [t for op in bwd_ops for t in op.inputs]\n",
    "            # list of tensors in forward graph that is in input to bwd graph\n",
    "            ts_filtered = list(set(bwd_inputs).intersection(ts_all))\n",
    "            debug_print(\"Using tensors %s\", ts_filtered)\n",
    "\n",
    "            # try two slightly different ways of getting bottlenecks tensors\n",
    "            # to checkpoint\n",
    "            for ts in [ts_filtered, ts_all]:\n",
    "\n",
    "                # get all bottlenecks in the graph\n",
    "                bottleneck_ts = []\n",
    "                for t in ts:\n",
    "                    b = set(ge.get_backward_walk_ops(t.op, inclusive=True, within_ops=fwd_ops))\n",
    "                    f = set(ge.get_forward_walk_ops(t.op, inclusive=False, within_ops=fwd_ops))\n",
    "                    # check that there are not shortcuts\n",
    "                    b_inp = set([inp for op in b for inp in op.inputs]).intersection(ts_all)\n",
    "                    f_inp = set([inp for op in f for inp in op.inputs]).intersection(ts_all)\n",
    "                    if not set(b_inp).intersection(f_inp) and len(b_inp)+len(f_inp) >= len(ts_all):\n",
    "                        bottleneck_ts.append(t)  # we have a bottleneck!\n",
    "                    else:\n",
    "                        debug_print(\"Rejected bottleneck candidate and ops %s\", [t] + list(set(ts_all) - set(b_inp) - set(f_inp)))\n",
    "\n",
    "                # success? or try again without filtering?\n",
    "                if len(bottleneck_ts) >= np.sqrt(len(ts_filtered)): # yes, enough bottlenecks found!\n",
    "                    break\n",
    "\n",
    "            if not bottleneck_ts:\n",
    "                raise Exception('unable to find bottleneck tensors! please provide checkpoint nodes manually, or use checkpoints=\"speed\".')\n",
    "\n",
    "            # sort the bottlenecks\n",
    "            bottlenecks_sorted_lists = tf_toposort(bottleneck_ts, within_ops=fwd_ops)\n",
    "            sorted_bottlenecks = [t for ts in bottlenecks_sorted_lists for t in ts]\n",
    "\n",
    "            # save an approximately optimal number ~ sqrt(N)\n",
    "            N = len(ts_filtered)\n",
    "            if len(bottleneck_ts) <= np.ceil(np.sqrt(N)):\n",
    "                checkpoints = sorted_bottlenecks\n",
    "            else:\n",
    "                step = int(np.ceil(len(bottleneck_ts) / np.sqrt(N)))\n",
    "                checkpoints = sorted_bottlenecks[step::step]\n",
    "\n",
    "        else:\n",
    "            raise Exception('%s is unsupported input for \"checkpoints\"' % (checkpoints,))\n",
    "\n",
    "    checkpoints = list(set(checkpoints).intersection(ts_all))\n",
    "\n",
    "    # at this point automatic selection happened and checkpoints is list of nodes\n",
    "    assert isinstance(checkpoints, list)\n",
    "\n",
    "    debug_print(\"Checkpoint nodes used: %s\", checkpoints)\n",
    "    # better error handling of special cases\n",
    "    # xs are already handled as checkpoint nodes, so no need to include them\n",
    "    xs_intersect_checkpoints = set(xs).intersection(set(checkpoints))\n",
    "    if xs_intersect_checkpoints:\n",
    "        debug_print(\"Warning, some input nodes are also checkpoint nodes: %s\",\n",
    "                    xs_intersect_checkpoints)\n",
    "    ys_intersect_checkpoints = set(ys).intersection(set(checkpoints))\n",
    "    debug_print(\"ys: %s, checkpoints: %s, intersect: %s\", ys, checkpoints,\n",
    "                ys_intersect_checkpoints)\n",
    "    # saving an output node (ys) gives no benefit in memory while creating\n",
    "    # new edge cases, exclude them\n",
    "    if ys_intersect_checkpoints:\n",
    "        debug_print(\"Warning, some output nodes are also checkpoints nodes: %s\",\n",
    "              format_ops(ys_intersect_checkpoints))\n",
    "\n",
    "    # remove initial and terminal nodes from checkpoints list if present\n",
    "    checkpoints = list(set(checkpoints) - set(ys) - set(xs))\n",
    "\n",
    "    # check that we have some nodes to checkpoint\n",
    "    # if not checkpoints:\n",
    "    #     raise Exception('no checkpoints nodes found or given as input! ')\n",
    "\n",
    "    # disconnect dependencies between checkpointed tensors\n",
    "    checkpoints_disconnected = {}\n",
    "    for x in checkpoints:\n",
    "        if x.op and x.op.name is not None:\n",
    "            grad_node = tf.stop_gradient(x, name=x.op.name+\"_sg\")\n",
    "        else:\n",
    "            grad_node = tf.stop_gradient(x)\n",
    "        checkpoints_disconnected[x] = grad_node\n",
    "\n",
    "    # partial derivatives to the checkpointed tensors and xs\n",
    "    ops_to_copy = fast_backward_ops(seed_ops=[y.op for y in ys],\n",
    "                                    stop_at_ts=checkpoints, within_ops=fwd_ops)\n",
    "    debug_print(\"Found %s ops to copy within fwd_ops %s, seed %s, stop_at %s\",\n",
    "                    len(ops_to_copy), fwd_ops, [r.op for r in ys], checkpoints)\n",
    "    debug_print(\"ops_to_copy = %s\", ops_to_copy)\n",
    "    debug_print(\"Processing list %s\", ys)\n",
    "    copied_sgv, info = ge.copy_with_input_replacements(ge.sgv(ops_to_copy), {})\n",
    "    for origin_op, op in info._transformed_ops.items():\n",
    "        op._set_device(origin_op.node_def.device)\n",
    "    copied_ops = info._transformed_ops.values()\n",
    "    debug_print(\"Copied %s to %s\", ops_to_copy, copied_ops)\n",
    "    ge.reroute_ts(checkpoints_disconnected.values(), checkpoints_disconnected.keys(), can_modify=copied_ops)\n",
    "    debug_print(\"Rewired %s in place of %s restricted to %s\",\n",
    "                checkpoints_disconnected.values(), checkpoints_disconnected.keys(), copied_ops)\n",
    "\n",
    "    # get gradients with respect to current boundary + original x's\n",
    "    copied_ys = [info._transformed_ops[y.op]._outputs[0] for y in ys]\n",
    "    boundary = list(checkpoints_disconnected.values())\n",
    "    dv = tf_gradients(ys=copied_ys, xs=boundary+xs, grad_ys=grad_ys, **kwargs)\n",
    "    debug_print(\"Got gradients %s\", dv)\n",
    "    debug_print(\"for %s\", copied_ys)\n",
    "    debug_print(\"with respect to %s\", boundary+xs)\n",
    "\n",
    "    inputs_to_do_before = [y.op for y in ys]\n",
    "    if grad_ys is not None:\n",
    "        inputs_to_do_before += grad_ys\n",
    "    wait_to_do_ops = list(copied_ops) + [g.op for g in dv if g is not None]\n",
    "    my_add_control_inputs(wait_to_do_ops, inputs_to_do_before)\n",
    "\n",
    "    # partial derivatives to the checkpointed nodes\n",
    "    # dictionary of \"node: backprop\" for nodes in the boundary\n",
    "    d_checkpoints = {r: dr for r,dr in zip(checkpoints_disconnected.keys(),\n",
    "                                        dv[:len(checkpoints_disconnected)])}\n",
    "    # partial derivatives to xs (usually the params of the neural net)\n",
    "    d_xs = dv[len(checkpoints_disconnected):]\n",
    "\n",
    "    # incorporate derivatives flowing through the checkpointed nodes\n",
    "    checkpoints_sorted_lists = tf_toposort(checkpoints, within_ops=fwd_ops)\n",
    "    for ts in checkpoints_sorted_lists[::-1]:\n",
    "        debug_print(\"Processing list %s\", ts)\n",
    "        checkpoints_other = [r for r in checkpoints if r not in ts]\n",
    "        checkpoints_disconnected_other = [checkpoints_disconnected[r] for r in checkpoints_other]\n",
    "\n",
    "        # copy part of the graph below current checkpoint node, stopping at\n",
    "        # other checkpoints nodes\n",
    "        ops_to_copy = fast_backward_ops(within_ops=fwd_ops, seed_ops=[r.op for r in ts], stop_at_ts=checkpoints_other)\n",
    "        debug_print(\"Found %s ops to copy within %s, seed %s, stop_at %s\",\n",
    "                    len(ops_to_copy), fwd_ops, [r.op for r in ts],\n",
    "                    checkpoints_other)\n",
    "        debug_print(\"ops_to_copy = %s\", ops_to_copy)\n",
    "        if not ops_to_copy: # we're done!\n",
    "            break\n",
    "        copied_sgv, info = ge.copy_with_input_replacements(ge.sgv(ops_to_copy), {})\n",
    "        for origin_op, op in info._transformed_ops.items():\n",
    "            op._set_device(origin_op.node_def.device)\n",
    "        copied_ops = info._transformed_ops.values()\n",
    "        debug_print(\"Copied %s to %s\", ops_to_copy, copied_ops)\n",
    "        ge.reroute_ts(checkpoints_disconnected_other, checkpoints_other, can_modify=copied_ops)\n",
    "        debug_print(\"Rewired %s in place of %s restricted to %s\",\n",
    "                    checkpoints_disconnected_other, checkpoints_other, copied_ops)\n",
    "\n",
    "        # gradient flowing through the checkpointed node\n",
    "        boundary = [info._transformed_ops[r.op]._outputs[0] for r in ts]\n",
    "        substitute_backprops = [d_checkpoints[r] for r in ts]\n",
    "        dv = tf_gradients(boundary,\n",
    "                          checkpoints_disconnected_other+xs,\n",
    "                          grad_ys=substitute_backprops, **kwargs)\n",
    "        debug_print(\"Got gradients %s\", dv)\n",
    "        debug_print(\"for %s\", boundary)\n",
    "        debug_print(\"with respect to %s\", checkpoints_disconnected_other+xs)\n",
    "        debug_print(\"with boundary backprop substitutions %s\", substitute_backprops)\n",
    "\n",
    "        inputs_to_do_before = [d_checkpoints[r].op for r in ts]\n",
    "        wait_to_do_ops = list(copied_ops) + [g.op for g in dv if g is not None]\n",
    "        my_add_control_inputs(wait_to_do_ops, inputs_to_do_before)\n",
    "\n",
    "        # partial derivatives to the checkpointed nodes\n",
    "        for r, dr in zip(checkpoints_other, dv[:len(checkpoints_other)]):\n",
    "            if dr is not None:\n",
    "                if d_checkpoints[r] is None:\n",
    "                    d_checkpoints[r] = dr\n",
    "                else:\n",
    "                    d_checkpoints[r] += dr\n",
    "        def _unsparsify(x):\n",
    "            if not isinstance(x, tf.IndexedSlices):\n",
    "                return x\n",
    "            assert x.dense_shape is not None, \"memory_saving_gradients encountered sparse gradients of unknown shape\"\n",
    "            indices = x.indices\n",
    "            while indices.shape.ndims < x.values.shape.ndims:\n",
    "                indices = tf.expand_dims(indices, -1)\n",
    "            return tf.scatter_nd(indices, x.values, x.dense_shape)\n",
    "\n",
    "        # partial derivatives to xs (usually the params of the neural net)\n",
    "        d_xs_new = dv[len(checkpoints_other):]\n",
    "        for j in range(len(xs)):\n",
    "            if d_xs_new[j] is not None:\n",
    "                if d_xs[j] is None:\n",
    "                    d_xs[j] = _unsparsify(d_xs_new[j])\n",
    "                else:\n",
    "                    d_xs[j] += _unsparsify(d_xs_new[j])\n",
    "\n",
    "\n",
    "    return d_xs\n",
    "\n",
    "def tf_toposort(ts, within_ops=None):\n",
    "    all_ops = ge.get_forward_walk_ops([x.op for x in ts], within_ops=within_ops)\n",
    "\n",
    "    deps = {}\n",
    "    for op in all_ops:\n",
    "        for o in op.outputs:\n",
    "            deps[o] = set(op.inputs)\n",
    "    sorted_ts = toposort(deps)\n",
    "\n",
    "    # only keep the tensors from our original list\n",
    "    ts_sorted_lists = []\n",
    "    for l in sorted_ts:\n",
    "        keep = list(set(l).intersection(ts))\n",
    "        if keep:\n",
    "            ts_sorted_lists.append(keep)\n",
    "\n",
    "    return ts_sorted_lists\n",
    "\n",
    "def fast_backward_ops(within_ops, seed_ops, stop_at_ts):\n",
    "    bwd_ops = set(ge.get_backward_walk_ops(seed_ops, stop_at_ts=stop_at_ts))\n",
    "    ops = bwd_ops.intersection(within_ops).difference([t.op for t in stop_at_ts])\n",
    "    return list(ops)\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def capture_ops():\n",
    "  \"\"\"Decorator to capture ops created in the block.\n",
    "  with capture_ops() as ops:\n",
    "    # create some ops\n",
    "  print(ops) # => prints ops created.\n",
    "  \"\"\"\n",
    "\n",
    "  micros = int(time.time()*10**6)\n",
    "  scope_name = str(micros)\n",
    "  op_list = []\n",
    "  with tf.compat.v1.name_scope(scope_name):\n",
    "    yield op_list\n",
    "\n",
    "  g = tf.compat.v1.get_default_graph()\n",
    "  op_list.extend(ge.select_ops(scope_name+\"/.*\", graph=g))\n",
    "\n",
    "def _to_op(tensor_or_op):\n",
    "  if hasattr(tensor_or_op, \"op\"):\n",
    "    return tensor_or_op.op\n",
    "  return tensor_or_op\n",
    "\n",
    "def _to_ops(iterable):\n",
    "  if not _is_iterable(iterable):\n",
    "    return iterable\n",
    "  return [_to_op(i) for i in iterable]\n",
    "\n",
    "def _is_iterable(o):\n",
    "  try:\n",
    "    _ = iter(o)\n",
    "  except Exception:\n",
    "    return False\n",
    "  return True\n",
    "\n",
    "DEBUG_LOGGING=False\n",
    "def debug_print(s, *args):\n",
    "  \"\"\"Like logger.log, but also replaces all TensorFlow ops/tensors with their\n",
    "  names. Sensitive to value of DEBUG_LOGGING, see enable_debug/disable_debug\n",
    "\n",
    "  Usage:\n",
    "    debug_print(\"see tensors %s for %s\", tensorlist, [1,2,3])\n",
    "  \"\"\"\n",
    "\n",
    "  if DEBUG_LOGGING:\n",
    "    formatted_args = [format_ops(arg) for arg in args]\n",
    "    print(\"DEBUG \"+s % tuple(formatted_args))\n",
    "\n",
    "def format_ops(ops, sort_outputs=True):\n",
    "  \"\"\"Helper method for printing ops. Converts Tensor/Operation op to op.name,\n",
    "  rest to str(op).\"\"\"\n",
    "\n",
    "  if hasattr(ops, '__iter__') and not isinstance(ops, str):\n",
    "    l = [(op.name if hasattr(op, \"name\") else str(op)) for op in ops]\n",
    "    if sort_outputs:\n",
    "      return sorted(l)\n",
    "    return l\n",
    "  else:\n",
    "    return ops.name if hasattr(ops, \"name\") else str(ops)\n",
    "\n",
    "def my_add_control_inputs(wait_to_do_ops, inputs_to_do_before):\n",
    "    for op in wait_to_do_ops:\n",
    "        ci = [i for i in inputs_to_do_before if op.control_inputs is None or i not in op.control_inputs]\n",
    "        ge.add_control_inputs(op, ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j2FqjqTMksna"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "def load_dataset(enc, path, combine):\n",
    "    paths = []\n",
    "#     paths = Path(path).glob('**/*.java')\n",
    "#       print(i)\n",
    "# #     if os.path.isfile(path):\n",
    "# #         # Simple file\n",
    "# #         paths.append(path)\n",
    "#     elif os.path.isdir(path):\n",
    "        # Directory\n",
    "#     for (dirpath, _, fnames) in os.walk(path):\n",
    "#         for fname in fnames:\n",
    "#             paths.append(os.path.join(dirpath, fname))\n",
    "# #     else:\n",
    "# #         # Assume glob\n",
    "#     paths = glob.glob(path, recursive=True)\n",
    "    if os.path.isfile(path):\n",
    "        # Simple file\n",
    "        paths.append(path)\n",
    "    elif os.path.isdir(path):\n",
    "        # Directory\n",
    "        for i, (dirpath, _, fnames) in enumerate(os.walk(path)):\n",
    "            if i % 5000 == 0:\n",
    "              print(i)\n",
    "            for fname in fnames:\n",
    "                paths.append(os.path.join(dirpath, fname))\n",
    "                \n",
    "            if i == 50000:\n",
    "              print(\"Breaking\")\n",
    "              break\n",
    "    else:\n",
    "        # Assume glob\n",
    "        paths = glob.glob(path)\n",
    "\n",
    "        \n",
    "#     print(\"Paths:\", paths)\n",
    "    token_chunks = []\n",
    "#     new_paths = list()\n",
    "    raw_text = ''\n",
    "    for i, path in enumerate(tqdm.tqdm(paths)):\n",
    "#         print(\"Path:\", path)\n",
    "        if 'after.java' not in path:\n",
    "          continue\n",
    "#         if path.endswith('.npz'):\n",
    "#             # Pre-encoded\n",
    "#             with np.load(path) as npz:\n",
    "#                 for item in npz.files:\n",
    "#                     token_chunks.append(npz[item])\n",
    "#         else:\n",
    "          # Plain text\n",
    "\n",
    "        try:\n",
    "            with open(path, 'r') as fp:\n",
    "                raw_text += fp.read()\n",
    "            tokens = np.stack(enc.encode(raw_text))\n",
    "            token_chunks.append(tokens)\n",
    "            raw_text = ''\n",
    "#                 methods = raw_text.splitlines()\n",
    "#                 for method in tqdm.tqdm(methods):\n",
    "#                     tokens = np.stack(enc.encode(method))\n",
    "#                     token_chunks.append(tokens)\n",
    "        except:\n",
    "            print(e)\n",
    "            if i % 100 == 0:\n",
    "              print(\"Methods:\", len(token_chunks))\n",
    "        if i >= 100000:\n",
    "          break\n",
    "#    if raw_text:\n",
    "#        tokens = np.stack(enc.encode(raw_text))\n",
    "#        token_chunks.append(tokens)\n",
    "    return token_chunks\n",
    "\n",
    "def wrapper(paths):\n",
    "  while True:\n",
    "    try:\n",
    "      yield next(paths)\n",
    "    except StopIteration:\n",
    "      raise\n",
    "    except Exception as e:\n",
    "      print(e) # or whatever kind of logging you want\n",
    "      pass\n",
    "\n",
    "def binary_search(f, lo, hi):\n",
    "    if f(lo) or not f(hi):\n",
    "        return None\n",
    "    while hi > lo + 1:\n",
    "        mid = (lo + hi) // 2\n",
    "        if f(mid):\n",
    "            hi = mid\n",
    "        else:\n",
    "            lo = mid\n",
    "    return hi\n",
    "\n",
    "\n",
    "class Sampler(object):\n",
    "    \"\"\"Fairly samples a slice from a set of variable sized chunks.\n",
    "\n",
    "    'Fairly' means that the distribution is the same as sampling from one concatenated chunk,\n",
    "    but without crossing chunk boundaries.\"\"\"\n",
    "\n",
    "    def __init__(self, chunks, seed=None):\n",
    "        self.chunks = chunks\n",
    "        self.total_size = sum(chunk.shape[0] for chunk in chunks)\n",
    "        self.boundaries = [0]\n",
    "        for i in range(len(chunks)):\n",
    "            self.boundaries.append(self.boundaries[-1] + chunks[i].shape[0])\n",
    "        self.rs = np.random.RandomState(seed=seed)\n",
    "\n",
    "    def sample(self, length):\n",
    "        assert length < self.total_size // len(\n",
    "            self.chunks\n",
    "        ), \"Dataset files are too small to sample {} tokens at a time\".format(\n",
    "            length)\n",
    "        while True:\n",
    "            index = self.rs.randint(0, self.total_size - length - 1)\n",
    "            i = binary_search(lambda j: self.boundaries[j] > index, 0,\n",
    "                              len(self.boundaries) - 1) - 1\n",
    "            if self.boundaries[i + 1] > index + length:\n",
    "                within_chunk = index - self.boundaries[i]\n",
    "                return self.chunks[i][within_chunk:within_chunk + length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PLkRBQSysTKq"
   },
   "outputs": [],
   "source": [
    "class Args():\n",
    "  def __init__(self, dataset, model_name, combine, batch_size, learning_rate, optimizer, noise, top_k, top_p, run_name, sample_every, sample_length, sample_num, save_every, val_dataset, val_batch_size, val_batch_count, val_every):\n",
    "    self.dataset = dataset\n",
    "    self.model_name = model_name\n",
    "    self.combine = combine\n",
    "    self.batch_size = batch_size\n",
    "    self.learning_rate = learning_rate\n",
    "    self.optimizer = optimizer\n",
    "    self.noise = noise\n",
    "    self.top_k = top_k\n",
    "    self.top_p = top_p\n",
    "    self.run_name = run_name\n",
    "    self.sample_every = sample_every\n",
    "    self.sample_length = sample_length\n",
    "    self.sample_num = sample_num\n",
    "    self.save_every = save_every\n",
    "    self.val_dataset = val_dataset\n",
    "    self.val_batch_size = val_batch_size\n",
    "    self.val_batch_count = val_batch_count\n",
    "    self.val_every = val_every"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "40000\n",
      "45000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 22/115158 [00:00<10:50, 176.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "Breaking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 99944/115158 [03:59<00:26, 581.30it/s]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25358"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 99944/115158 [04:10<00:26, 581.30it/s]"
     ]
    }
   ],
   "source": [
    "args = Args(\n",
    "                dataset=\"../sciclone/data10/mtufano/deepLearningMutants/out/changes/code\",\n",
    "                model_name=\"117M\",\n",
    "                combine=50000,\n",
    "                batch_size=1,\n",
    "                learning_rate=0.00002,\n",
    "                optimizer=\"sgd\",\n",
    "                noise=0.0,\n",
    "                top_k=40,\n",
    "                top_p=0.0,\n",
    "                run_name=\"run1\",\n",
    "                sample_every=100,\n",
    "                sample_length=1023,\n",
    "                sample_num=1,\n",
    "                save_every=1000,\n",
    "                val_dataset=None,\n",
    "                val_batch_size=2,\n",
    "                val_batch_count=40,\n",
    "                val_every=0\n",
    "    )\n",
    "enc = get_encoder(args.model_name, \"models\")\n",
    "\n",
    "data_set = load_dataset(enc, args.dataset, args.combine)\n",
    "len(data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20286, 2535, 2535)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_SET_SIZE = len(data_set)\n",
    "TRN_SET_SIZE = int(DATA_SET_SIZE * 0.8)\n",
    "VAL_SET_SIZE = int(DATA_SET_SIZE * 0.1)\n",
    "TST_SET_SIZE = int(DATA_SET_SIZE * 0.1)\n",
    "\n",
    "trn_set = data_set[:TRN_SET_SIZE]\n",
    "val_set = data_set[TRN_SET_SIZE:TRN_SET_SIZE + VAL_SET_SIZE]\n",
    "tst_set = data_set[-TST_SET_SIZE:]\n",
    "len(trn_set), len(val_set), len(tst_set)\n",
    "# print(len(trn_set), len(val_set), len(tst_set))\n",
    "\n",
    "# print(len(trn_set) + len(val_set) + len(tst_set), DATA_SET_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 705262,
     "status": "error",
     "timestamp": 1562073894102,
     "user": {
      "displayName": "Nathan Cooper",
      "photoUrl": "",
      "userId": "15284233239426922637"
     },
     "user_tz": 300
    },
    "id": "cfjs2UHNkN5J",
    "outputId": "0a2ea262-c6af-4ac5-b102-80e1e417b19f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0703 20:37:51.112021 140155313919808 deprecation.py:323] From <ipython-input-11-ef3b52cbd52e>:12: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0703 20:38:00.931291 140155313919808 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint models/117M/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "dataset has 15705181 tokens\n",
      "Training...\n",
      "Calculating validation loss...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▎         | 1/40 [00:01<00:46,  1.19s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:01<00:28,  1.20it/s]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:01<00:17,  1.69it/s]\u001b[A\n",
      " 40%|████      | 16/40 [00:01<00:10,  2.37it/s]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:01<00:05,  3.31it/s]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:01<00:03,  4.56it/s]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:01<00:01,  6.22it/s]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:01<00:00,  8.38it/s]\u001b[A\n",
      "100%|██████████| 40/40 [00:02<00:00, 11.05it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 | 2.21] validation loss = 2.27\n",
      "[1 | 6.01] loss=2.11 avg=2.11\n",
      "[2 | 6.07] loss=2.81 avg=2.46\n",
      "[3 | 6.12] loss=2.48 avg=2.47\n",
      "[4 | 6.17] loss=2.06 avg=2.36\n",
      "[5 | 6.23] loss=3.36 avg=2.57\n",
      "[6 | 6.28] loss=2.57 avg=2.57\n",
      "[7 | 6.33] loss=2.34 avg=2.53\n",
      "[8 | 6.38] loss=1.81 avg=2.44\n",
      "[9 | 6.44] loss=2.06 avg=2.40\n",
      "[10 | 6.49] loss=2.82 avg=2.44\n",
      "[11 | 6.54] loss=2.75 avg=2.47\n",
      "[12 | 6.60] loss=2.32 avg=2.46\n",
      "[13 | 6.65] loss=1.84 avg=2.41\n",
      "[14 | 6.70] loss=3.25 avg=2.47\n",
      "[15 | 6.76] loss=3.07 avg=2.51\n",
      "[16 | 6.81] loss=1.70 avg=2.46\n",
      "[17 | 6.86] loss=2.19 avg=2.44\n",
      "[18 | 6.91] loss=2.02 avg=2.42\n",
      "[19 | 6.97] loss=2.64 avg=2.43\n",
      "[20 | 7.02] loss=1.97 avg=2.40\n",
      "[21 | 7.06] loss=2.83 avg=2.43\n",
      "[22 | 7.12] loss=1.76 avg=2.39\n",
      "[23 | 7.17] loss=1.52 avg=2.35\n",
      "[24 | 7.23] loss=1.83 avg=2.33\n",
      "[25 | 7.28] loss=2.66 avg=2.34\n",
      "[26 | 7.33] loss=2.13 avg=2.33\n",
      "[27 | 7.38] loss=1.46 avg=2.30\n",
      "[28 | 7.44] loss=1.09 avg=2.25\n",
      "[29 | 7.49] loss=2.82 avg=2.27\n",
      "[30 | 7.54] loss=1.58 avg=2.24\n",
      "[31 | 7.60] loss=2.83 avg=2.26\n",
      "[32 | 7.65] loss=1.09 avg=2.22\n",
      "[33 | 7.70] loss=2.82 avg=2.24\n",
      "[34 | 7.75] loss=2.06 avg=2.24\n",
      "[35 | 7.81] loss=2.81 avg=2.26\n",
      "[36 | 7.86] loss=3.16 avg=2.29\n",
      "[37 | 7.91] loss=2.68 avg=2.30\n",
      "[38 | 7.97] loss=2.41 avg=2.30\n",
      "[39 | 8.02] loss=1.61 avg=2.28\n",
      "[40 | 8.08] loss=2.13 avg=2.28\n",
      "[41 | 8.13] loss=2.64 avg=2.29\n",
      "[42 | 8.18] loss=2.96 avg=2.31\n",
      "[43 | 8.23] loss=1.65 avg=2.29\n",
      "[44 | 8.29] loss=2.28 avg=2.29\n",
      "[45 | 8.34] loss=2.22 avg=2.29\n",
      "[46 | 8.40] loss=2.27 avg=2.29\n",
      "[47 | 8.45] loss=2.35 avg=2.29\n",
      "[48 | 8.51] loss=2.00 avg=2.28\n",
      "[49 | 8.56] loss=2.28 avg=2.28\n",
      "[50 | 8.61] loss=1.90 avg=2.27\n",
      "[51 | 8.66] loss=2.37 avg=2.27\n",
      "[52 | 8.72] loss=2.17 avg=2.27\n",
      "[53 | 8.78] loss=2.89 avg=2.29\n",
      "[54 | 8.83] loss=2.59 avg=2.29\n",
      "[55 | 8.88] loss=3.33 avg=2.32\n",
      "[56 | 8.94] loss=2.78 avg=2.33\n",
      "[57 | 8.99] loss=1.56 avg=2.31\n",
      "[58 | 9.04] loss=3.25 avg=2.33\n",
      "[59 | 9.09] loss=2.80 avg=2.34\n",
      "[60 | 9.15] loss=1.30 avg=2.32\n",
      "[61 | 9.20] loss=2.20 avg=2.32\n",
      "[62 | 9.26] loss=0.32 avg=2.27\n",
      "[63 | 9.31] loss=2.71 avg=2.28\n",
      "[64 | 9.37] loss=2.10 avg=2.28\n",
      "[65 | 9.42] loss=2.59 avg=2.29\n",
      "[66 | 9.48] loss=2.27 avg=2.28\n",
      "[67 | 9.53] loss=2.37 avg=2.29\n",
      "[68 | 9.59] loss=1.45 avg=2.27\n",
      "[69 | 9.64] loss=2.12 avg=2.27\n",
      "[70 | 9.69] loss=3.64 avg=2.29\n",
      "[71 | 9.75] loss=2.28 avg=2.29\n",
      "[72 | 9.80] loss=2.10 avg=2.29\n",
      "[73 | 9.86] loss=0.81 avg=2.26\n",
      "[74 | 9.91] loss=0.04 avg=2.22\n",
      "[75 | 9.96] loss=2.47 avg=2.22\n",
      "[76 | 10.01] loss=1.37 avg=2.21\n",
      "[77 | 10.07] loss=2.12 avg=2.21\n",
      "[78 | 10.12] loss=2.34 avg=2.21\n",
      "[79 | 10.18] loss=2.33 avg=2.21\n",
      "[80 | 10.23] loss=2.89 avg=2.22\n",
      "[81 | 10.29] loss=2.15 avg=2.22\n",
      "[82 | 10.34] loss=3.62 avg=2.25\n",
      "[83 | 10.39] loss=3.02 avg=2.26\n",
      "[84 | 10.44] loss=1.72 avg=2.25\n",
      "[85 | 10.49] loss=2.19 avg=2.25\n",
      "[86 | 10.55] loss=2.67 avg=2.26\n",
      "[87 | 10.60] loss=2.67 avg=2.26\n",
      "[88 | 10.65] loss=2.43 avg=2.27\n",
      "[89 | 10.71] loss=2.85 avg=2.28\n",
      "[90 | 10.76] loss=3.08 avg=2.29\n",
      "[91 | 10.81] loss=2.02 avg=2.29\n",
      "[92 | 10.86] loss=1.16 avg=2.27\n",
      "[93 | 10.91] loss=2.23 avg=2.27\n",
      "[94 | 10.97] loss=1.21 avg=2.25\n",
      "[95 | 11.02] loss=2.20 avg=2.25\n",
      "[96 | 11.07] loss=1.45 avg=2.24\n",
      "[97 | 11.12] loss=1.69 avg=2.23\n",
      "[98 | 11.18] loss=2.62 avg=2.23\n",
      "[99 | 11.23] loss=1.91 avg=2.23\n",
      "Generating samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:00<00:00, 40.88it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== SAMPLE 1 ========\n",
      " { The object gets its parameter values from the class. A class member may have multiple members. You must not define any of the following functions, except for set() . set() allows the set to be a separate class. For example, set() is equivalent to setting the class instance to class D. It also specifies how the class hierarchy is implemented. If you are compiling from source.c , you must convert this class to a C interface. set() . for class D. The method f() creates an instance of D that contains D , while set() is equivalent to f() . set(d) , f(d) . When you create an F instance, set() may be called without calling f(d) . set(&) provides a way to write an implementation defined within an environment. It allows you to set multiple inheritance levels, and it allows you to manipulate the methods you pass (but not those defined in set() ). set(...) provides a way to use the property of an interface as its argument. The property values are returned automatically within the object. An object has the following setOf() and setOfTwo() parameters. The default value for any given setOf() and setOfTwo() parameter is an absolute value. When the property value is nonzero, then the setting will be computed. For instance, the default setOf() in all builtin implementations of setof(...) is 0. For methods that provide property values that do not have at least one argument (such as set(...) ), that value becomes set(...) . For instance, setF(...) , setF(...) and setF(...) are not set methods. The setOf() argument returns its value by using setOf() and setOf(...) methods, respectively. The first argument of f() is evaluated in the current call. The second argument of set() is evaluated in the next call. In one instance, F is the property value of d (the constructor). The first argument in f() is, in effect, a method to define D when it is called. The second argument in set() is a property value (either an F instance, or an internal copy of D ). The method setF() computes D if at least one call to setOf(...) occurs on the object. The argument for setOf() in f() and setOfTwo() , which are used to implement the method setD() , is setOf(...) that takes a string argument: setOfWith(d) Sets d to a set of D . The setOfWith method accepts argument d. The first parameter of setOf() is to a F instance. The second parameter in set(...) is a method to define F when and if it is called. Each argument for setOf() is evaluated and the given function returns 1 . If setOf() cannot be called from within the C context, setOf(...) is not called for that element. The third argument of setOfTwo() is defined as setOf(...) after the first argument has received its parameter value. This argument should be returned immediately. The second argument of setOfF() is a method to define F when called. The third argument in set() is a value for the property of a F instance. For instance, setOfF(...) sets d to an instance of setOfF . The third argument in setF() is a property value, not f(d). The second argument in f() is a method to define F when called. For instance, setOf2F(...) sets d to an instance of setOf2F . The third argument in setF() is a property value f(d). The third argument in setOf() is a method to define f when called. The first argument is called after setOfF() calls d . The second argument to f() returns a value at the current call. The initial call to setOf is called with the parameter value d of setOf() , and the first argument of setOf() has no argument. For instance, setOfD(...) returns f(d) . The method setOfWith sets d in its own C function called f() . The method setOfWithF returns the property that is used by setOfWithF or setOfD to return x . If f(), setOf(), setOfF or setOfF does not return the set of d , setOfD does not return either. SetOf is not defined in this instance. SetOf returns an object. The method setWith(...) computes x with the parameter value setD for d , setWithD for d'(a), setD for d'' b'(a) and set d for d c'(d()) (see above for detailed explanation of parameters). When you pass arguments to a method set of the form setOf(...) , then the method must also return the set of d . You may only return x values for setOf and setOfD\n",
      "\n",
      "Calculating validation loss...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 10/40 [00:00<00:00, 40.79it/s]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:00<00:00, 40.79it/s]\u001b[A\n",
      " 50%|█████     | 20/40 [00:00<00:00, 40.96it/s]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:00<00:00, 41.81it/s]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:00<00:00, 42.46it/s]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:00<00:00, 42.28it/s]\u001b[A\n",
      "100%|██████████| 40/40 [00:00<00:00, 42.44it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100 | 27.75] validation loss = 2.11\n",
      "[100 | 27.81] loss=2.84 avg=2.24\n",
      "[101 | 27.87] loss=1.49 avg=2.23\n",
      "[102 | 27.92] loss=1.99 avg=2.22\n",
      "[103 | 27.97] loss=2.59 avg=2.23\n",
      "[104 | 28.03] loss=2.62 avg=2.23\n",
      "[105 | 28.09] loss=2.87 avg=2.24\n",
      "[106 | 28.14] loss=1.15 avg=2.23\n",
      "[107 | 28.19] loss=2.75 avg=2.24\n",
      "[108 | 28.24] loss=0.79 avg=2.21\n",
      "[109 | 28.30] loss=0.04 avg=2.18\n",
      "[110 | 28.35] loss=1.25 avg=2.17\n",
      "[111 | 28.40] loss=1.14 avg=2.15\n",
      "[112 | 28.46] loss=1.69 avg=2.14\n",
      "[113 | 28.51] loss=1.53 avg=2.14\n",
      "[114 | 28.56] loss=0.51 avg=2.11\n",
      "[115 | 28.61] loss=1.28 avg=2.10\n",
      "[116 | 28.67] loss=2.45 avg=2.10\n",
      "[117 | 28.72] loss=2.04 avg=2.10\n",
      "[118 | 28.78] loss=3.12 avg=2.12\n",
      "[119 | 28.83] loss=2.23 avg=2.12\n",
      "[120 | 28.88] loss=1.70 avg=2.11\n",
      "[121 | 28.94] loss=2.80 avg=2.12\n",
      "[122 | 28.99] loss=2.71 avg=2.13\n",
      "[123 | 29.05] loss=2.81 avg=2.14\n",
      "[124 | 29.10] loss=2.02 avg=2.14\n",
      "[125 | 29.16] loss=2.08 avg=2.14\n",
      "[126 | 29.21] loss=2.27 avg=2.14\n",
      "[127 | 29.26] loss=2.14 avg=2.14\n",
      "[128 | 29.32] loss=2.32 avg=2.14\n",
      "[129 | 29.37] loss=2.87 avg=2.15\n",
      "[130 | 29.42] loss=3.05 avg=2.17\n",
      "[131 | 29.47] loss=2.06 avg=2.16\n",
      "[132 | 29.53] loss=1.77 avg=2.16\n",
      "[133 | 29.58] loss=1.81 avg=2.15\n",
      "[134 | 29.64] loss=2.45 avg=2.16\n",
      "[135 | 29.69] loss=2.05 avg=2.16\n",
      "[136 | 29.75] loss=2.70 avg=2.16\n",
      "[137 | 29.80] loss=2.35 avg=2.17\n",
      "[138 | 29.85] loss=0.35 avg=2.14\n",
      "[139 | 29.91] loss=3.61 avg=2.16\n",
      "[140 | 29.96] loss=2.09 avg=2.16\n",
      "[141 | 30.02] loss=2.06 avg=2.16\n",
      "[142 | 30.07] loss=1.81 avg=2.15\n",
      "[143 | 30.12] loss=2.06 avg=2.15\n",
      "[144 | 30.18] loss=2.35 avg=2.16\n",
      "[145 | 30.23] loss=2.13 avg=2.16\n",
      "[146 | 30.28] loss=1.85 avg=2.15\n",
      "[147 | 30.34] loss=0.96 avg=2.14\n",
      "[148 | 30.39] loss=2.08 avg=2.14\n",
      "[149 | 30.44] loss=2.28 avg=2.14\n",
      "[150 | 30.50] loss=1.81 avg=2.13\n",
      "[151 | 30.55] loss=2.50 avg=2.14\n",
      "[152 | 30.60] loss=2.07 avg=2.14\n",
      "[153 | 30.65] loss=1.79 avg=2.13\n",
      "[154 | 30.70] loss=2.56 avg=2.14\n",
      "[155 | 30.76] loss=2.17 avg=2.14\n",
      "[156 | 30.81] loss=2.48 avg=2.14\n",
      "[157 | 30.87] loss=2.59 avg=2.15\n",
      "[158 | 30.93] loss=3.08 avg=2.16\n",
      "[159 | 30.98] loss=2.03 avg=2.16\n",
      "[160 | 31.03] loss=1.45 avg=2.15\n",
      "[161 | 31.09] loss=1.15 avg=2.14\n",
      "[162 | 31.14] loss=2.60 avg=2.14\n",
      "[163 | 31.19] loss=2.56 avg=2.15\n",
      "[164 | 31.25] loss=2.63 avg=2.15\n",
      "[165 | 31.30] loss=3.60 avg=2.17\n",
      "[166 | 31.36] loss=2.20 avg=2.17\n",
      "[167 | 31.41] loss=3.56 avg=2.19\n",
      "[168 | 31.46] loss=2.78 avg=2.20\n",
      "[169 | 31.52] loss=1.83 avg=2.19\n",
      "[170 | 31.57] loss=2.04 avg=2.19\n",
      "[171 | 31.62] loss=1.94 avg=2.19\n",
      "[172 | 31.67] loss=2.21 avg=2.19\n",
      "[173 | 31.73] loss=2.33 avg=2.19\n",
      "[174 | 31.78] loss=2.48 avg=2.19\n",
      "[175 | 31.84] loss=3.09 avg=2.20\n",
      "[176 | 31.89] loss=2.88 avg=2.21\n",
      "[177 | 31.94] loss=0.74 avg=2.19\n",
      "[178 | 31.99] loss=2.93 avg=2.20\n",
      "[179 | 32.04] loss=1.30 avg=2.19\n",
      "[180 | 32.10] loss=2.59 avg=2.20\n",
      "[181 | 32.15] loss=0.74 avg=2.18\n",
      "[182 | 32.20] loss=1.89 avg=2.18\n",
      "[183 | 32.26] loss=4.05 avg=2.20\n",
      "[184 | 32.31] loss=1.54 avg=2.19\n",
      "[185 | 32.36] loss=1.66 avg=2.18\n",
      "[186 | 32.41] loss=1.10 avg=2.17\n",
      "[187 | 32.47] loss=2.67 avg=2.18\n",
      "[188 | 32.52] loss=2.92 avg=2.19\n",
      "[189 | 32.57] loss=2.93 avg=2.20\n",
      "[190 | 32.63] loss=2.51 avg=2.20\n",
      "[191 | 32.68] loss=1.29 avg=2.19\n",
      "[192 | 32.73] loss=1.32 avg=2.18\n",
      "[193 | 32.79] loss=1.74 avg=2.17\n",
      "[194 | 32.84] loss=2.07 avg=2.17\n",
      "[195 | 32.89] loss=2.00 avg=2.17\n",
      "[196 | 32.95] loss=1.76 avg=2.17\n",
      "[197 | 33.00] loss=2.03 avg=2.16\n",
      "[198 | 33.05] loss=0.91 avg=2.15\n",
      "[199 | 33.10] loss=3.43 avg=2.16\n",
      "Generating samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:00<00:00, 42.24it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== SAMPLE 1 ========\n",
      "  is the first to admit that the data on its own isn't the best. Indeed, while there is strong evidence showing the value of the data (in terms of its relevance to policy), the results and research findings on the matter are less clear.<|endoftext|>Pleasantville High Principal, Former Secretary to Arkansas State Senator Joseph N. L. P. Wiles, A.B.Sc. from New Castle College, has died. He was 97. Born in Arkansas on January 28, 1855, P.B., Benton County, Ark., in 1846, he died in his sleep in September, 1865 at age 89. For his service to state, his widow, Mary,  and his family, visit his grave at his home in Pleasantville, Arkansas.  He may be missed;  his son, William, was born June 4, 1886, in P.B. A. .  He grew up in Arkansas and was a member of the Arkansas State Senate.  He rose through the ranks to become State Representative from P.B. A. in 1916 and became Arkansas' first Senator in 1923.  Wiles' final act was his resignation as Arkansas Governor from that position in March, 1923.  After Arkansas continued to dominate the political scene, William was appointed Arkansas State Senator from July, 1921 until December, 1924.  He served in that position for a total of 43 years, as its state representative from 1932 to 1933.   Wiles served as Arkansas' first secretary of state from 1935 through 1952.  He served as a member of Arkansas' cabinet from 1946 through 1954, secretary and director from 1950 through 1953, secretary of commerce from 1964 to 1966 and vice chairman of commerce for the State House from 1971 to 1975\n",
      "In April 1977 the Arkansas Daily Times  reported that \"Mr. Wiles was in the country illegally and, after being released from prison, is believed to be seeking asylum in Britain, according to a state employee.  It was the third time he has been in Britain with an American visa and, like Mr. Wiles, was unable to return to Arkansas.   He was detained in Paris for three weeks in July, on suspicion of aiding a gang .  Some of his friends and family have been killed in the ongoing war and have been put to work illegally as agents.    Arkansas authorities believe he may have been murdered by a suspected agent.  Some of his  financial  policies are reportedly in danger.          he is said to have   done   in addition to    paying     tax  to      an       he        committed         treason in            he              conduct                           _________________ \n",
      "Photo:  http    https         /  # _________________ \n",
      "Photo taken May 9, 2017             _________________<|endoftext|>When two high school buddies arrive, both are shocked to find themselves in a crowded bus. A woman they had met in one of the older ladies' rooms comes to visit and the two men immediately get into an argument. Though the two of them end up arguing about how much of a risk they are taking, the bus arrives at the bus stop near the end of the drive. Despite the fact they are both extremely young, the bus finally arrives and they realize there might be someone waiting in the back. The woman they were meeting in one of the buses starts to talk to the man and when he tells her that he can't see her, she is surprised.      \n",
      "  [back to main page]<|endoftext|>We asked many questions like \"Why is a good book so bad?\" and \"What really goes wrong when one of Shakespeare's greatest plays ends without an epic ending?\" and \"How does this happen in the first two chapters?\" I've spent a long time exploring why an epic ending would be bad, and I think the following answers to these questions have provided answers that don't need to be said.\n",
      "\n",
      "What Does Shakespeare Really Mean?\n",
      "\n",
      "The definition of \"good\" can be hard to accept.    It is often difficult to imagine a film or television character such as Henry III, or even James Bond, that does not deliver on what they would have been expected to achieve, and what they wouldn't have achieved without being able to deliver.      \n",
      " \n",
      "Why Doesn't Shakespeare Really Mean an Epic Ending?\n",
      "\n",
      "\n",
      "\n",
      "Calculating validation loss...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 10/40 [00:00<00:00, 42.15it/s]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:00<00:00, 42.25it/s]\u001b[A\n",
      " 50%|█████     | 20/40 [00:00<00:00, 42.74it/s]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:00<00:00, 42.72it/s]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:00<00:00, 42.35it/s]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:00<00:00, 42.23it/s]\u001b[A\n",
      "100%|██████████| 40/40 [00:00<00:00, 41.44it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200 | 47.63] validation loss = 2.09\n",
      "[200 | 47.69] loss=0.19 avg=2.14\n",
      "[201 | 47.74] loss=2.32 avg=2.14\n",
      "[202 | 47.79] loss=1.82 avg=2.14\n",
      "[203 | 47.85] loss=2.62 avg=2.15\n",
      "[204 | 47.90] loss=2.36 avg=2.15\n",
      "[205 | 47.96] loss=1.07 avg=2.14\n",
      "[206 | 48.01] loss=1.92 avg=2.13\n",
      "[207 | 48.06] loss=1.02 avg=2.12\n",
      "[208 | 48.12] loss=2.94 avg=2.13\n",
      "[209 | 48.17] loss=1.90 avg=2.13\n",
      "[210 | 48.23] loss=1.39 avg=2.12\n",
      "[211 | 48.28] loss=2.06 avg=2.12\n",
      "[212 | 48.33] loss=3.03 avg=2.13\n",
      "[213 | 48.39] loss=1.33 avg=2.12\n",
      "[214 | 48.44] loss=2.20 avg=2.12\n",
      "[215 | 48.50] loss=1.92 avg=2.12\n",
      "[216 | 48.55] loss=0.87 avg=2.10\n",
      "[217 | 48.61] loss=2.53 avg=2.11\n",
      "[218 | 48.66] loss=3.35 avg=2.12\n",
      "[219 | 48.71] loss=0.59 avg=2.10\n",
      "[220 | 48.77] loss=2.51 avg=2.11\n",
      "[221 | 48.82] loss=2.95 avg=2.12\n",
      "[222 | 48.88] loss=1.57 avg=2.11\n",
      "[223 | 48.93] loss=3.25 avg=2.13\n",
      "[224 | 48.98] loss=1.73 avg=2.12\n",
      "[225 | 49.03] loss=1.38 avg=2.11\n",
      "[226 | 49.09] loss=1.40 avg=2.10\n",
      "[227 | 49.14] loss=2.39 avg=2.11\n",
      "[228 | 49.20] loss=0.43 avg=2.09\n",
      "[229 | 49.25] loss=1.56 avg=2.08\n",
      "[230 | 49.30] loss=2.46 avg=2.09\n",
      "[231 | 49.36] loss=1.75 avg=2.08\n",
      "[232 | 49.41] loss=1.06 avg=2.07\n",
      "[233 | 49.47] loss=2.34 avg=2.08\n",
      "[234 | 49.52] loss=2.51 avg=2.08\n",
      "[235 | 49.57] loss=1.05 avg=2.07\n",
      "[236 | 49.62] loss=2.22 avg=2.07\n",
      "[237 | 49.68] loss=0.04 avg=2.05\n",
      "[238 | 49.73] loss=2.76 avg=2.06\n",
      "[239 | 49.78] loss=2.56 avg=2.06\n",
      "[240 | 49.84] loss=1.53 avg=2.06\n",
      "[241 | 49.89] loss=1.35 avg=2.05\n",
      "[242 | 49.94] loss=2.44 avg=2.05\n",
      "[243 | 50.00] loss=0.40 avg=2.03\n",
      "[244 | 50.05] loss=2.61 avg=2.04\n",
      "[245 | 50.10] loss=2.64 avg=2.05\n",
      "[246 | 50.16] loss=3.56 avg=2.06\n",
      "[247 | 50.21] loss=1.98 avg=2.06\n",
      "[248 | 50.26] loss=1.58 avg=2.06\n",
      "[249 | 50.32] loss=1.83 avg=2.06\n",
      "[250 | 50.37] loss=3.37 avg=2.07\n",
      "[251 | 50.42] loss=3.11 avg=2.08\n",
      "[252 | 50.48] loss=0.98 avg=2.07\n",
      "[253 | 50.53] loss=3.23 avg=2.08\n",
      "[254 | 50.58] loss=2.09 avg=2.08\n",
      "[255 | 50.63] loss=1.68 avg=2.08\n",
      "[256 | 50.69] loss=3.19 avg=2.09\n",
      "[257 | 50.74] loss=2.82 avg=2.10\n",
      "[258 | 50.80] loss=2.25 avg=2.10\n",
      "[259 | 50.85] loss=3.50 avg=2.11\n",
      "[260 | 50.91] loss=0.04 avg=2.09\n",
      "[261 | 50.96] loss=2.66 avg=2.10\n",
      "[262 | 51.02] loss=1.31 avg=2.09\n",
      "[263 | 51.07] loss=1.46 avg=2.08\n",
      "[264 | 51.12] loss=1.88 avg=2.08\n",
      "[265 | 51.17] loss=1.78 avg=2.08\n",
      "[266 | 51.23] loss=2.98 avg=2.09\n",
      "[267 | 51.28] loss=2.08 avg=2.09\n",
      "[268 | 51.34] loss=2.94 avg=2.10\n",
      "[269 | 51.39] loss=1.43 avg=2.09\n",
      "[270 | 51.44] loss=1.57 avg=2.08\n",
      "[271 | 51.49] loss=2.69 avg=2.09\n",
      "[272 | 51.55] loss=2.46 avg=2.09\n",
      "[273 | 51.60] loss=2.21 avg=2.09\n",
      "[274 | 51.65] loss=1.25 avg=2.09\n",
      "[275 | 51.71] loss=1.59 avg=2.08\n",
      "[276 | 51.76] loss=2.43 avg=2.08\n",
      "[277 | 51.81] loss=2.77 avg=2.09\n",
      "[278 | 51.86] loss=1.57 avg=2.09\n",
      "[279 | 51.92] loss=2.21 avg=2.09\n",
      "[280 | 51.97] loss=1.03 avg=2.08\n",
      "[281 | 52.02] loss=2.78 avg=2.08\n",
      "[282 | 52.07] loss=2.23 avg=2.08\n",
      "[283 | 52.13] loss=1.65 avg=2.08\n",
      "[284 | 52.18] loss=1.70 avg=2.08\n",
      "[285 | 52.23] loss=2.70 avg=2.08\n",
      "[286 | 52.29] loss=1.30 avg=2.07\n",
      "[287 | 52.34] loss=3.29 avg=2.09\n",
      "[288 | 52.39] loss=2.30 avg=2.09\n",
      "[289 | 52.44] loss=2.55 avg=2.09\n",
      "[290 | 52.50] loss=0.19 avg=2.07\n",
      "[291 | 52.55] loss=2.13 avg=2.07\n",
      "[292 | 52.61] loss=1.75 avg=2.07\n",
      "[293 | 52.66] loss=1.79 avg=2.07\n",
      "[294 | 52.72] loss=1.82 avg=2.07\n",
      "[295 | 52.77] loss=2.25 avg=2.07\n",
      "[296 | 52.83] loss=3.36 avg=2.08\n",
      "[297 | 52.88] loss=0.22 avg=2.06\n",
      "[298 | 52.93] loss=2.20 avg=2.06\n",
      "[299 | 52.99] loss=2.20 avg=2.06\n",
      "Generating samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:00<00:00, 40.51it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== SAMPLE 1 ========\n",
      " .  After some preliminary testing, we found the \"Boltage Indicator\" in all but three cases.    We then had one of the first \"Numerical Analysis\" exercises           to identify what parts of each     ,                   form factor we needed to measure        for the     series.      We                         ________ ________   ______________________ ______________________ ______________________ _____________________________________________________________________ _________________________  ا  _        ,                                    \n",
      "Posted on by   Jansen                                  ]<|endoftext|>The number of children and families with severe mental disorders is increasing in South Korea, leading to concerns about their mental well-being. Although there has been a number of studies to date on the impact of stress on children, there is little research on the relation between stress and the severity of the mental disorders. Nevertheless, there is concern that, while they may have more of an impact on mental health in South Korea and South Korea's public system than in other countries, some children may have lower health outcomes.\n",
      " ______________________________________ ________ ________ / ________  ________  | ________ ______________________________  ____ _______ ________ ________ ______________________ ___ _____________________________________ _____________________________________ ______________________ ______________________  ________    ______________________________________ ______________________________  __ ________  ________  ________  ________   ______________________________  _____ ________ _____ ________ ________ _____ ________  ______________________   ____ |  ____ ____ ___    ______________________\n",
      " __________________________________ ______________________ ________ ________ ______________________________ ____ ________   ___ _______  ___      |    ____   ____  ________   ________            ___ \n",
      "EXCUSSION:      ________                                   \n",
      "This post originally appeared October 18, 2010. It was made possible thanks to a Kickstarter campaign.                   ___                                              \n",
      "This post originally appeared October 18, 2010. It was made possible thanks to a Kickstarter campaign.                                                      \n",
      "Posted by: T                                            \n",
      "Brought to you by                                     \n",
      "This blog has also been featured on       . ___________________________       ____                  \n",
      "We have already                                           \n",
      "Read more ________    ________ ________   ________   ________  ________  ____  ___  -              \n",
      "Dear ____            _____              __                                         \n",
      "Dear\n",
      "\n",
      "Calculating validation loss...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 10/40 [00:00<00:00, 40.73it/s]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:00<00:00, 41.55it/s]\u001b[A\n",
      " 50%|█████     | 20/40 [00:00<00:00, 42.06it/s]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:00<00:00, 42.13it/s]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:00<00:00, 42.38it/s]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:00<00:00, 42.48it/s]\u001b[A\n",
      "100%|██████████| 40/40 [00:00<00:00, 42.47it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300 | 67.78] validation loss = 2.08\n",
      "[300 | 67.83] loss=3.16 avg=2.08\n",
      "[301 | 67.89] loss=1.74 avg=2.07\n",
      "[302 | 67.95] loss=1.64 avg=2.07\n",
      "[303 | 68.00] loss=2.30 avg=2.07\n",
      "[304 | 68.05] loss=2.24 avg=2.07\n",
      "[305 | 68.11] loss=1.54 avg=2.07\n",
      "[306 | 68.16] loss=0.96 avg=2.06\n",
      "[307 | 68.21] loss=2.93 avg=2.06\n",
      "[308 | 68.27] loss=2.25 avg=2.07\n",
      "[309 | 68.32] loss=2.00 avg=2.07\n",
      "[310 | 68.38] loss=1.86 avg=2.06\n",
      "[311 | 68.43] loss=2.25 avg=2.07\n",
      "[312 | 68.49] loss=1.64 avg=2.06\n",
      "[313 | 68.54] loss=2.60 avg=2.07\n",
      "[314 | 68.60] loss=2.19 avg=2.07\n",
      "[315 | 68.65] loss=2.32 avg=2.07\n",
      "[316 | 68.71] loss=2.46 avg=2.07\n",
      "[317 | 68.76] loss=1.46 avg=2.07\n",
      "[318 | 68.81] loss=2.22 avg=2.07\n",
      "[319 | 68.87] loss=2.68 avg=2.08\n",
      "[320 | 68.92] loss=2.47 avg=2.08\n",
      "[321 | 68.97] loss=1.20 avg=2.07\n",
      "[322 | 69.02] loss=1.47 avg=2.06\n",
      "[323 | 69.07] loss=2.33 avg=2.07\n",
      "[324 | 69.13] loss=2.48 avg=2.07\n",
      "[325 | 69.19] loss=1.66 avg=2.07\n",
      "[326 | 69.24] loss=1.99 avg=2.07\n",
      "[327 | 69.30] loss=2.93 avg=2.08\n",
      "[328 | 69.35] loss=1.89 avg=2.07\n",
      "[329 | 69.40] loss=1.84 avg=2.07\n",
      "[330 | 69.46] loss=2.05 avg=2.07\n",
      "[331 | 69.52] loss=2.39 avg=2.07\n",
      "[332 | 69.58] loss=1.46 avg=2.07\n",
      "[333 | 69.63] loss=2.53 avg=2.07\n",
      "[334 | 69.68] loss=2.12 avg=2.07\n",
      "[335 | 69.73] loss=1.88 avg=2.07\n",
      "[336 | 69.79] loss=2.68 avg=2.08\n",
      "[337 | 69.84] loss=2.81 avg=2.09\n",
      "[338 | 69.90] loss=0.77 avg=2.07\n",
      "[339 | 69.95] loss=2.15 avg=2.07\n",
      "[340 | 70.00] loss=1.50 avg=2.07\n",
      "[341 | 70.06] loss=1.53 avg=2.06\n",
      "[342 | 70.11] loss=1.85 avg=2.06\n",
      "[343 | 70.17] loss=2.84 avg=2.07\n",
      "[344 | 70.22] loss=1.96 avg=2.07\n",
      "[345 | 70.28] loss=2.58 avg=2.07\n",
      "[346 | 70.33] loss=1.76 avg=2.07\n",
      "[347 | 70.39] loss=2.54 avg=2.07\n",
      "[348 | 70.44] loss=2.67 avg=2.08\n",
      "[349 | 70.49] loss=0.96 avg=2.07\n",
      "[350 | 70.54] loss=1.54 avg=2.06\n",
      "[351 | 70.60] loss=2.76 avg=2.07\n",
      "[352 | 70.65] loss=2.18 avg=2.07\n",
      "[353 | 70.71] loss=2.30 avg=2.07\n",
      "[354 | 70.76] loss=2.15 avg=2.07\n",
      "[355 | 70.81] loss=2.38 avg=2.08\n",
      "[356 | 70.87] loss=2.63 avg=2.08\n",
      "[357 | 70.92] loss=2.28 avg=2.08\n",
      "[358 | 70.97] loss=1.80 avg=2.08\n",
      "[359 | 71.03] loss=3.37 avg=2.09\n",
      "[360 | 71.08] loss=0.91 avg=2.08\n",
      "[361 | 71.13] loss=0.73 avg=2.07\n",
      "[362 | 71.19] loss=2.88 avg=2.08\n",
      "[363 | 71.24] loss=1.43 avg=2.07\n",
      "[364 | 71.30] loss=1.92 avg=2.07\n",
      "[365 | 71.35] loss=2.57 avg=2.07\n",
      "[366 | 71.40] loss=1.77 avg=2.07\n",
      "[367 | 71.46] loss=1.96 avg=2.07\n",
      "[368 | 71.51] loss=1.30 avg=2.06\n",
      "[369 | 71.56] loss=2.81 avg=2.07\n",
      "[370 | 71.62] loss=1.63 avg=2.06\n",
      "[371 | 71.67] loss=2.79 avg=2.07\n",
      "[372 | 71.72] loss=1.80 avg=2.07\n",
      "[373 | 71.78] loss=0.92 avg=2.06\n",
      "[374 | 71.83] loss=1.53 avg=2.05\n",
      "[375 | 71.89] loss=1.57 avg=2.05\n",
      "[376 | 71.94] loss=2.53 avg=2.05\n",
      "[377 | 71.99] loss=2.64 avg=2.06\n",
      "[378 | 72.05] loss=1.69 avg=2.05\n",
      "[379 | 72.10] loss=2.25 avg=2.06\n",
      "[380 | 72.15] loss=2.42 avg=2.06\n",
      "[381 | 72.20] loss=1.13 avg=2.05\n",
      "[382 | 72.25] loss=3.07 avg=2.06\n",
      "[383 | 72.31] loss=1.69 avg=2.06\n",
      "[384 | 72.36] loss=1.50 avg=2.05\n",
      "[385 | 72.41] loss=2.09 avg=2.05\n",
      "[386 | 72.47] loss=3.13 avg=2.06\n",
      "[387 | 72.52] loss=2.78 avg=2.07\n",
      "[388 | 72.57] loss=1.14 avg=2.06\n",
      "[389 | 72.62] loss=2.78 avg=2.07\n",
      "[390 | 72.67] loss=2.93 avg=2.08\n",
      "[391 | 72.72] loss=0.04 avg=2.06\n",
      "[392 | 72.78] loss=2.74 avg=2.06\n",
      "[393 | 72.83] loss=2.21 avg=2.06\n",
      "[394 | 72.89] loss=2.04 avg=2.06\n",
      "[395 | 72.94] loss=2.39 avg=2.07\n",
      "[396 | 72.99] loss=1.53 avg=2.06\n",
      "[397 | 73.04] loss=2.82 avg=2.07\n",
      "[398 | 73.09] loss=2.43 avg=2.07\n",
      "[399 | 73.14] loss=1.77 avg=2.07\n",
      "Generating samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:00<00:00, 42.19it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== SAMPLE 1 ========\n",
      "product for a few years or until we had one. In that time, we realized there are many different types of bacteria in the water, and that if you remove it from your hand you may run into certain health problems. When we tested all that, there were no differences in pH, but a few things seemed very different.  The pH that we found was the same for all different kinds of bacteria, with the exception of some   that were very common.  But this study           found that   we       �    some                             \n",
      "  C.          \n",
      "                       \n",
      "                                                                                   \n",
      "    -   \n",
      "            \n",
      "          \n",
      "         \n",
      "         \n",
      "         \n",
      "         \n",
      " \n",
      "         \n",
      " C.               C.           \n",
      "         C.                     \n",
      "                  C              \n",
      "                                \n",
      "                                           C.\n",
      "                                                            \n",
      "                                                      \n",
      "Diet        \n",
      "                                                                                                                          \n",
      "\n",
      "Calculating validation loss...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 10/40 [00:00<00:00, 42.00it/s]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:00<00:00, 40.95it/s]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:00<00:00, 41.70it/s]\u001b[A\n",
      " 60%|██████    | 24/40 [00:00<00:00, 41.70it/s]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:00<00:00, 40.47it/s]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:00<00:00, 40.66it/s]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:00<00:00, 40.77it/s]\u001b[A\n",
      "100%|██████████| 40/40 [00:00<00:00, 40.82it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400 | 87.77] validation loss = 2.06\n",
      "[400 | 87.82] loss=1.33 avg=2.06\n",
      "[401 | 87.88] loss=2.78 avg=2.07\n",
      "[402 | 87.94] loss=2.07 avg=2.07\n",
      "[403 | 87.99] loss=2.73 avg=2.08\n",
      "[404 | 88.05] loss=1.90 avg=2.07\n",
      "[405 | 88.10] loss=2.19 avg=2.08\n",
      "[406 | 88.15] loss=2.47 avg=2.08\n",
      "[407 | 88.21] loss=2.16 avg=2.08\n",
      "[408 | 88.26] loss=2.58 avg=2.09\n",
      "[409 | 88.31] loss=2.71 avg=2.09\n",
      "[410 | 88.36] loss=2.82 avg=2.10\n",
      "[411 | 88.41] loss=2.14 avg=2.10\n",
      "[412 | 88.47] loss=1.54 avg=2.09\n",
      "[413 | 88.52] loss=2.18 avg=2.10\n",
      "[414 | 88.57] loss=2.65 avg=2.10\n",
      "[415 | 88.63] loss=0.31 avg=2.08\n",
      "[416 | 88.68] loss=2.77 avg=2.09\n",
      "[417 | 88.73] loss=2.21 avg=2.09\n",
      "[418 | 88.78] loss=1.43 avg=2.08\n",
      "[419 | 88.84] loss=2.14 avg=2.08\n",
      "[420 | 88.89] loss=3.06 avg=2.09\n",
      "[421 | 88.94] loss=1.12 avg=2.08\n",
      "[422 | 88.99] loss=2.10 avg=2.08\n",
      "[423 | 89.04] loss=0.29 avg=2.07\n",
      "[424 | 89.10] loss=1.54 avg=2.06\n",
      "[425 | 89.16] loss=3.04 avg=2.07\n",
      "[426 | 89.21] loss=3.29 avg=2.08\n",
      "[427 | 89.26] loss=0.31 avg=2.07\n",
      "[428 | 89.31] loss=0.61 avg=2.05\n",
      "[429 | 89.36] loss=3.19 avg=2.06\n",
      "[430 | 89.42] loss=2.20 avg=2.06\n",
      "[431 | 89.47] loss=1.65 avg=2.06\n",
      "[432 | 89.53] loss=0.95 avg=2.05\n",
      "[433 | 89.59] loss=1.56 avg=2.04\n",
      "[434 | 89.64] loss=2.66 avg=2.05\n",
      "[435 | 89.69] loss=0.78 avg=2.04\n",
      "[436 | 89.75] loss=1.26 avg=2.03\n",
      "[437 | 89.80] loss=2.02 avg=2.03\n",
      "[438 | 89.86] loss=2.51 avg=2.03\n",
      "[439 | 89.91] loss=1.66 avg=2.03\n",
      "[440 | 89.96] loss=2.99 avg=2.04\n",
      "[441 | 90.01] loss=1.61 avg=2.04\n",
      "[442 | 90.07] loss=1.73 avg=2.03\n",
      "[443 | 90.12] loss=1.83 avg=2.03\n",
      "[444 | 90.17] loss=0.77 avg=2.02\n",
      "[445 | 90.23] loss=2.03 avg=2.02\n",
      "[446 | 90.29] loss=2.20 avg=2.02\n",
      "[447 | 90.34] loss=1.78 avg=2.02\n",
      "[448 | 90.39] loss=2.30 avg=2.02\n",
      "[449 | 90.44] loss=2.34 avg=2.02\n",
      "[450 | 90.50] loss=1.49 avg=2.02\n",
      "[451 | 90.55] loss=2.01 avg=2.02\n",
      "[452 | 90.61] loss=1.61 avg=2.01\n",
      "[453 | 90.66] loss=1.75 avg=2.01\n",
      "[454 | 90.72] loss=2.03 avg=2.01\n",
      "[455 | 90.77] loss=2.48 avg=2.02\n",
      "[456 | 90.82] loss=1.67 avg=2.01\n",
      "[457 | 90.88] loss=1.88 avg=2.01\n",
      "[458 | 90.93] loss=2.51 avg=2.02\n",
      "[459 | 90.98] loss=2.50 avg=2.02\n",
      "[460 | 91.03] loss=2.96 avg=2.03\n",
      "[461 | 91.08] loss=2.24 avg=2.03\n",
      "[462 | 91.14] loss=3.19 avg=2.04\n",
      "[463 | 91.19] loss=2.75 avg=2.05\n",
      "[464 | 91.24] loss=2.20 avg=2.05\n",
      "[465 | 91.29] loss=2.99 avg=2.06\n",
      "[466 | 91.35] loss=2.26 avg=2.06\n",
      "[467 | 91.40] loss=1.71 avg=2.06\n",
      "[468 | 91.46] loss=2.80 avg=2.07\n",
      "[469 | 91.51] loss=2.78 avg=2.08\n",
      "[470 | 91.56] loss=1.80 avg=2.07\n",
      "[471 | 91.62] loss=2.32 avg=2.08\n",
      "[472 | 91.67] loss=1.78 avg=2.07\n",
      "[473 | 91.73] loss=2.13 avg=2.07\n",
      "[474 | 91.78] loss=1.91 avg=2.07\n",
      "[475 | 91.83] loss=0.74 avg=2.06\n",
      "[476 | 91.89] loss=3.37 avg=2.07\n",
      "[477 | 91.94] loss=1.82 avg=2.07\n",
      "[478 | 92.00] loss=3.11 avg=2.08\n",
      "[479 | 92.05] loss=3.03 avg=2.09\n",
      "[480 | 92.10] loss=1.85 avg=2.09\n",
      "[481 | 92.16] loss=0.62 avg=2.07\n",
      "[482 | 92.21] loss=0.49 avg=2.06\n",
      "[483 | 92.26] loss=1.64 avg=2.05\n",
      "[484 | 92.32] loss=1.06 avg=2.04\n",
      "[485 | 92.37] loss=2.01 avg=2.04\n",
      "[486 | 92.43] loss=1.26 avg=2.03\n",
      "[487 | 92.48] loss=2.34 avg=2.04\n",
      "[488 | 92.53] loss=0.31 avg=2.02\n",
      "[489 | 92.58] loss=0.94 avg=2.01\n",
      "[490 | 92.64] loss=2.63 avg=2.01\n",
      "[491 | 92.69] loss=2.06 avg=2.01\n",
      "[492 | 92.74] loss=4.04 avg=2.04\n",
      "[493 | 92.79] loss=2.38 avg=2.04\n",
      "[494 | 92.84] loss=2.16 avg=2.04\n",
      "[495 | 92.90] loss=2.19 avg=2.04\n",
      "[496 | 92.95] loss=1.78 avg=2.04\n",
      "[497 | 93.00] loss=2.12 avg=2.04\n",
      "[498 | 93.06] loss=1.26 avg=2.03\n",
      "[499 | 93.11] loss=2.48 avg=2.04\n",
      "Generating samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:00<00:00, 42.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== SAMPLE 1 ========\n",
      "  (5.12.01) ・2 (5.12.02) 겜트 한 가 김 옭 한 구는 ꠀ가 는 겴 삼 햴 그 햔 트알 괴 행 규 게 그 잘 햴서곊 계 헥 해 꺀 할 그 환 현 가 옭 한 김 안 거 걆 터 관 ��� 핔 사 포 행 가 회 걼 한 김 위 기 괳 혀 터 곌 히 홠 히 그 팜 하 결 궃 혀 터 가 이 퍼 풀 삼 행 는 혔 햸 훈 프 환 훈 훈 환 (6.13) ・2 (6.13.01) 엶 팭 펼 퍰 흱 곕 관 행 격 홴 ��� 겍영 거 괚 곽 정 괨 게 괰 혀 괼 행 기 괅 강 궕 곽 게는 결 곋 퀤 겠 겠 겡 겠 겠 겡 대 하 곀 가 선 ��� 횩 괬 게 괫 혀 격 괔 궩 겠 겠 아 테 팑 ꜄ 거 꽃 걼 팀 가 가 격 시 감 겡 겡 겡 겡 (9.1) グ 후 행 꼀 퐬 휄 갽 그 환 테 و 홄 횩 풀 행 기 격 선 ퟶ 가 히 히 격 기 겡 겡 겡 겡 겡 겡 겡 겡 희 혀 환 포 퓵 히 곀 결 곐 곽 격 고 격 고 고 겠 과 겠 겠 과 겠 과 과 과 과 곽 곽 겠 겠 곽 겠 겠 겠 (9.1) ・2 (9.1.02) グ 필 겠 겠 구 한 곀 겠 겡 겡 겡 겡 겡 겡 겡 켓 괭 행 겡 햁 검 괝 교 격 괪 겡 겡 겡 \n",
      "\n",
      "Calculating validation loss...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 22%|██▎       | 9/40 [00:00<00:00, 41.29it/s]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:00<00:00, 41.35it/s]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:00<00:00, 42.49it/s]\u001b[A\n",
      " 60%|██████    | 24/40 [00:00<00:00, 42.91it/s]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:00<00:00, 42.68it/s]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:00<00:00, 41.69it/s]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:00<00:00, 41.59it/s]\u001b[A\n",
      "100%|██████████| 40/40 [00:00<00:00, 41.89it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500 | 107.81] validation loss = 2.05\n",
      "[500 | 107.87] loss=2.35 avg=2.04\n",
      "[501 | 107.93] loss=1.73 avg=2.04\n",
      "[502 | 107.98] loss=0.26 avg=2.02\n",
      "[503 | 108.03] loss=1.41 avg=2.01\n",
      "[504 | 108.09] loss=1.47 avg=2.01\n",
      "[505 | 108.14] loss=0.74 avg=1.99\n",
      "[506 | 108.19] loss=3.25 avg=2.01\n",
      "[507 | 108.24] loss=0.22 avg=1.99\n",
      "[508 | 108.30] loss=2.91 avg=2.00\n",
      "[509 | 108.35] loss=2.51 avg=2.00\n",
      "[510 | 108.41] loss=1.99 avg=2.00\n",
      "[511 | 108.46] loss=0.22 avg=1.99\n",
      "[512 | 108.51] loss=2.43 avg=1.99\n",
      "[513 | 108.57] loss=1.53 avg=1.98\n",
      "[514 | 108.62] loss=1.86 avg=1.98\n",
      "[515 | 108.68] loss=1.93 avg=1.98\n",
      "[516 | 108.73] loss=3.82 avg=2.00\n",
      "[517 | 108.78] loss=1.14 avg=1.99\n",
      "[518 | 108.83] loss=1.55 avg=1.99\n",
      "[519 | 108.89] loss=1.58 avg=1.98\n",
      "[520 | 108.94] loss=2.76 avg=1.99\n",
      "[521 | 109.00] loss=2.06 avg=1.99\n",
      "[522 | 109.05] loss=2.13 avg=1.99\n",
      "[523 | 109.10] loss=1.19 avg=1.99\n",
      "[524 | 109.16] loss=3.06 avg=2.00\n",
      "[525 | 109.21] loss=2.03 avg=2.00\n",
      "[526 | 109.26] loss=1.34 avg=1.99\n",
      "[527 | 109.31] loss=0.80 avg=1.98\n",
      "[528 | 109.37] loss=2.57 avg=1.98\n",
      "[529 | 109.42] loss=2.28 avg=1.99\n",
      "[530 | 109.47] loss=2.86 avg=2.00\n",
      "[531 | 109.53] loss=2.02 avg=2.00\n",
      "[532 | 109.58] loss=2.43 avg=2.00\n",
      "[533 | 109.64] loss=1.89 avg=2.00\n",
      "[534 | 109.69] loss=1.25 avg=1.99\n",
      "[535 | 109.74] loss=2.28 avg=2.00\n",
      "[536 | 109.80] loss=2.18 avg=2.00\n",
      "[537 | 109.85] loss=1.58 avg=1.99\n",
      "[538 | 109.90] loss=2.71 avg=2.00\n",
      "[539 | 109.96] loss=1.06 avg=1.99\n",
      "[540 | 110.01] loss=1.48 avg=1.99\n",
      "[541 | 110.07] loss=1.17 avg=1.98\n",
      "[542 | 110.12] loss=1.33 avg=1.97\n",
      "[543 | 110.17] loss=1.31 avg=1.96\n",
      "[544 | 110.23] loss=2.12 avg=1.97\n",
      "[545 | 110.28] loss=1.90 avg=1.96\n",
      "[546 | 110.33] loss=2.44 avg=1.97\n",
      "[547 | 110.38] loss=3.41 avg=1.98\n",
      "[548 | 110.44] loss=1.80 avg=1.98\n",
      "[549 | 110.49] loss=2.53 avg=1.99\n",
      "[550 | 110.54] loss=2.48 avg=1.99\n",
      "[551 | 110.59] loss=0.61 avg=1.98\n",
      "[552 | 110.65] loss=1.17 avg=1.97\n",
      "[553 | 110.70] loss=1.36 avg=1.96\n",
      "[554 | 110.75] loss=1.90 avg=1.96\n",
      "[555 | 110.81] loss=1.76 avg=1.96\n",
      "[556 | 110.87] loss=2.68 avg=1.97\n",
      "[557 | 110.92] loss=1.27 avg=1.96\n",
      "[558 | 110.97] loss=1.87 avg=1.96\n",
      "[559 | 111.02] loss=1.52 avg=1.96\n",
      "[560 | 111.08] loss=2.01 avg=1.96\n",
      "[561 | 111.14] loss=2.34 avg=1.96\n",
      "[562 | 111.19] loss=1.75 avg=1.96\n",
      "[563 | 111.24] loss=2.08 avg=1.96\n",
      "[564 | 111.29] loss=1.72 avg=1.96\n",
      "[565 | 111.35] loss=1.96 avg=1.96\n",
      "[566 | 111.40] loss=2.26 avg=1.96\n",
      "[567 | 111.45] loss=1.73 avg=1.96\n",
      "[568 | 111.51] loss=2.23 avg=1.96\n",
      "[569 | 111.56] loss=1.43 avg=1.96\n",
      "[570 | 111.61] loss=1.69 avg=1.95\n",
      "[571 | 111.66] loss=1.56 avg=1.95\n",
      "[572 | 111.72] loss=2.40 avg=1.95\n",
      "[573 | 111.77] loss=3.00 avg=1.96\n",
      "[574 | 111.82] loss=1.44 avg=1.96\n",
      "[575 | 111.87] loss=1.03 avg=1.95\n",
      "[576 | 111.93] loss=2.55 avg=1.96\n",
      "[577 | 111.98] loss=1.73 avg=1.95\n",
      "[578 | 112.03] loss=3.25 avg=1.97\n",
      "[579 | 112.08] loss=2.37 avg=1.97\n",
      "[580 | 112.14] loss=2.58 avg=1.98\n",
      "[581 | 112.19] loss=1.99 avg=1.98\n",
      "[582 | 112.24] loss=1.85 avg=1.98\n",
      "[583 | 112.29] loss=1.20 avg=1.97\n",
      "[584 | 112.35] loss=0.54 avg=1.95\n",
      "[585 | 112.40] loss=2.00 avg=1.95\n",
      "[586 | 112.46] loss=2.49 avg=1.96\n",
      "[587 | 112.51] loss=2.40 avg=1.96\n",
      "[588 | 112.56] loss=1.57 avg=1.96\n",
      "[589 | 112.61] loss=2.93 avg=1.97\n",
      "[590 | 112.67] loss=0.49 avg=1.95\n",
      "[591 | 112.72] loss=1.29 avg=1.95\n",
      "[592 | 112.77] loss=2.55 avg=1.95\n",
      "[593 | 112.82] loss=0.47 avg=1.94\n",
      "[594 | 112.88] loss=0.84 avg=1.93\n",
      "[595 | 112.93] loss=1.90 avg=1.93\n",
      "[596 | 112.98] loss=1.33 avg=1.92\n",
      "[597 | 113.04] loss=1.75 avg=1.92\n",
      "[598 | 113.09] loss=0.49 avg=1.91\n",
      "[599 | 113.14] loss=2.37 avg=1.91\n",
      "Generating samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:00<00:00, 41.95it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== SAMPLE 1 ========\n",
      " -1-1-1 -1-1-1-1-1 -1-1-1-1-1-1 -1-1-1-1-1-1-1 -1-1-1-1-1 -1-1-1-1-1) and any character (such as this text) will be rendered in the final form to create the document.\n",
      "\n",
      "\n",
      "As such, for a single (a-h1-h2) character, the document will be converted to the standard format.\n",
      "\n",
      "\n",
      "Any character (including numbers) will be converted to the format of the standard text.\n",
      "\n",
      "\n",
      "This document does not require any special permission from author or publisher. Please visit this document at the source for information relevant to your particular situation.\n",
      "\n",
      "\n",
      "-1-1-1\n",
      "\n",
      "1. What is the purpose of this paragraph? The purpose of this paragraph is to provide a general view of the problems and developments associated with the current world and its processes (see \"This Document\").\n",
      "\n",
      "\n",
      "1-1-1-1\n",
      "\n",
      "\n",
      "1-1-1-1 describes some of the main concerns and issues (e.g., problems of social engineering, of a complex network of government entities and civil liberties and rights, of \"cyberspace\"), but do not specifically give a general outline of the main policy aspects. For example, most of this document only states what problems or issues may cause change (i.e., what the goals of particular governments might be). However, the main goals and problems are usually not obvious.\n",
      "\n",
      "\n",
      "-1-1-1\n",
      " -------------- -- -------------- This document is about changes, but there may be other issues (such as a new law and government regulations, for example) -------------- -------------- -------------- -------------- This section describes some of the problems and issues associated with changes, but do not specifically give a general outline of the main policy aspects. For example, most of this document only states what problems or issues may cause change -------------- ----------------------------------------------------- If you have any questions about this document, please e-mail me: jmatt at gmail dot com. Note that this section is intended for a general audience. -------------- -------------- -------------- ----------------------------------------------------- -------------- -------------- This version of this document is subject to the terms of the GNU General Public License, Version 3 ( http://www.gnu.org/licenses/general-licenses ), which permits use with modifications or changes that: -------------- -------------- -------------- -------------- (1) add new problems or issues; or (2) modify, modify, or merge this document in any way that affects your requirements, issues, or other data. --------------\n",
      "\n",
      "1-1-1-1\n",
      "\n",
      "1-1-1-1 -------------- --\n",
      "\n",
      "1-1-1-1\n",
      "\n",
      "1-1-1-1-1\n",
      "\n",
      "1-1-1-1\n",
      "\n",
      "1-1-1-1\n",
      ". -------------- -- -------------- -------------- This document is about changes made within any government agency, and has not been updated since the last update. See all changes -------------- -------------- -------------- -------------- to the original source -------------- -------------- -------------- Changes -------------- -------------- -------------- -------------- -------------- -------------- -------------- -------------- -------------- -------------- -------------- This version of this document is subject to the terms of the GNU General Public License, Version 3 ( http://www.gnu.org/licenses/general-licenses ), which permits use with modifications or changes that: -------- -------------- -------- This document is based upon a manuscript by Martin Luther King, Jr. -------------- -------------- -------------- -------------- -------------- -------------- -------------- -------------- -------------- -------------- -------------- -------------- -------------- -------------- -------------- If you find something wrong with this document, please email me at bjmatt at gmail dot com. -------------- -------------- -------- -------------- -------------- -------------- -------------- -------- -------------- -------------- -------- . -------- -------------- -------------- -------------- -------------- -------------- -------------- -------------- -------------- -------- -------------- -------------- -------- -------------- -------------- -------------- -------- ------------------ ------------------- -------------- -------------- -------- 1. -------------- -------------- -------------- -------------- 2. -------------- | -------------- -------------- -------------- - -------------- -------------- -------------- -------------- -------------- -------------- -------------- 1. -------------- -------- -------------- -------- 1. -------------- -------------- -------- -------------- -------- -------------- -------- -------------- -------- -------- [ -------------- -------------- -------- -------------- -------- . -------------- -------- -------------- -------------- -------------- -------- -------------- ] --- -------------- -------- -------------- -------- -------------- -------------- -------- -------------- -------------- . -------------- -------- -------------- -------- -------------- --- -------------- -------- -------------- -------- -------------- -------------- -------- -------------- -------------- -------------- -------------- -------------- -------------- -------------- -------------- -------------- -------------- -------------- -------------- -------------- -------------- -------- -------- -------------- -------- [ -------------- -------- --------\n",
      "\n",
      "Calculating validation loss...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 22%|██▎       | 9/40 [00:00<00:00, 41.30it/s]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:00<00:00, 41.78it/s]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:00<00:00, 42.00it/s]\u001b[A\n",
      " 60%|██████    | 24/40 [00:00<00:00, 41.92it/s]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:00<00:00, 42.01it/s]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:00<00:00, 42.47it/s]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:00<00:00, 42.72it/s]\u001b[A\n",
      "100%|██████████| 40/40 [00:00<00:00, 42.24it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[600 | 127.95] validation loss = 2.04\n",
      "[600 | 128.00] loss=1.78 avg=1.91\n",
      "[601 | 128.05] loss=1.98 avg=1.91\n",
      "[602 | 128.10] loss=2.53 avg=1.92\n",
      "[603 | 128.15] loss=2.28 avg=1.92\n",
      "[604 | 128.21] loss=2.55 avg=1.93\n",
      "[605 | 128.26] loss=1.91 avg=1.93\n",
      "[606 | 128.31] loss=2.24 avg=1.93\n",
      "[607 | 128.36] loss=2.28 avg=1.93\n",
      "[608 | 128.42] loss=1.25 avg=1.93\n",
      "[609 | 128.47] loss=1.98 avg=1.93\n",
      "[610 | 128.52] loss=2.56 avg=1.93\n",
      "[611 | 128.57] loss=0.04 avg=1.91\n",
      "[612 | 128.62] loss=2.44 avg=1.92\n",
      "[613 | 128.68] loss=1.78 avg=1.92\n",
      "[614 | 128.73] loss=2.82 avg=1.93\n",
      "[615 | 128.78] loss=1.65 avg=1.92\n",
      "[616 | 128.83] loss=1.70 avg=1.92\n",
      "[617 | 128.88] loss=2.75 avg=1.93\n",
      "[618 | 128.94] loss=1.92 avg=1.93\n",
      "[619 | 128.99] loss=2.12 avg=1.93\n",
      "[620 | 129.05] loss=1.86 avg=1.93\n",
      "[621 | 129.10] loss=1.45 avg=1.93\n",
      "[622 | 129.15] loss=0.56 avg=1.91\n",
      "[623 | 129.21] loss=1.11 avg=1.90\n",
      "[624 | 129.26] loss=1.29 avg=1.90\n",
      "[625 | 129.32] loss=1.45 avg=1.89\n",
      "[626 | 129.38] loss=2.11 avg=1.90\n",
      "[627 | 129.43] loss=0.97 avg=1.89\n",
      "[628 | 129.48] loss=2.16 avg=1.89\n",
      "[629 | 129.54] loss=2.08 avg=1.89\n",
      "[630 | 129.59] loss=1.59 avg=1.89\n",
      "[631 | 129.64] loss=3.24 avg=1.90\n",
      "[632 | 129.69] loss=2.06 avg=1.90\n",
      "[633 | 129.75] loss=3.45 avg=1.92\n",
      "[634 | 129.80] loss=2.56 avg=1.93\n",
      "[635 | 129.86] loss=1.39 avg=1.92\n",
      "[636 | 129.91] loss=2.03 avg=1.92\n",
      "[637 | 129.97] loss=2.95 avg=1.93\n",
      "[638 | 130.02] loss=2.13 avg=1.93\n",
      "[639 | 130.07] loss=1.95 avg=1.93\n",
      "[640 | 130.12] loss=2.44 avg=1.94\n",
      "[641 | 130.17] loss=4.07 avg=1.96\n",
      "[642 | 130.22] loss=2.41 avg=1.96\n",
      "[643 | 130.28] loss=2.91 avg=1.97\n",
      "[644 | 130.33] loss=2.35 avg=1.98\n",
      "[645 | 130.38] loss=2.09 avg=1.98\n",
      "[646 | 130.44] loss=2.50 avg=1.98\n",
      "[647 | 130.49] loss=1.86 avg=1.98\n",
      "[648 | 130.54] loss=1.20 avg=1.98\n",
      "[649 | 130.60] loss=0.82 avg=1.96\n",
      "[650 | 130.65] loss=2.71 avg=1.97\n",
      "[651 | 130.70] loss=2.88 avg=1.98\n",
      "[652 | 130.76] loss=2.60 avg=1.99\n",
      "[653 | 130.81] loss=1.27 avg=1.98\n",
      "[654 | 130.86] loss=0.04 avg=1.96\n",
      "[655 | 130.92] loss=0.77 avg=1.95\n",
      "[656 | 130.97] loss=2.26 avg=1.95\n",
      "[657 | 131.02] loss=1.05 avg=1.94\n",
      "[658 | 131.08] loss=2.83 avg=1.95\n",
      "[659 | 131.13] loss=2.28 avg=1.95\n",
      "[660 | 131.18] loss=0.41 avg=1.94\n",
      "[661 | 131.24] loss=2.07 avg=1.94\n",
      "[662 | 131.29] loss=1.59 avg=1.94\n",
      "[663 | 131.34] loss=1.50 avg=1.93\n",
      "[664 | 131.40] loss=3.09 avg=1.94\n",
      "[665 | 131.46] loss=1.71 avg=1.94\n",
      "[666 | 131.51] loss=2.11 avg=1.94\n",
      "[667 | 131.58] loss=3.50 avg=1.96\n",
      "[668 | 131.63] loss=1.80 avg=1.96\n",
      "[669 | 131.68] loss=2.93 avg=1.97\n",
      "[670 | 131.73] loss=1.52 avg=1.96\n",
      "[671 | 131.78] loss=0.84 avg=1.95\n",
      "[672 | 131.84] loss=1.74 avg=1.95\n",
      "[673 | 131.89] loss=0.82 avg=1.94\n",
      "[674 | 131.95] loss=1.09 avg=1.93\n",
      "[675 | 132.00] loss=2.42 avg=1.93\n",
      "[676 | 132.06] loss=1.50 avg=1.93\n",
      "[677 | 132.11] loss=2.27 avg=1.93\n",
      "[678 | 132.16] loss=3.05 avg=1.94\n",
      "[679 | 132.22] loss=2.00 avg=1.94\n",
      "[680 | 132.27] loss=1.56 avg=1.94\n",
      "[681 | 132.33] loss=2.70 avg=1.95\n",
      "[682 | 132.38] loss=1.33 avg=1.94\n",
      "[683 | 132.43] loss=0.92 avg=1.93\n",
      "[684 | 132.48] loss=2.45 avg=1.94\n",
      "[685 | 132.53] loss=2.90 avg=1.95\n",
      "[686 | 132.58] loss=2.98 avg=1.96\n",
      "[687 | 132.64] loss=0.89 avg=1.95\n",
      "[688 | 132.69] loss=2.41 avg=1.95\n",
      "[689 | 132.75] loss=2.35 avg=1.96\n",
      "[690 | 132.80] loss=1.73 avg=1.95\n",
      "[691 | 132.85] loss=2.69 avg=1.96\n",
      "[692 | 132.91] loss=0.14 avg=1.94\n",
      "[693 | 132.96] loss=1.70 avg=1.94\n",
      "[694 | 133.01] loss=2.50 avg=1.95\n",
      "[695 | 133.07] loss=1.35 avg=1.94\n",
      "[696 | 133.12] loss=0.60 avg=1.93\n",
      "[697 | 133.17] loss=1.72 avg=1.92\n",
      "[698 | 133.23] loss=1.68 avg=1.92\n",
      "[699 | 133.28] loss=1.93 avg=1.92\n",
      "Generating samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:00<00:00, 42.43it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== SAMPLE 1 ========\n",
      "screen. This allows you to easily change the resolution (including brightness) of the display.\n",
      "\n",
      "\n",
      "On Windows XP, the settings are similar to the default, but you still need to have the same program to enable or disable any of the settings, which are not listed. However there will be some additional options added in the future. The best places to find the settings is the settings menu at the bottom of every app. There you will find all of the default settings. Note that you must also set up your device with Xcode, as there won't be any options you do not need. Xcode provides you with two ways to control the Xcode window. First, you can enter a message through the \"Send text...\" window. If you type anything after the text then you are out of luck. For that, I suggest trying \"Show Xcode Text...\". You will receive a message which instructs you to press the \"Cancel\" button. As you do this, you will receive a message that tells you you have to stop using Xcode. You can then go back and look for the next option. ______________________________________________________ _______________________________________________ ______________ _______________________________________________ _______________________________________________ _______________________________________________ _______________________________________________ _______________________________________________\n",
      " ________\\ \\ +----------------------------------------+ | ---------------+ | x ---------------+----------------------------------------+ ******** ********| ******** | ---------------+----------------------------------------+ ********| ******** | ---------------+----------------------------------------+ ********| | ---------------------------+-----------------------+                   ------------------------------+---------------------------+   |        ------------------------------+---------------------------+ --------       --------      --------  \n",
      "                                       |  -------------------------           |                    |  ------------------------|  --------          | |           --------  --------                                   | | | | ------------------------   ------------------------|          |      --------   --------  --------    \n",
      "      ----------------               |                  |                    \n",
      "\n",
      "  --------------------                     | ------------------------       \\                   ;                                           ;          |                      |             |            \n",
      "\n",
      "   ----         |               \n",
      "\n",
      "                                                  |    \n",
      "                          \n",
      "               \n",
      "                     \n",
      "               \n",
      "                 \n",
      "   |   |        \n",
      "                        ;    \n",
      "                       ;           \n",
      "\n",
      "Calculating validation loss...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 22%|██▎       | 9/40 [00:00<00:00, 41.51it/s]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:00<00:00, 40.94it/s]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:00<00:00, 41.52it/s]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:00<00:00, 41.65it/s]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:00<00:00, 40.85it/s]\u001b[A\n",
      " 80%|████████  | 32/40 [00:00<00:00, 40.53it/s]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:00<00:00, 40.66it/s]\u001b[A\n",
      "100%|██████████| 40/40 [00:00<00:00, 40.90it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[700 | 147.92] validation loss = 2.03\n",
      "[700 | 147.98] loss=2.26 avg=1.92\n",
      "[701 | 148.04] loss=0.40 avg=1.91\n",
      "[702 | 148.09] loss=1.58 avg=1.91\n",
      "[703 | 148.15] loss=2.26 avg=1.91\n",
      "[704 | 148.20] loss=2.63 avg=1.92\n",
      "[705 | 148.25] loss=2.55 avg=1.92\n",
      "[706 | 148.31] loss=2.51 avg=1.93\n",
      "[707 | 148.36] loss=1.53 avg=1.93\n",
      "[708 | 148.41] loss=2.39 avg=1.93\n",
      "[709 | 148.47] loss=1.07 avg=1.92\n",
      "[710 | 148.52] loss=1.48 avg=1.92\n",
      "[711 | 148.57] loss=2.13 avg=1.92\n",
      "[712 | 148.63] loss=3.54 avg=1.94\n",
      "[713 | 148.68] loss=2.58 avg=1.94\n",
      "[714 | 148.74] loss=2.73 avg=1.95\n",
      "[715 | 148.79] loss=0.69 avg=1.94\n",
      "[716 | 148.84] loss=1.77 avg=1.94\n",
      "[717 | 148.90] loss=1.62 avg=1.93\n",
      "[718 | 148.95] loss=1.12 avg=1.92\n",
      "[719 | 149.01] loss=1.36 avg=1.92\n",
      "[720 | 149.06] loss=1.83 avg=1.92\n",
      "[721 | 149.11] loss=1.68 avg=1.91\n",
      "[722 | 149.17] loss=2.68 avg=1.92\n",
      "[723 | 149.23] loss=2.31 avg=1.93\n",
      "[724 | 149.28] loss=0.63 avg=1.91\n",
      "[725 | 149.34] loss=3.22 avg=1.93\n",
      "[726 | 149.39] loss=1.62 avg=1.92\n",
      "[727 | 149.44] loss=2.01 avg=1.92\n",
      "[728 | 149.50] loss=2.87 avg=1.93\n",
      "[729 | 149.55] loss=3.03 avg=1.94\n",
      "[730 | 149.61] loss=2.75 avg=1.95\n",
      "[731 | 149.67] loss=1.29 avg=1.95\n",
      "[732 | 149.72] loss=1.85 avg=1.95\n",
      "[733 | 149.78] loss=1.56 avg=1.94\n",
      "[734 | 149.83] loss=1.24 avg=1.93\n",
      "[735 | 149.88] loss=2.57 avg=1.94\n",
      "[736 | 149.93] loss=2.83 avg=1.95\n",
      "[737 | 149.99] loss=1.66 avg=1.95\n",
      "[738 | 150.04] loss=1.61 avg=1.94\n",
      "[739 | 150.10] loss=1.40 avg=1.94\n",
      "[740 | 150.15] loss=2.76 avg=1.95\n",
      "[741 | 150.20] loss=1.94 avg=1.95\n",
      "[742 | 150.26] loss=2.30 avg=1.95\n",
      "[743 | 150.31] loss=2.26 avg=1.95\n",
      "[744 | 150.37] loss=0.95 avg=1.94\n",
      "[745 | 150.42] loss=2.85 avg=1.95\n",
      "[746 | 150.47] loss=2.72 avg=1.96\n",
      "[747 | 150.52] loss=2.06 avg=1.96\n",
      "[748 | 150.58] loss=1.23 avg=1.95\n",
      "[749 | 150.63] loss=2.71 avg=1.96\n",
      "[750 | 150.68] loss=2.04 avg=1.96\n",
      "[751 | 150.73] loss=2.51 avg=1.97\n",
      "[752 | 150.79] loss=1.80 avg=1.97\n",
      "[753 | 150.84] loss=1.86 avg=1.96\n",
      "[754 | 150.89] loss=1.67 avg=1.96\n",
      "[755 | 150.95] loss=2.46 avg=1.97\n",
      "[756 | 151.00] loss=2.40 avg=1.97\n",
      "[757 | 151.05] loss=1.93 avg=1.97\n",
      "[758 | 151.11] loss=1.83 avg=1.97\n",
      "[759 | 151.16] loss=2.45 avg=1.97\n",
      "[760 | 151.22] loss=1.15 avg=1.97\n",
      "[761 | 151.27] loss=2.23 avg=1.97\n",
      "[762 | 151.32] loss=1.86 avg=1.97\n",
      "[763 | 151.38] loss=3.23 avg=1.98\n",
      "[764 | 151.43] loss=1.75 avg=1.98\n",
      "[765 | 151.48] loss=2.17 avg=1.98\n",
      "[766 | 151.54] loss=1.19 avg=1.97\n",
      "[767 | 151.59] loss=3.13 avg=1.98\n",
      "[768 | 151.64] loss=1.38 avg=1.98\n",
      "[769 | 151.70] loss=1.83 avg=1.98\n",
      "[770 | 151.75] loss=2.52 avg=1.98\n",
      "[771 | 151.80] loss=1.39 avg=1.97\n",
      "[772 | 151.86] loss=1.58 avg=1.97\n",
      "[773 | 151.91] loss=0.04 avg=1.95\n",
      "[774 | 151.96] loss=4.04 avg=1.97\n",
      "[775 | 152.01] loss=1.53 avg=1.97\n",
      "[776 | 152.06] loss=0.79 avg=1.96\n",
      "[777 | 152.12] loss=2.32 avg=1.96\n",
      "[778 | 152.17] loss=1.69 avg=1.96\n",
      "[779 | 152.23] loss=2.26 avg=1.96\n",
      "[780 | 152.28] loss=0.18 avg=1.94\n",
      "[781 | 152.34] loss=2.46 avg=1.95\n",
      "[782 | 152.39] loss=2.06 avg=1.95\n",
      "[783 | 152.44] loss=0.15 avg=1.93\n",
      "[784 | 152.50] loss=2.59 avg=1.94\n",
      "[785 | 152.55] loss=1.48 avg=1.93\n",
      "[786 | 152.60] loss=0.47 avg=1.92\n",
      "[787 | 152.65] loss=3.08 avg=1.93\n",
      "[788 | 152.71] loss=1.10 avg=1.92\n",
      "[789 | 152.77] loss=2.72 avg=1.93\n",
      "[790 | 152.82] loss=2.22 avg=1.93\n",
      "[791 | 152.87] loss=0.97 avg=1.92\n",
      "[792 | 152.93] loss=1.83 avg=1.92\n",
      "[793 | 152.98] loss=1.34 avg=1.92\n",
      "[794 | 153.03] loss=2.20 avg=1.92\n",
      "[795 | 153.09] loss=1.28 avg=1.91\n",
      "[796 | 153.14] loss=2.00 avg=1.91\n",
      "[797 | 153.19] loss=0.95 avg=1.90\n",
      "[798 | 153.24] loss=1.46 avg=1.90\n",
      "[799 | 153.30] loss=2.57 avg=1.91\n",
      "Generating samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:00<00:00, 45.23it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== SAMPLE 1 ========\n",
      " new by a local entrepreneur named Eric. He was looking for the right thing to do with the time he had left when he left to pursue his passion for video games for a living. Eric was a huge fan and soon decided to share his ideas with him. He brought this dream to life and has been working on this project all year to date. He is now working on a way for the game to work and will continue to work on it after its release.\n",
      "\n",
      "The team at Nintendo have made a fantastic debut on Kickstarter. The video game, Wii U was funded with only 40 backers (just 3 of this year). This is a project that has seen the development of new technology like a game or a game controller. In addition, the team have also created a Kickstarter campaign that will allow the crowd in this game to be helped through its final release. The amount of money they are getting into this is a testament to how generous of a team their passion is. It will take an amazing amount of hard work from the entire team to do their best. It is extremely difficult to come up with a project like this in early development, and this game has so much potential. However, it has been a tough decision to give into their desire. We have made a huge commitment to the game and have been extremely careful to deliver on all expectations. When all is said and done, we will be able to complete the design and release the game. Now everyone who follows the Kickstarter can take advantage of a free copy of the game. This will not only give you a great title, but will also show the passion and skills that will be needed to support the developers.\n",
      "\n",
      "We hope you enjoy the game!<|endoftext|>When you're stuck in a busy home, the best time to get down with friends on the job is in the form of a job interview. That's why many young adults don't need formal introductions and even so, these days there's no need to seek a job. Rather, there's a reason why job openings don't usually take that long.\n",
      "\n",
      "We talked to a new study published this week by the American Enterprise Institute (AEI), that shows that only 30 days for young American workers outnumber the 30-day age limit for job advertisements. That's the difference between being in the military and being under the age of 20. And when it comes to job applications, the American Enterprise Institute was the third most recent to compare job openings for young workers in their 20s to those of older workers.\n",
      "\n",
      "\"These results provide a great case study of the difficulty that people at a job opportunity don't always have in reaching an age in the workplace,\" said study co-author and assistant professor of educational and community life, Jennifer B. Smith. \"It's an advantage that a broad range of potential employers can have a harder time recruiting. Employers will only find someone more suited for their specific requirements if the applicant is well represented at age 20. But what is particularly important is the fact that younger workers, whose time at a job opportunity is relatively short, are much more willing to work on the job. It makes perfect sense for employers because this is the age they have the most opportunity to gain the most experience. This explains why we see more young workers than those who have had the experience. That can have serious implications for the future of our workforce.\"\n",
      "\n",
      "It doesn't stop there. \"In particular, the finding that young people who worked full time are more willing to have fun and do great work has implications for hiring managers and employers across the board,\" B. E. Smith said. \"However, it also increases the incentive for employers to hire people who have had the opportunity to get to the workplace to do good work. If employers want to hire people who have an interest in getting to the workplace, it's important for them to see the people they hire, and to consider them as part of their workforce.\"\n",
      " _________________________________________________\n",
      "\n",
      "In addition to being easier to spot -- with the study looking at employers who offer job advertisements for young workers compared to the older workers' ages -- it can also be used to attract new hire. \"People who are well represented on an age-restricted resume tend to get more job applications,\" Smith said. \"With both a good resume and a clear application strategy, people can be recruited quickly. That leads directly to opportunities for people coming in, who can learn the skills and skills needed to reach higher positions. With the ability to use these applications as an opportunity to obtain a new job, job seekers are more likely than ever to get their chance to get started.\"\n",
      "\n",
      "However, the study also found that job offers for these groups were not the same. In fact, the study found that young Americans' current employment prospects were actually quite different than those of the younger workers. While their job search opportunities were good, they were \"quite less competitive. The reasons for those differences were generally not entirely clear. For example, the age group older with these jobs was significantly younger than young (35\n",
      "\n",
      "Calculating validation loss...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 10/40 [00:00<00:00, 44.76it/s]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:00<00:00, 44.25it/s]\u001b[A\n",
      " 50%|█████     | 20/40 [00:00<00:00, 43.46it/s]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:00<00:00, 42.90it/s]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:00<00:00, 42.46it/s]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:00<00:00, 41.46it/s]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:00<00:00, 40.86it/s]\u001b[A\n",
      "100%|██████████| 40/40 [00:00<00:00, 41.83it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[800 | 167.84] validation loss = 2.02\n",
      "[800 | 167.90] loss=2.52 avg=1.91\n",
      "[801 | 167.96] loss=2.10 avg=1.91\n",
      "[802 | 168.01] loss=2.39 avg=1.92\n",
      "[803 | 168.07] loss=2.82 avg=1.93\n",
      "[804 | 168.12] loss=2.88 avg=1.94\n",
      "[805 | 168.17] loss=2.06 avg=1.94\n",
      "[806 | 168.23] loss=1.47 avg=1.93\n",
      "[807 | 168.28] loss=2.08 avg=1.94\n",
      "[808 | 168.34] loss=1.59 avg=1.93\n",
      "[809 | 168.39] loss=1.83 avg=1.93\n",
      "[810 | 168.44] loss=1.05 avg=1.92\n",
      "[811 | 168.50] loss=1.19 avg=1.91\n",
      "[812 | 168.55] loss=2.48 avg=1.92\n",
      "[813 | 168.60] loss=1.05 avg=1.91\n",
      "[814 | 168.66] loss=1.98 avg=1.91\n",
      "[815 | 168.71] loss=2.46 avg=1.92\n",
      "[816 | 168.77] loss=1.83 avg=1.92\n",
      "[817 | 168.82] loss=1.82 avg=1.92\n",
      "[818 | 168.87] loss=2.00 avg=1.92\n",
      "[819 | 168.92] loss=1.15 avg=1.91\n",
      "[820 | 168.98] loss=2.79 avg=1.92\n",
      "[821 | 169.04] loss=3.30 avg=1.93\n",
      "[822 | 169.09] loss=1.87 avg=1.93\n",
      "[823 | 169.14] loss=1.62 avg=1.93\n",
      "[824 | 169.20] loss=1.89 avg=1.93\n",
      "[825 | 169.26] loss=1.90 avg=1.93\n",
      "[826 | 169.31] loss=1.82 avg=1.93\n",
      "[827 | 169.36] loss=2.39 avg=1.93\n",
      "[828 | 169.41] loss=2.12 avg=1.93\n",
      "[829 | 169.46] loss=0.53 avg=1.92\n",
      "[830 | 169.51] loss=1.66 avg=1.92\n",
      "[831 | 169.57] loss=2.37 avg=1.92\n",
      "[832 | 169.62] loss=2.16 avg=1.92\n",
      "[833 | 169.68] loss=1.23 avg=1.92\n",
      "[834 | 169.73] loss=0.91 avg=1.91\n",
      "[835 | 169.79] loss=1.72 avg=1.90\n",
      "[836 | 169.84] loss=1.36 avg=1.90\n",
      "[837 | 169.90] loss=2.80 avg=1.91\n",
      "[838 | 169.95] loss=1.81 avg=1.91\n",
      "[839 | 170.01] loss=1.57 avg=1.90\n",
      "[840 | 170.06] loss=1.77 avg=1.90\n",
      "[841 | 170.11] loss=2.34 avg=1.91\n",
      "[842 | 170.17] loss=2.44 avg=1.91\n",
      "[843 | 170.22] loss=1.54 avg=1.91\n",
      "[844 | 170.27] loss=2.12 avg=1.91\n",
      "[845 | 170.32] loss=1.21 avg=1.90\n",
      "[846 | 170.38] loss=2.54 avg=1.91\n",
      "[847 | 170.43] loss=3.58 avg=1.93\n",
      "[848 | 170.49] loss=1.85 avg=1.93\n",
      "[849 | 170.54] loss=1.81 avg=1.92\n",
      "[850 | 170.59] loss=2.34 avg=1.93\n",
      "[851 | 170.65] loss=2.47 avg=1.93\n",
      "[852 | 170.70] loss=2.59 avg=1.94\n",
      "[853 | 170.75] loss=2.78 avg=1.95\n",
      "[854 | 170.80] loss=2.98 avg=1.96\n",
      "[855 | 170.85] loss=1.64 avg=1.96\n",
      "[856 | 170.90] loss=2.10 avg=1.96\n",
      "[857 | 170.96] loss=3.10 avg=1.97\n",
      "[858 | 171.01] loss=1.94 avg=1.97\n",
      "[859 | 171.06] loss=1.77 avg=1.97\n",
      "[860 | 171.12] loss=2.42 avg=1.97\n",
      "[861 | 171.17] loss=2.77 avg=1.98\n",
      "[862 | 171.23] loss=1.00 avg=1.97\n",
      "[863 | 171.28] loss=2.32 avg=1.97\n",
      "[864 | 171.33] loss=2.33 avg=1.98\n",
      "[865 | 171.39] loss=2.34 avg=1.98\n",
      "[866 | 171.44] loss=3.04 avg=1.99\n",
      "[867 | 171.49] loss=1.71 avg=1.99\n",
      "[868 | 171.55] loss=1.33 avg=1.98\n",
      "[869 | 171.60] loss=1.39 avg=1.98\n",
      "[870 | 171.66] loss=1.83 avg=1.97\n",
      "[871 | 171.71] loss=0.28 avg=1.96\n",
      "[872 | 171.76] loss=1.76 avg=1.95\n",
      "[873 | 171.82] loss=2.59 avg=1.96\n",
      "[874 | 171.87] loss=1.51 avg=1.96\n",
      "[875 | 171.93] loss=2.18 avg=1.96\n",
      "[876 | 171.98] loss=2.55 avg=1.96\n",
      "[877 | 172.04] loss=1.62 avg=1.96\n",
      "[878 | 172.09] loss=2.70 avg=1.97\n",
      "[879 | 172.14] loss=2.48 avg=1.97\n",
      "[880 | 172.20] loss=1.79 avg=1.97\n",
      "[881 | 172.25] loss=3.45 avg=1.99\n",
      "[882 | 172.30] loss=2.24 avg=1.99\n",
      "[883 | 172.36] loss=1.94 avg=1.99\n",
      "[884 | 172.41] loss=0.18 avg=1.97\n",
      "[885 | 172.47] loss=2.51 avg=1.98\n",
      "[886 | 172.52] loss=2.07 avg=1.98\n",
      "[887 | 172.57] loss=2.66 avg=1.98\n",
      "[888 | 172.63] loss=2.15 avg=1.99\n",
      "[889 | 172.68] loss=1.49 avg=1.98\n",
      "[890 | 172.73] loss=0.04 avg=1.96\n",
      "[891 | 172.79] loss=2.15 avg=1.96\n",
      "[892 | 172.84] loss=0.80 avg=1.95\n",
      "[893 | 172.90] loss=2.31 avg=1.95\n",
      "[894 | 172.95] loss=0.04 avg=1.94\n",
      "[895 | 173.00] loss=1.58 avg=1.93\n",
      "[896 | 173.05] loss=1.30 avg=1.93\n",
      "[897 | 173.10] loss=2.07 avg=1.93\n",
      "[898 | 173.16] loss=0.91 avg=1.92\n",
      "[899 | 173.21] loss=1.40 avg=1.91\n",
      "Generating samples...\n"
     ]
    }
   ],
   "source": [
    "CHECKPOINT_DIR = 'checkpoint'\n",
    "SAMPLE_DIR = 'samples'\n",
    "\n",
    "\n",
    "# parser = argparse.ArgumentParser(\n",
    "#     description='Fine-tune GPT-2 on your custom dataset.',\n",
    "#     formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "\n",
    "# parser.add_argument('--dataset', metavar='PATH', type=str, required=True, help='Input file, directory, or glob pattern (utf-8 text, or preencoded .npz files).')\n",
    "# parser.add_argument('--model_name', metavar='MODEL', type=str, default='117M', help='Pretrained model name')\n",
    "# parser.add_argument('--combine', metavar='CHARS', type=int, default=50000, help='Concatenate input files with <|endoftext|> separator into chunks of this minimum size')\n",
    "\n",
    "# parser.add_argument('--batch_size', metavar='SIZE', type=int, default=1, help='Batch size')\n",
    "# parser.add_argument('--learning_rate', metavar='LR', type=float, default=0.00002, help='Learning rate for Adam')\n",
    "# parser.add_argument('--accumulate_gradients', metavar='N', type=int, default=1, help='Accumulate gradients across N minibatches.')\n",
    "# parser.add_argument('--memory_saving_gradients', default=False, action='store_true', help='Use gradient checkpointing to reduce vram usage.')\n",
    "# parser.add_argument('--only_train_transformer_layers', default=False, action='store_true', help='Restrict training to the transformer blocks.')\n",
    "# parser.add_argument('--optimizer', type=str, default='adam', help='Optimizer. <adam|sgd>.')\n",
    "# parser.add_argument('--noise', type=float, default=0.0, help='Add noise to input training data to regularize against typos.')\n",
    "\n",
    "# parser.add_argument('--top_k', type=int, default=40, help='K for top-k sampling.')\n",
    "# parser.add_argument('--top_p', type=float, default=0.0, help='P for top-p sampling. Overrides top_k if set > 0.')\n",
    "\n",
    "# parser.add_argument('--restore_from', type=str, default='latest', help='Either \"latest\", \"fresh\", or a path to a checkpoint file')\n",
    "# parser.add_argument('--run_name', type=str, default='run1', help='Run id. Name of subdirectory in checkpoint/ and samples/')\n",
    "# parser.add_argument('--sample_every', metavar='N', type=int, default=100, help='Generate samples every N steps')\n",
    "# parser.add_argument('--sample_length', metavar='TOKENS', type=int, default=1023, help='Sample this many tokens')\n",
    "# parser.add_argument('--sample_num', metavar='N', type=int, default=1, help='Generate this many samples')\n",
    "# parser.add_argument('--save_every', metavar='N', type=int, default=1000, help='Write a checkpoint every N steps')\n",
    "\n",
    "# parser.add_argument('--val_dataset', metavar='PATH', type=str, default=None, help='Dataset for validation loss, defaults to --dataset.')\n",
    "# parser.add_argument('--val_batch_size', metavar='SIZE', type=int, default=2, help='Batch size for validation.')\n",
    "# parser.add_argument('--val_batch_count', metavar='N', type=int, default=40, help='Number of batches for validation.')\n",
    "# parser.add_argument('--val_every', metavar='STEPS', type=int, default=0, help='Calculate validation loss every STEPS steps.')\n",
    "\n",
    "\n",
    "def maketree(path):\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "def randomize(context, hparams, p):\n",
    "    if p > 0:\n",
    "        mask = tf.random.uniform(shape=tf.shape(input=context)) < p\n",
    "        noise = tf.random.uniform(shape=tf.shape(input=context), minval=0, maxval=hparams.n_vocab, dtype=tf.int32)\n",
    "        return tf.compat.v1.where(mask, noise, context)\n",
    "    else:\n",
    "        return context\n",
    "\n",
    "\n",
    "def main():\n",
    "    args = Args(\n",
    "                dataset=\"../data/sciclone/data10/mtufano/deepLearningMutants/out/changes/code\",\n",
    "                model_name=\"117M\",\n",
    "                combine=50000,\n",
    "                batch_size=1,\n",
    "                learning_rate=0.00002,\n",
    "                optimizer=\"sgd\",\n",
    "                noise=0.0,\n",
    "                top_k=40,\n",
    "                top_p=0.0,\n",
    "                run_name=\"run1\",\n",
    "                sample_every=100,\n",
    "                sample_length=1023,\n",
    "                sample_num=1,\n",
    "                save_every=1000,\n",
    "                val_dataset=None,\n",
    "                val_batch_size=2,\n",
    "                val_batch_count=40,\n",
    "                val_every=100\n",
    "    )\n",
    "    \n",
    "    enc = get_encoder(args.model_name, \"models\")\n",
    "    hparams = default_hparams()\n",
    "#     with open(os.path.join('models', args.model_name, 'hparams.json')) as f:\n",
    "#         hparams.override_from_dict(json.load(f))\n",
    "\n",
    "    if args.sample_length > hparams.n_ctx:\n",
    "        raise ValueError(\n",
    "            \"Can't get samples longer than window size: %s\" % hparams.n_ctx)\n",
    "\n",
    "#     if args.model_name == '345M':\n",
    "#         args.memory_saving_gradients = True\n",
    "#         if args.optimizer == 'adam':\n",
    "#             args.only_train_transformer_layers = True\n",
    "\n",
    "    config = tf.compat.v1.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    config.graph_options.rewrite_options.layout_optimizer = rewriter_config_pb2.RewriterConfig.OFF\n",
    "    with tf.compat.v1.Session(config=config) as sess:\n",
    "        context = tf.compat.v1.placeholder(tf.int32, [args.batch_size, None])\n",
    "        context_in = context # randomize(context, hparams, args.noise)\n",
    "        output = model(hparams=hparams, X=context_in)\n",
    "        loss = tf.reduce_mean(\n",
    "            input_tensor=tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                labels=context[:, 1:], logits=output['logits'][:, :-1]))\n",
    "\n",
    "        if args.val_every > 0:\n",
    "            val_context = tf.compat.v1.placeholder(tf.int32, [args.val_batch_size, None])\n",
    "            val_output = model(hparams=hparams, X=val_context)\n",
    "            val_loss = tf.reduce_mean(\n",
    "                input_tensor=tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                    labels=val_context[:, 1:], logits=val_output['logits'][:, :-1]))\n",
    "            val_loss_summary = tf.compat.v1.summary.scalar('val_loss', val_loss)\n",
    "\n",
    "\n",
    "        tf_sample = sample_sequence(\n",
    "            hparams=hparams,\n",
    "            length=args.sample_length,\n",
    "            context=context,\n",
    "            batch_size=args.batch_size,\n",
    "            temperature=1.0,\n",
    "            top_k=args.top_k)\n",
    "\n",
    "        all_vars = [v for v in tf.compat.v1.trainable_variables() if 'model' in v.name]\n",
    "        train_vars = all_vars # [v for v in all_vars if '/h' in v.name] if args.only_train_transformer_layers else all_vars\n",
    "\n",
    "        if args.optimizer == 'adam':\n",
    "            opt = tf.compat.v1.train.AdamOptimizer(learning_rate=args.learning_rate)\n",
    "        elif args.optimizer == 'sgd':\n",
    "            opt = tf.compat.v1.train.GradientDescentOptimizer(learning_rate=args.learning_rate)\n",
    "        else:\n",
    "            exit('Bad optimizer:', args.optimizer)\n",
    "\n",
    "        opt_grads = tf.gradients(ys=loss, xs=train_vars)\n",
    "        opt_grads = list(zip(opt_grads, train_vars))\n",
    "        opt_apply = opt.apply_gradients(opt_grads)\n",
    "        summary_loss = tf.compat.v1.summary.scalar('loss', loss)\n",
    "\n",
    "        summary_lr = tf.compat.v1.summary.scalar('learning_rate', args.learning_rate)\n",
    "        summaries = tf.compat.v1.summary.merge([summary_lr, summary_loss])\n",
    "\n",
    "        summary_log = tf.compat.v1.summary.FileWriter(\n",
    "            os.path.join(CHECKPOINT_DIR, args.run_name))\n",
    "\n",
    "        saver = tf.compat.v1.train.Saver(\n",
    "            var_list=all_vars,\n",
    "            max_to_keep=5,\n",
    "            keep_checkpoint_every_n_hours=2)\n",
    "        sess.run(tf.compat.v1.global_variables_initializer())\n",
    "\n",
    "        ckpt = tf.train.latest_checkpoint(\n",
    "            os.path.join(CHECKPOINT_DIR, args.run_name))\n",
    "        if ckpt is None:\n",
    "            # Get fresh GPT weights if new run.\n",
    "            ckpt = tf.train.latest_checkpoint(\n",
    "                os.path.join('models', args.model_name))\n",
    "\n",
    "        print('Loading checkpoint', ckpt)\n",
    "        saver.restore(sess, ckpt)\n",
    "\n",
    "        print('Loading dataset...')\n",
    "#         chunks = load_dataset(enc, args.dataset, args.combine)\n",
    "        data_sampler = Sampler(trn_set)\n",
    "        if args.val_every > 0:\n",
    "            val_chunks = val_set # load_dataset(enc, args.val_dataset, args.combine) if args.val_dataset else chunks\n",
    "        print('dataset has', data_sampler.total_size, 'tokens')\n",
    "        print('Training...')\n",
    "\n",
    "        if args.val_every > 0:\n",
    "            # Sample from validation set once with fixed seed to make\n",
    "            # it deterministic during training as well as across runs.\n",
    "            val_data_sampler = Sampler(val_chunks, seed=1)\n",
    "            val_batches = [[val_data_sampler.sample(128) for _ in range(args.val_batch_size)]\n",
    "                           for _ in range(args.val_batch_count)]\n",
    "\n",
    "        counter = 1\n",
    "        counter_path = os.path.join(CHECKPOINT_DIR, args.run_name, 'counter')\n",
    "        if os.path.exists(counter_path):\n",
    "            # Load the step number if we're resuming a run\n",
    "            # Add 1 so we don't immediately try to save again\n",
    "            with open(counter_path, 'r') as fp:\n",
    "                counter = int(fp.read()) + 1\n",
    "\n",
    "        def save():\n",
    "            maketree(os.path.join(CHECKPOINT_DIR, args.run_name))\n",
    "            print(\n",
    "                'Saving',\n",
    "                os.path.join(CHECKPOINT_DIR, args.run_name,\n",
    "                             'model-{}').format(counter))\n",
    "            saver.save(\n",
    "                sess,\n",
    "                os.path.join(CHECKPOINT_DIR, args.run_name, 'model'),\n",
    "                global_step=counter)\n",
    "            with open(counter_path, 'w') as fp:\n",
    "                fp.write(str(counter) + '\\n')\n",
    "\n",
    "        def generate_samples():\n",
    "            print('Generating samples...')\n",
    "            context_tokens = data_sampler.sample(1)\n",
    "            all_text = []\n",
    "            index = 0\n",
    "            while index < args.sample_num:\n",
    "                out = sess.run(\n",
    "                    tf_sample,\n",
    "                    feed_dict={context: args.batch_size * [context_tokens]})\n",
    "                for i in range(min(args.sample_num - index, args.batch_size)):\n",
    "                    text = enc.decode(out[i])\n",
    "                    text = '======== SAMPLE {} ========\\n{}\\n'.format(\n",
    "                        index + 1, text)\n",
    "                    all_text.append(text)\n",
    "                    index += 1\n",
    "            print(text)\n",
    "            maketree(os.path.join(SAMPLE_DIR, args.run_name))\n",
    "            with open(\n",
    "                    os.path.join(SAMPLE_DIR, args.run_name,\n",
    "                                 'samples-{}').format(counter), 'w') as fp:\n",
    "                fp.write('\\n'.join(all_text))\n",
    "\n",
    "        def validation():\n",
    "            print('Calculating validation loss...')\n",
    "            losses = []\n",
    "            for batch in tqdm.tqdm(val_batches):\n",
    "                losses.append(sess.run(val_loss, feed_dict={val_context: batch}))\n",
    "            v_val_loss = np.mean(losses)\n",
    "            v_summary = sess.run(val_loss_summary, feed_dict={val_loss: v_val_loss})\n",
    "            summary_log.add_summary(v_summary, counter)\n",
    "            summary_log.flush()\n",
    "            print(\n",
    "                '[{counter} | {time:2.2f}] validation loss = {loss:2.2f}'\n",
    "                .format(\n",
    "                    counter=counter,\n",
    "                    time=time.time() - start_time,\n",
    "                    loss=v_val_loss))\n",
    "\n",
    "        def sample_batch():\n",
    "            return [data_sampler.sample(128) for _ in range(args.batch_size)]\n",
    "\n",
    "\n",
    "        avg_loss = (0.0, 0.0)\n",
    "        start_time = time.time()\n",
    "\n",
    "        try:\n",
    "            while True:\n",
    "                if counter % args.save_every == 0:\n",
    "                    save()\n",
    "                if counter % args.sample_every == 0:\n",
    "                    generate_samples()\n",
    "                if args.val_every > 0 and (counter % args.val_every == 0 or counter == 1):\n",
    "                    validation()\n",
    "\n",
    "#                 if args.accumulate_gradients > 1:\n",
    "#                     sess.run(opt_reset)\n",
    "#                     for _ in range(args.accumulate_gradients):\n",
    "#                         sess.run(\n",
    "#                             opt_compute, feed_dict={context: sample_batch()})\n",
    "#                     (v_loss, v_summary) = sess.run((opt_apply, summaries))\n",
    "#                 else:\n",
    "                (_, v_loss, v_summary) = sess.run(\n",
    "                    (opt_apply, loss, summaries),\n",
    "                    feed_dict={context: sample_batch()})\n",
    "\n",
    "                summary_log.add_summary(v_summary, counter)\n",
    "\n",
    "                avg_loss = (avg_loss[0] * 0.99 + v_loss,\n",
    "                            avg_loss[1] * 0.99 + 1.0)\n",
    "\n",
    "                print(\n",
    "                    '[{counter} | {time:2.2f}] loss={loss:2.2f} avg={avg:2.2f}'\n",
    "                    .format(\n",
    "                        counter=counter,\n",
    "                        time=time.time() - start_time,\n",
    "                        loss=v_loss,\n",
    "                        avg=avg_loss[0] / avg_loss[1]))\n",
    "\n",
    "                counter += 1\n",
    "        except KeyboardInterrupt:\n",
    "            print('interrupted')\n",
    "            save()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tensorboard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:6006\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fc101426320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir checkpoint/run1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "gpt2_tf2_new.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
